{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53e67d62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25474,
     "status": "ok",
     "timestamp": 1651889012814,
     "user": {
      "displayName": "Glen Uehara",
      "userId": "02405348223145207511"
     },
     "user_tz": 420
    },
    "id": "53e67d62",
    "outputId": "0c62cd79-f0fa-41b7-fbe9-835ae7dad619"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pennylane in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (0.23.1)\n",
      "Requirement already satisfied: semantic-version==2.6 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane) (2.6.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane) (2.8.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane) (1.22.4)\n",
      "Requirement already satisfied: cachetools in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane) (5.2.0)\n",
      "Requirement already satisfied: autograd in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane) (1.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane) (1.8.1)\n",
      "Requirement already satisfied: retworkx in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane) (0.11.0)\n",
      "Requirement already satisfied: pennylane-lightning>=0.23 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane) (0.23.0)\n",
      "Requirement already satisfied: autoray>=0.3.1 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane) (0.3.1)\n",
      "Requirement already satisfied: appdirs in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane) (1.4.4)\n",
      "Requirement already satisfied: toml in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane) (0.10.2)\n",
      "Requirement already satisfied: ninja in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane-lightning>=0.23->pennylane) (1.10.2.3)\n",
      "Requirement already satisfied: future>=0.15.2 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from autograd->pennylane) (0.18.2)\n",
      "Requirement already satisfied: pennylane-qiskit in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: pennylane>=0.22 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane-qiskit) (0.23.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane-qiskit) (1.22.4)\n",
      "Requirement already satisfied: mthree>=0.17 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane-qiskit) (0.23.0)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane-qiskit) (2.8.3)\n",
      "Requirement already satisfied: qiskit>=0.32 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane-qiskit) (0.36.2)\n",
      "Requirement already satisfied: qiskit-ibmq-provider>=0.15 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from mthree>=0.17->pennylane-qiskit) (0.19.1)\n",
      "Requirement already satisfied: qiskit-terra>=0.18 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from mthree>=0.17->pennylane-qiskit) (0.20.2)\n",
      "Requirement already satisfied: scipy>=1.3 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from mthree>=0.17->pennylane-qiskit) (1.8.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from mthree>=0.17->pennylane-qiskit) (5.9.1)\n",
      "Requirement already satisfied: cython>=0.29 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from mthree>=0.17->pennylane-qiskit) (0.29.30)\n",
      "Requirement already satisfied: orjson>=3.0.0 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from mthree>=0.17->pennylane-qiskit) (3.7.1)\n",
      "Requirement already satisfied: autograd in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane>=0.22->pennylane-qiskit) (1.4)\n",
      "Requirement already satisfied: cachetools in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane>=0.22->pennylane-qiskit) (5.2.0)\n",
      "Requirement already satisfied: semantic-version==2.6 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane>=0.22->pennylane-qiskit) (2.6.0)\n",
      "Requirement already satisfied: autoray>=0.3.1 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane>=0.22->pennylane-qiskit) (0.3.1)\n",
      "Requirement already satisfied: appdirs in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane>=0.22->pennylane-qiskit) (1.4.4)\n",
      "Requirement already satisfied: toml in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane>=0.22->pennylane-qiskit) (0.10.2)\n",
      "Requirement already satisfied: pennylane-lightning>=0.23 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane>=0.22->pennylane-qiskit) (0.23.0)\n",
      "Requirement already satisfied: retworkx in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane>=0.22->pennylane-qiskit) (0.11.0)\n",
      "Requirement already satisfied: ninja in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from pennylane-lightning>=0.23->pennylane>=0.22->pennylane-qiskit) (1.10.2.3)\n",
      "Requirement already satisfied: qiskit-ignis==0.7.1 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit>=0.32->pennylane-qiskit) (0.7.1)\n",
      "Requirement already satisfied: qiskit-aer==0.10.4 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit>=0.32->pennylane-qiskit) (0.10.4)\n",
      "Requirement already satisfied: requests-ntlm>=1.1.0 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (1.1.0)\n",
      "Requirement already satisfied: requests>=2.19 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (2.27.1)\n",
      "Requirement already satisfied: websockets>=10.0 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (10.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (2.8.2)\n",
      "Requirement already satisfied: websocket-client>=1.0.1 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (1.3.2)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (1.26.9)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-ignis==0.7.1->qiskit>=0.32->pennylane-qiskit) (61.2.0)\n",
      "Requirement already satisfied: sympy>=1.3 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-terra>=0.18->mthree>=0.17->pennylane-qiskit) (1.10.1)\n",
      "Requirement already satisfied: tweedledum<2.0,>=1.1 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-terra>=0.18->mthree>=0.17->pennylane-qiskit) (1.1.1)\n",
      "Requirement already satisfied: dill>=0.3 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-terra>=0.18->mthree>=0.17->pennylane-qiskit) (0.3.5.1)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-terra>=0.18->mthree>=0.17->pennylane-qiskit) (3.5.0)\n",
      "Requirement already satisfied: ply>=3.10 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-terra>=0.18->mthree>=0.17->pennylane-qiskit) (3.11)\n",
      "Requirement already satisfied: python-constraint>=1.4 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-terra>=0.18->mthree>=0.17->pennylane-qiskit) (1.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from python-dateutil>=2.8.0->qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from requests>=2.19->qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (2022.5.18.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from requests>=2.19->qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from requests>=2.19->qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (3.3)\n",
      "Requirement already satisfied: ntlm-auth>=1.0.2 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from requests-ntlm>=1.1.0->qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (1.5.0)\n",
      "Requirement already satisfied: cryptography>=1.3 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from requests-ntlm>=1.1.0->qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (37.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (2.21)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from stevedore>=3.0.0->qiskit-terra>=0.18->mthree>=0.17->pennylane-qiskit) (5.9.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from sympy>=1.3->qiskit-terra>=0.18->mthree>=0.17->pennylane-qiskit) (1.2.1)\n",
      "Requirement already satisfied: future>=0.15.2 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from autograd->pennylane>=0.22->pennylane-qiskit) (0.18.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qiskit in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (0.36.2)\n",
      "Requirement already satisfied: qiskit-terra==0.20.2 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit) (0.20.2)\n",
      "Requirement already satisfied: qiskit-aer==0.10.4 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit) (0.10.4)\n",
      "Requirement already satisfied: qiskit-ignis==0.7.1 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit) (0.7.1)\n",
      "Requirement already satisfied: qiskit-ibmq-provider==0.19.1 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit) (0.19.1)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-aer==0.10.4->qiskit) (1.8.1)\n",
      "Requirement already satisfied: numpy>=1.16.3 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-aer==0.10.4->qiskit) (1.22.4)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-ibmq-provider==0.19.1->qiskit) (1.26.9)\n",
      "Requirement already satisfied: requests>=2.19 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-ibmq-provider==0.19.1->qiskit) (2.27.1)\n",
      "Requirement already satisfied: websockets>=10.0 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-ibmq-provider==0.19.1->qiskit) (10.3)\n",
      "Requirement already satisfied: requests-ntlm>=1.1.0 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-ibmq-provider==0.19.1->qiskit) (1.1.0)\n",
      "Requirement already satisfied: websocket-client>=1.0.1 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-ibmq-provider==0.19.1->qiskit) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-ibmq-provider==0.19.1->qiskit) (2.8.2)\n",
      "Requirement already satisfied: retworkx>=0.8.0 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-ignis==0.7.1->qiskit) (0.11.0)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-ignis==0.7.1->qiskit) (61.2.0)\n",
      "Requirement already satisfied: python-constraint>=1.4 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-terra==0.20.2->qiskit) (1.4.0)\n",
      "Requirement already satisfied: dill>=0.3 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-terra==0.20.2->qiskit) (0.3.5.1)\n",
      "Requirement already satisfied: ply>=3.10 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-terra==0.20.2->qiskit) (3.11)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-terra==0.20.2->qiskit) (3.5.0)\n",
      "Requirement already satisfied: psutil>=5 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-terra==0.20.2->qiskit) (5.9.1)\n",
      "Requirement already satisfied: sympy>=1.3 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-terra==0.20.2->qiskit) (1.10.1)\n",
      "Requirement already satisfied: tweedledum<2.0,>=1.1 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from qiskit-terra==0.20.2->qiskit) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from python-dateutil>=2.8.0->qiskit-ibmq-provider==0.19.1->qiskit) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.1->qiskit) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.1->qiskit) (2022.5.18.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.1->qiskit) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=1.3 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.19.1->qiskit) (37.0.1)\n",
      "Requirement already satisfied: ntlm-auth>=1.0.2 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.19.1->qiskit) (1.5.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.19.1->qiskit) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.19.1->qiskit) (2.21)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from stevedore>=3.0.0->qiskit-terra==0.20.2->qiskit) (5.9.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (from sympy>=1.3->qiskit-terra==0.20.2->qiskit) (1.2.1)\n",
      "Collecting qml\n",
      "  Using cached qml-0.4.0.27.tar.gz (41 kB)\n",
      "Building wheels for collected packages: qml\n",
      "  Building wheel for qml (setup.py): started\n",
      "  Building wheel for qml (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for qml\n",
      "Failed to build qml\n",
      "Installing collected packages: qml\n",
      "    Running setup.py install for qml: started\n",
      "    Running setup.py install for qml: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\gueha\\anaconda3\\envs\\quantum\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\gueha\\\\AppData\\\\Local\\\\Temp\\\\pip-install-uj3qr0yi\\\\qml_e26fd7e820ad46d6b9eee82a0b7bec8d\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\gueha\\\\AppData\\\\Local\\\\Temp\\\\pip-install-uj3qr0yi\\\\qml_e26fd7e820ad46d6b9eee82a0b7bec8d\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\gueha\\AppData\\Local\\Temp\\pip-wheel-hc0vkx9r'\n",
      "       cwd: C:\\Users\\gueha\\AppData\\Local\\Temp\\pip-install-uj3qr0yi\\qml_e26fd7e820ad46d6b9eee82a0b7bec8d\\\n",
      "  Complete output (69 lines):\n",
      "  MKL-discover: MKLROOT was not set\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running config_cc\n",
      "  INFO: unifing config_cc, config, build_clib, build_ext, build commands --compiler options\n",
      "  running config_fc\n",
      "  INFO: unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options\n",
      "  running build_src\n",
      "  INFO: build_src\n",
      "  INFO: building extension \"ffchl_module\" sources\n",
      "  INFO: f2py options: ['--quiet']\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10\\fortranobject.c' to sources.\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10' to include_dirs.\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\ffchl_module-f2pywrappers2.f90' to sources.\n",
      "  INFO: building extension \"farad_kernels\" sources\n",
      "  INFO: f2py options: ['--quiet']\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10\\fortranobject.c' to sources.\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10' to include_dirs.\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\farad_kernels-f2pywrappers2.f90' to sources.\n",
      "  INFO: building extension \"fcho_solve\" sources\n",
      "  INFO: f2py options: ['--quiet']\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10\\fortranobject.c' to sources.\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10' to include_dirs.\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\fcho_solve-f2pywrappers2.f90' to sources.\n",
      "  INFO: building extension \"fdistance\" sources\n",
      "  INFO: f2py options: ['--quiet']\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10\\fortranobject.c' to sources.\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10' to include_dirs.\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\fdistance-f2pywrappers2.f90' to sources.\n",
      "  INFO: building extension \"fkernels\" sources\n",
      "  INFO: f2py options: ['--quiet']\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10\\fortranobject.c' to sources.\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10' to include_dirs.\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\fkernels-f2pywrappers2.f90' to sources.\n",
      "  INFO: building extension \"fslatm\" sources\n",
      "  INFO: f2py options: ['--quiet']\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10\\fortranobject.c' to sources.\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10' to include_dirs.\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\fslatm-f2pywrappers2.f90' to sources.\n",
      "  INFO: building extension \"frepresentations\" sources\n",
      "  INFO: f2py options: ['--quiet']\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10\\fortranobject.c' to sources.\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10' to include_dirs.\n",
      "  INFO:   adding 'build\\src.win-amd64-3.10\\frepresentations-f2pywrappers2.f90' to sources.\n",
      "  INFO: build_src: building npy-pkg config files\n",
      "  C:\\Users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "    warnings.warn(\n",
      "  running build_py\n",
      "  creating build\\lib.win-amd64-3.10\n",
      "  creating build\\lib.win-amd64-3.10\\qml\n",
      "  copying qml\\alchemy.py -> build\\lib.win-amd64-3.10\\qml\n",
      "  copying qml\\arad.py -> build\\lib.win-amd64-3.10\\qml\n",
      "  copying qml\\compound.py -> build\\lib.win-amd64-3.10\\qml\n",
      "  copying qml\\data.py -> build\\lib.win-amd64-3.10\\qml\n",
      "  copying qml\\distance.py -> build\\lib.win-amd64-3.10\\qml\n",
      "  copying qml\\fchl.py -> build\\lib.win-amd64-3.10\\qml\n",
      "  copying qml\\kernels.py -> build\\lib.win-amd64-3.10\\qml\n",
      "  copying qml\\math.py -> build\\lib.win-amd64-3.10\\qml\n",
      "  copying qml\\representations.py -> build\\lib.win-amd64-3.10\\qml\n",
      "  copying qml\\slatm.py -> build\\lib.win-amd64-3.10\\qml\n",
      "  copying qml\\wrappers.py -> build\\lib.win-amd64-3.10\\qml\n",
      "  copying qml\\__init__.py -> build\\lib.win-amd64-3.10\\qml\n",
      "  running build_ext\n",
      "  INFO: No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  INFO: customize MSVCCompiler\n",
      "  INFO: customize MSVCCompiler using build_ext\n",
      "  INFO: CCompilerOpt.cc_test_flags[1029] : testing flags (/O2)\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  INFO: CCompilerOpt.cache_flush[825] : write cache to path -> C:\\Users\\gueha\\AppData\\Local\\Temp\\pip-install-uj3qr0yi\\qml_e26fd7e820ad46d6b9eee82a0b7bec8d\\build\\temp.win-amd64-3.10\\Release\\ccompiler_opt_cache_ext.py\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for qml\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\gueha\\anaconda3\\envs\\quantum\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\gueha\\\\AppData\\\\Local\\\\Temp\\\\pip-install-uj3qr0yi\\\\qml_e26fd7e820ad46d6b9eee82a0b7bec8d\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\gueha\\\\AppData\\\\Local\\\\Temp\\\\pip-install-uj3qr0yi\\\\qml_e26fd7e820ad46d6b9eee82a0b7bec8d\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\gueha\\AppData\\Local\\Temp\\pip-record-22xj62lg\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\gueha\\anaconda3\\envs\\quantum\\Include\\qml'\n",
      "         cwd: C:\\Users\\gueha\\AppData\\Local\\Temp\\pip-install-uj3qr0yi\\qml_e26fd7e820ad46d6b9eee82a0b7bec8d\\\n",
      "    Complete output (69 lines):\n",
      "    MKL-discover: MKLROOT was not set\n",
      "    running install\n",
      "    C:\\Users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "      warnings.warn(\n",
      "    running build\n",
      "    running config_cc\n",
      "    INFO: unifing config_cc, config, build_clib, build_ext, build commands --compiler options\n",
      "    running config_fc\n",
      "    INFO: unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options\n",
      "    running build_src\n",
      "    INFO: build_src\n",
      "    INFO: building extension \"ffchl_module\" sources\n",
      "    INFO: f2py options: ['--quiet']\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10\\fortranobject.c' to sources.\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10' to include_dirs.\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\ffchl_module-f2pywrappers2.f90' to sources.\n",
      "    INFO: building extension \"farad_kernels\" sources\n",
      "    INFO: f2py options: ['--quiet']\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10\\fortranobject.c' to sources.\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10' to include_dirs.\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\farad_kernels-f2pywrappers2.f90' to sources.\n",
      "    INFO: building extension \"fcho_solve\" sources\n",
      "    INFO: f2py options: ['--quiet']\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10\\fortranobject.c' to sources.\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10' to include_dirs.\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\fcho_solve-f2pywrappers2.f90' to sources.\n",
      "    INFO: building extension \"fdistance\" sources\n",
      "    INFO: f2py options: ['--quiet']\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10\\fortranobject.c' to sources.\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10' to include_dirs.\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\fdistance-f2pywrappers2.f90' to sources.\n",
      "    INFO: building extension \"fkernels\" sources\n",
      "    INFO: f2py options: ['--quiet']\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10\\fortranobject.c' to sources.\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10' to include_dirs.\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\fkernels-f2pywrappers2.f90' to sources.\n",
      "    INFO: building extension \"fslatm\" sources\n",
      "    INFO: f2py options: ['--quiet']\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10\\fortranobject.c' to sources.\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10' to include_dirs.\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\fslatm-f2pywrappers2.f90' to sources.\n",
      "    INFO: building extension \"frepresentations\" sources\n",
      "    INFO: f2py options: ['--quiet']\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10\\fortranobject.c' to sources.\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\build\\src.win-amd64-3.10' to include_dirs.\n",
      "    INFO:   adding 'build\\src.win-amd64-3.10\\frepresentations-f2pywrappers2.f90' to sources.\n",
      "    INFO: build_src: building npy-pkg config files\n",
      "    running build_py\n",
      "    creating build\\lib.win-amd64-3.10\n",
      "    creating build\\lib.win-amd64-3.10\\qml\n",
      "    copying qml\\alchemy.py -> build\\lib.win-amd64-3.10\\qml\n",
      "    copying qml\\arad.py -> build\\lib.win-amd64-3.10\\qml\n",
      "    copying qml\\compound.py -> build\\lib.win-amd64-3.10\\qml\n",
      "    copying qml\\data.py -> build\\lib.win-amd64-3.10\\qml\n",
      "    copying qml\\distance.py -> build\\lib.win-amd64-3.10\\qml\n",
      "    copying qml\\fchl.py -> build\\lib.win-amd64-3.10\\qml\n",
      "    copying qml\\kernels.py -> build\\lib.win-amd64-3.10\\qml\n",
      "    copying qml\\math.py -> build\\lib.win-amd64-3.10\\qml\n",
      "    copying qml\\representations.py -> build\\lib.win-amd64-3.10\\qml\n",
      "    copying qml\\slatm.py -> build\\lib.win-amd64-3.10\\qml\n",
      "    copying qml\\wrappers.py -> build\\lib.win-amd64-3.10\\qml\n",
      "    copying qml\\__init__.py -> build\\lib.win-amd64-3.10\\qml\n",
      "    running build_ext\n",
      "    INFO: No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    INFO: customize MSVCCompiler\n",
      "    INFO: customize MSVCCompiler using build_ext\n",
      "    INFO: CCompilerOpt.cc_test_flags[1029] : testing flags (/O2)\n",
      "    error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    INFO: CCompilerOpt.cache_flush[825] : write cache to path -> C:\\Users\\gueha\\AppData\\Local\\Temp\\pip-install-uj3qr0yi\\qml_e26fd7e820ad46d6b9eee82a0b7bec8d\\build\\temp.win-amd64-3.10\\Release\\ccompiler_opt_cache_ext.py\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\gueha\\anaconda3\\envs\\quantum\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\gueha\\\\AppData\\\\Local\\\\Temp\\\\pip-install-uj3qr0yi\\\\qml_e26fd7e820ad46d6b9eee82a0b7bec8d\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\gueha\\\\AppData\\\\Local\\\\Temp\\\\pip-install-uj3qr0yi\\\\qml_e26fd7e820ad46d6b9eee82a0b7bec8d\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\gueha\\AppData\\Local\\Temp\\pip-record-22xj62lg\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\gueha\\anaconda3\\envs\\quantum\\Include\\qml' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "!pip install pennylane\n",
    "!pip install pennylane-qiskit\n",
    "!pip install qiskit\n",
    "!pip install qml\n",
    "#!pip install tensorflow-macos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d99f2336",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "executionInfo": {
     "elapsed": 2001,
     "status": "error",
     "timestamp": 1651889014803,
     "user": {
      "displayName": "Glen Uehara",
      "userId": "02405348223145207511"
     },
     "user_tz": 420
    },
    "id": "d99f2336",
    "outputId": "dd085783-2902-47c2-8ab9-3fc06e5391f4"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "#import pickle\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.templates import RandomLayers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import scipy\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import time as ti\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers  import Conv2D, MaxPooling2D, Dense,Flatten, GRU, BatchNormalization, Conv1D, Dropout, Bidirectional,MaxPooling1D, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Lambda, BatchNormalization, Conv1D, GRU, TimeDistributed, Activation, Dense, Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "\n",
    "import qiskit\n",
    "import qiskit.providers.aer.noise as noise\n",
    "from qiskit import IBMQ\n",
    "\n",
    "## Local Definition \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57faad9a",
   "metadata": {
    "id": "57faad9a"
   },
   "outputs": [],
   "source": [
    "noise_mode = True # for running at QPU\n",
    "\n",
    "# Error probabilities\n",
    "prob_1 = 0.001  # 1-qubit gate\n",
    "prob_2 = 0.01   # 2-qubit gate\n",
    "\n",
    "# Depolarizing quantum errors\n",
    "error_1 = noise.depolarizing_error(prob_1, 1)\n",
    "error_2 = noise.depolarizing_error(prob_2, 2)\n",
    "\n",
    "# Add errors to noise model\n",
    "noise_model = noise.NoiseModel()\n",
    "noise_model.add_all_qubit_quantum_error(error_1, ['u1', 'u2', 'u3'])\n",
    "noise_model.add_all_qubit_quantum_error(error_2, ['cx'])\n",
    "\n",
    "n_w = 2 # numbers of wires def 2\n",
    "\n",
    "\n",
    "if  noise_mode == True:\n",
    "    #dev = qml.device('qiskit.aer', wires= n_w, noise_model=noise_model)\n",
    "    #dev = qml.device('qiskit.ibmq', wires=n_w, backend='ibmq_qasm_simulator', provider=provider)\n",
    "    dev = qml.device(\"default.mixed\", wires= n_w)\n",
    "else:\n",
    "    #local quantum simulator\n",
    "    dev = qml.device(\"default.qubit\", wires= n_w)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "669188af",
   "metadata": {
    "id": "669188af"
   },
   "outputs": [],
   "source": [
    "n_layers = 1\n",
    "\n",
    "# Random circuit parameters\n",
    "rand_params1 = np.random.uniform(high= 2 * np.pi, size=(n_layers, n_w)) # def 2, n_w = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7062f6dd",
   "metadata": {
    "id": "7062f6dd"
   },
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def circuit(p=0.01,phi=None):\n",
    "    # Encoding of 4 classical input values\n",
    "    for j in range(n_w):\n",
    "        qml.RY(np.pi * phi[j], wires=j)\n",
    "        qml.DepolarizingChannel(p, wires=j)\n",
    "\n",
    "    # Random quantum circuit\n",
    "    RandomLayers(rand_params1, wires=list(range(n_w)))\n",
    "\n",
    "    # Measurement producing 4 classical output values\n",
    "    return [qml.expval(qml.PauliZ(j)) for j in range(n_w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35eda3f7",
   "metadata": {
    "id": "35eda3f7"
   },
   "outputs": [],
   "source": [
    "def quanv(image, kr=2, p=0.01):\n",
    "    h_feat, w_feat, ch_n = image.shape\n",
    "    \"\"\"Convolves the input speech with many applications of the same quantum circuit.\"\"\"\n",
    "    out = np.zeros((h_feat//kr, w_feat//kr, n_w))\n",
    "\n",
    "    # Loop over the coordinates of the top-left pixel of 2X2 squares\n",
    "    for j in range(0, h_feat-1, kr):\n",
    "        for k in range(0, w_feat-1, kr):\n",
    "            # Process a squared 2x2 region of the image with a quantum circuit\n",
    "            q_results = circuit(\n",
    "                p,\n",
    "                # kernal 3 ## phi=[image[j, k, 0], image[j, k + 1, 0], image[j, k + 2, 0], image[j + 1, k, 0], \n",
    "                # image[j + 1, k + 1, 0], image[j + 1, k +2 , 0],image[j+2, k, 0], image[j+2, k+1, 0], image[j+2, k+2, 0]]\n",
    "                phi=[image[j, k, 0], image[j, k + 1, 0], image[j + 1, k, 0], image[j + 1, k + 1, 0]]\n",
    "            )\n",
    "            # Assign expectation values to different channels of the output pixel (j/2, k/2)\n",
    "            for c in range(n_w):\n",
    "                out[j // kr, k // kr, c] = q_results[c]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ff57390",
   "metadata": {
    "id": "0ff57390"
   },
   "outputs": [],
   "source": [
    "def gen_qspeech(x_train, x_valid, kr, p=0.01): # kernal size = 2x2 or 3x3\n",
    "    q_train = []\n",
    "    print(\"Quantum pre-processing of train Speech:\")\n",
    "    for idx, img in enumerate(x_train):\n",
    "        print(\"{}/{}        \".format(idx + 1, len(x_train)), end=\"\\r\")\n",
    "        q_train.append(quanv(img, kr, p))\n",
    "    q_train = np.asarray(q_train)\n",
    "\n",
    "    q_valid = []\n",
    "    print(\"\\nQuantum pre-processing of test Speech:\")\n",
    "    for idx, img in enumerate(x_valid):\n",
    "        print(\"{}/{}        \".format(idx + 1, len(x_valid)), end=\"\\r\")\n",
    "        q_valid.append(quanv(img, kr))\n",
    "    q_valid = np.asarray(q_valid)\n",
    "    \n",
    "    return q_train, q_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43a472f9",
   "metadata": {
    "id": "43a472f9"
   },
   "outputs": [],
   "source": [
    "def plot_acc_loss(q_history1, q_history2, q_history3, q_history4):\n",
    "\n",
    "    plt.figure()\n",
    "    plt.style.use(\"seaborn\")\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6, 9))\n",
    "\n",
    "    ax1.plot(q_history0.history[\"accuracy\"], \"-ok\", label=\"with p=0\")\n",
    "    ax1.plot(q_history1.history[\"accuracy\"], \"-ok\", label=\"with p=0.001\")\n",
    "    ax1.plot(q_history2.history[\"accuracy\"], \"-ob\", label=\"with p=0.01\")\n",
    "    ax1.plot(q_history3.history[\"accuracy\"], \"-og\", label=\"with p=0.1\")\n",
    "    ax1.plot(q_history4.history[\"accuracy\"], \"-og\", label=\"with p=0.2\")\n",
    "    ax1.set_ylabel(\"Train Accuracy\")\n",
    "    ax1.set_ylim([0, 1.2])\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(q_history0.history[\"val_accuracy\"], \"-ok\", label=\"with p=0\")\n",
    "    ax2.plot(q_history1.history[\"val_accuracy\"], \"-ok\", label=\"with p=0.001\")\n",
    "    ax2.plot(q_history2.history[\"val_accuracy\"], \"-ob\", label=\"with p=0.01\")\n",
    "    ax2.plot(q_history3.history[\"val_accuracy\"], \"-og\", label=\"with p=0.1\")\n",
    "    ax2.plot(q_history4.history[\"val_accuracy\"], \"-og\", label=\"with p=0.2\")\n",
    "    ax2.set_ylabel(\"Test Accuracy\")\n",
    "    ax1.set_ylim([0, 1.2])\n",
    "    #ax2.set_ylim(top=5.5)\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.legend()\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\"images/\"+ data_ix +\"_conv_speech_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ba7feb8",
   "metadata": {
    "id": "3ba7feb8"
   },
   "outputs": [],
   "source": [
    "def show_speech(x_train, q_train, use_ch, idx, tmp = \"tmp\"):\n",
    "    plt.figure()\n",
    "    plt.subplot(5, 1, 1)\n",
    "    if use_ch != True:\n",
    "        librosa.display.specshow(librosa.power_to_db(x_train[idx,:,:,0], ref=np.max))\n",
    "    else:\n",
    "        librosa.display.specshow(librosa.power_to_db(x_train[idx,:,:], ref=np.max))\n",
    "    plt.title('Input Speech: ' + tmp)\n",
    "\n",
    "    for i in range(4):\n",
    "        plt.subplot(5, 1, i+2)\n",
    "        librosa.display.specshow(librosa.power_to_db(q_train[idx,:,:,i], ref=np.max))\n",
    "        plt.title('Channel '+str(i+1)+': Quantum Compressed Speech')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"images/speech_encoder_\" + tmp + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bd8afad",
   "metadata": {
    "id": "5bd8afad"
   },
   "outputs": [],
   "source": [
    "def show_stft_speech(x_train, q_train, use_ch, idx, tmp = \"tmp\"):\n",
    "    plt.figure()\n",
    "    plt.subplot(5, 1, 1)\n",
    "    if use_ch != True:\n",
    "        librosa.display.specshow(librosa.amplitude_to_db(x_train[idx,:,:,0], ref=np.max))\n",
    "    else:\n",
    "        librosa.display.specshow(librosa.amplitude_to_db(x_train[idx,:,:,0], ref=np.max))\n",
    "    plt.title('Input Speech: ' + tmp)\n",
    "    \n",
    "    for i in range(4):\n",
    "        plt.subplot(5, 1, i+2)\n",
    "        librosa.display.specshow(librosa.amplitude_to_db(q_train[idx,:,:,1], ref=np.max))\n",
    "        plt.title('Channel '+str(i+1)+': Quantum Compressed Speech')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bafd69f",
   "metadata": {
    "id": "6bafd69f"
   },
   "outputs": [],
   "source": [
    "def dense_Model(x, labels):\n",
    "    \"\"\"Initializes and returns a custom Keras model\n",
    "    which is ready to be trained.\"\"\"\n",
    "    if len(x.shape) >= 3:\n",
    "        h_feat,w_feat,ch_size = x.shape\n",
    "        input_layer = keras.layers.Input(shape=(h_feat,w_feat,ch_size))\n",
    "    else:\n",
    "        h_feat,w_feat = x.shape\n",
    "        input_layer = keras.layers.Input(shape=(h_feat,w_feat))\n",
    "    model = keras.models.Sequential([\n",
    "        input_layer,\n",
    "        keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64),\n",
    "        keras.layers.Dense(64),\n",
    "        keras.layers.Dense(32),\n",
    "        keras.layers.Dense(len(labels), activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f1eb363",
   "metadata": {
    "id": "8f1eb363"
   },
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def cnn_Model(h_feat, w_feat, labels):       \n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(6, (2, 2), padding='valid', activation='relu', input_shape=(h_feat, w_feat, 1)))\n",
    "\t#model.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(len(labels), activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "557b0761",
   "metadata": {
    "id": "557b0761"
   },
   "outputs": [],
   "source": [
    "def attrnn_Model(x_in, labels, use_cnn=False, ablation = False):\n",
    "    # simple LSTM\n",
    "    rnn_func = L.LSTM\n",
    "    use_Unet = True\n",
    "\n",
    "    if len(x_in.shape) >= 3:\n",
    "        h_feat,w_feat,ch_size = x_in.shape\n",
    "        inputs = keras.layers.Input(shape=(h_feat, w_feat, ch_size))\n",
    "    else:\n",
    "        h_feat, w_feat = x_in.shape\n",
    "        inputs = keras.layers.Input(shape=(h_feat, w_feat))\n",
    "\n",
    "    inputs = L.Input(shape=(h_feat, w_feat, ch_size))\n",
    "\n",
    "    if use_cnn == True:\n",
    "        #x = L.Permute((2, 1, 3))(inputs)\n",
    "        # First conv block\n",
    "        x = L.Conv2D(\n",
    "            32,\n",
    "            (3, 3),\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"same\",\n",
    "            name=\"Conv1\",\n",
    "        )(inputs)\n",
    "        x = L.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
    "\n",
    "        # Second conv block\n",
    "        x = L.Conv2D(\n",
    "            64,\n",
    "            (3, 3),\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"same\",\n",
    "            name=\"Conv2\",\n",
    "        )(x)\n",
    "        x = L.MaxPooling2D((2, 2), name=\"pool2\")(x)\n",
    "    else:\n",
    "        x=inputs\n",
    "        \n",
    "    if ablation == True:\n",
    "        x = L.Conv2D(4, (1, 1), strides=(2, 2), activation='relu', padding='same', name='abla_conv')(x)\n",
    "        x = BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True)(x)\n",
    "    else:\n",
    "        x = BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True)(x)\n",
    "\n",
    "    # note that Melspectrogram puts the sequence in shape (batch_size, melDim, timeSteps, 1)\n",
    "    # we would rather have it the other way around for LSTMs\n",
    "\n",
    "    x = L.Permute((2, 1, 3))(x)\n",
    "\n",
    "    if use_Unet == True:\n",
    "        x = L.Conv2D(16, (5, 1), activation='relu', padding='same', name='ConvUp')(x)\n",
    "        up = L.BatchNormalization()(x)\n",
    "        x = L.Conv2D(32, (5, 1), activation='relu', padding='same', name='ConvDown1')(up)\n",
    "        x = L.BatchNormalization()(x)\n",
    "        x = L.Conv2D(16, (5, 1), activation='relu', padding='same', name='ConvDown2')(x)\n",
    "        down = L.BatchNormalization()(x)\n",
    "        merge = L.Concatenate(axis=3)([up,down])\n",
    "        x = L.Conv2D(1, (5, 1), activation='relu', padding='same', name='ConvMerge')(merge)\n",
    "        x = L.BatchNormalization()(x)\n",
    "    else:\n",
    "        x = L.Conv2D(10, (5, 1), activation='relu', padding='same')(x)\n",
    "        x = L.BatchNormalization()(x)\n",
    "        x = L.Conv2D(1, (5, 1), activation='relu', padding='same')(x)\n",
    "        x = L.BatchNormalization()(x)\n",
    "\n",
    "    x = L.Lambda(lambda q: K.squeeze(q, -1), name='squeeze_last_dim')(x)\n",
    "\n",
    "\n",
    "    x = L.Bidirectional(rnn_func(64, return_sequences=True)\n",
    "                        )(x)  # [b_s, seq_len, vec_dim]\n",
    "    x = L.Bidirectional(rnn_func(64, return_sequences=True)\n",
    "                        )(x)  # [b_s, seq_len, vec_dim]\n",
    "\n",
    "    xFirst = L.Lambda(lambda q: q[:, -1])(x)  # [b_s, vec_dim]\n",
    "    query = L.Dense(128)(xFirst)\n",
    "\n",
    "    # dot product attention\n",
    "    attScores = L.Dot(axes=[1, 2])([query, x])\n",
    "    attScores = L.Softmax(name='attSoftmax')(attScores)  # [b_s, seq_len]\n",
    "\n",
    "    # rescale sequence\n",
    "    attVector = L.Dot(axes=[1, 1])([attScores, x])  # [b_s, vec_dim]\n",
    "\n",
    "    x = L.Dense(64, activation='relu')(attVector)\n",
    "    x = L.Dense(32)(x)\n",
    "\n",
    "    output = L.Dense(len(labels), activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(\n",
    "        optimizer=SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e12f2589",
   "metadata": {
    "id": "e12f2589"
   },
   "outputs": [],
   "source": [
    "#%cd speech_quantum_dl\n",
    "#from google.colab import drive\n",
    "\n",
    "#drive.mount('/content/drive/', force_remount=True)\n",
    "#%cd '/content/drive/My Drive/QuantumTeams/Pennylane Speech/'\n",
    "#from google.colab import drive\n",
    "#drive.mount(\"/content/drive\", force_remount=True)\n",
    "#!cd /content/drive/My\\ Drive/Michael\\ COVID\\ audio\\ data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b96a125",
   "metadata": {
    "id": "7b96a125"
   },
   "outputs": [],
   "source": [
    "data_ix = ti.strftime(\"%m%d_%H%M\")\n",
    "SAVE_PATH = \"data_quantum/\" # Data saving folder\n",
    "#train_audio_path = '/content/drive/My Drive/QuantumTeams/Pennylane Speech'\n",
    "train_audio_path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06d71f67",
   "metadata": {
    "id": "06d71f67"
   },
   "outputs": [],
   "source": [
    "def gen_mel(labels, train_audio_path, sr, port):\n",
    "    all_wave = []\n",
    "    all_label = []\n",
    "    maxL=0\n",
    "    minL=358321\n",
    "    for label in tqdm(labels):\n",
    "        waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n",
    "        for num, wav in enumerate(waves, 0):\n",
    "            #print(wav)\n",
    "            y, _ = librosa.load(train_audio_path + '/' + label + '/' + wav, sr = sr)\n",
    "            if len(y)>maxL:\n",
    "                maxL =len(y)\n",
    "            if len(y)<minL:\n",
    "                minL =len(y)\n",
    "            if num % port ==0:   # take 1/port samples\n",
    "                if(len(y)>= 16000) :\n",
    "                    mel_feat = librosa.feature.melspectrogram(y=y[0:16000], sr=sr, n_fft=1024, hop_length=128, center=True, power=1.0, n_mels=60, fmin=40.0, fmax=sr/2) #y[0:sr]\n",
    "                    all_wave.append(np.expand_dims(mel_feat, axis=2))\n",
    "                    all_label.append(label)\n",
    "    print(maxL)\n",
    "    print(minL)\n",
    "    return all_wave, all_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f15e5581-e36b-4f2d-8ce5-b08756957351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_stft(labels, train_audio_path, sr, port):\n",
    "    all_wave = []\n",
    "    all_label = []\n",
    "    windowLength = 1024\n",
    "    window = scipy.signal.hamming(windowLength, sym=False)\n",
    "    overlap      = round(0.25 * windowLength) # overlap of 75%\n",
    "    for label in tqdm(labels):\n",
    "        waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n",
    "        for num, wav in enumerate(waves, 0):\n",
    "            y, _ = librosa.load(train_audio_path + '/' + label + '/' + wav, sr = sr)\n",
    "            if num % port ==0:   # take 1/port samples\n",
    "                if(len(y)== sr) :\n",
    "                    stft_feat = librosa.stft(y, n_fft=windowLength, win_length=windowLength, hop_length=128,\n",
    "                            window=window, center=True)\n",
    "                    all_wave.append(np.expand_dims(stft_feat, axis=2))\n",
    "                    all_label.append(label)\n",
    "    \n",
    "    return all_wave, all_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "583fd784",
   "metadata": {
    "id": "583fd784"
   },
   "outputs": [],
   "source": [
    "#want to change eps, bsize, sr to optimize\n",
    "eps = 250\n",
    "bsize = 16\n",
    "sr = 48000\n",
    "net = 1\n",
    "mel = 0\n",
    "quanv_mode = 1\n",
    "# Quantum Layers\n",
    "ql0 = 1\n",
    "ql1 = 1\n",
    "ql2 = 1\n",
    "ql3 = 1\n",
    "ql4 = 1\n",
    "port = 1\n",
    "labels = [\n",
    "    'covid_segment','healthy_segment'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65d08b9c",
   "metadata": {
    "id": "65d08b9c"
   },
   "outputs": [],
   "source": [
    "def gen_train(labels, train_audio_path, sr, port):\n",
    "    all_wave, all_label = gen_mel(labels, train_audio_path, sr, port)\n",
    "    #all_wave, all_label = gen_stft(labels, train_audio_path, sr, port)\n",
    "\n",
    "    label_enconder = LabelEncoder()\n",
    "    y = label_enconder.fit_transform(all_label)\n",
    "    classes = list(label_enconder.classes_)\n",
    "    y = keras.utils.to_categorical(y, num_classes=len(labels))\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(np.array(all_wave),np.array(y),stratify=y,test_size = 0.2,random_state=777,shuffle=True)\n",
    "    h_feat, w_feat, _ = x_train[0].shape\n",
    "    np.save(SAVE_PATH + \"21n_x_train_speech.npy\", x_train)\n",
    "    np.save(SAVE_PATH + \"21n_x_test_speech.npy\", x_valid)\n",
    "    np.save(SAVE_PATH + \"21n_y_train_speech.npy\", y_train)\n",
    "    np.save(SAVE_PATH + \"21n_y_test_speech.npy\", y_valid)\n",
    "    print(\"===== Shape\", h_feat, w_feat)\n",
    "\n",
    "    return x_train, x_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f341f496",
   "metadata": {
    "id": "f341f496"
   },
   "outputs": [],
   "source": [
    "def gen_quanv(x_train, x_valid, kr, p):\n",
    "    print(\"Kernal = \", kr)\n",
    "    q_train, q_valid = gen_qspeech(x_train, x_valid, kr, p)\n",
    "\n",
    "    np.save(SAVE_PATH + \"2\"+str(p) + \"n_q_train_speech.npy\", q_train)\n",
    "    np.save(SAVE_PATH + \"2\"+str(p) + \"n_q_test_speech.npy\", q_valid)\n",
    "\n",
    "    return q_train, q_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d709104d",
   "metadata": {
    "id": "d709104d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if mel == 1:\n",
    "    x_train, x_valid, y_train, y_valid = gen_train(labels, train_audio_path, sr, port) \n",
    "else:\n",
    "    x_train = np.load(SAVE_PATH + \"41n_x_train_speech.npy\")\n",
    "    x_valid = np.load(SAVE_PATH + \"41n_x_test_speech.npy\")\n",
    "    y_train = np.load(SAVE_PATH + \"41n_y_train_speech.npy\")\n",
    "    y_valid = np.load(SAVE_PATH + \"41n_y_test_speech.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e6c55ae",
   "metadata": {
    "id": "9e6c55ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain len: 688\n",
      "XValid len: 172\n",
      "Valid count\n",
      "Healthy: 88\n",
      "Covid: 84\n",
      "Total: 172\n",
      "Train count\n",
      "Healthy: 353\n",
      "Covid: 335\n",
      "Total: 688\n"
     ]
    }
   ],
   "source": [
    "print(\"Xtrain len:\", len(x_train))\n",
    "print(\"XValid len:\", len(x_valid))\n",
    "\n",
    "zero_val = 0\n",
    "one_val = 0\n",
    "for i in y_valid:\n",
    "    # get(key, default) falls back to default if key is not present\n",
    "    if i[1] == 1:\n",
    "        one_val = one_val + 1\n",
    "    else:\n",
    "        zero_val = zero_val + 1\n",
    "\n",
    "print(\"Valid count\")\n",
    "print(\"Healthy:\", one_val)\n",
    "print(\"Covid:\", zero_val)\n",
    "print(\"Total:\", one_val+zero_val)\n",
    "\n",
    "zero_val = 0\n",
    "one_val = 0\n",
    "for i in y_train:\n",
    "    # get(key, default) falls back to default if key is not present\n",
    "    if i[1] == 1:\n",
    "        one_val = one_val + 1\n",
    "    else:\n",
    "        zero_val = zero_val + 1\n",
    "\n",
    "print(\"Train count\")\n",
    "print(\"Healthy:\", one_val)\n",
    "print(\"Covid:\", zero_val)\n",
    "print(\"Total:\", one_val+zero_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c18b504a",
   "metadata": {
    "id": "c18b504a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernal =  2\n",
      "Quantum pre-processing of train Speech:\n",
      "688/688        \n",
      "Quantum pre-processing of test Speech:\n",
      "Kernal =  2    \n",
      "Quantum pre-processing of train Speech:\n",
      "688/688        \n",
      "Quantum pre-processing of test Speech:\n",
      "Kernal =  2    \n",
      "Quantum pre-processing of train Speech:\n",
      "688/688        \n",
      "Quantum pre-processing of test Speech:\n",
      "Kernal =  2    \n",
      "Quantum pre-processing of train Speech:\n",
      "688/688        \n",
      "Quantum pre-processing of test Speech:\n",
      "Kernal =  2    \n",
      "Quantum pre-processing of train Speech:\n",
      "688/688        \n",
      "Quantum pre-processing of test Speech:\n",
      "172/172        \r"
     ]
    }
   ],
   "source": [
    "if quanv_mode == 1:\n",
    "    if ql0 == 1:\n",
    "        q_train0, q_valid0 = gen_quanv(x_train, x_valid, 2,0) \n",
    "    if ql1 == 1:\n",
    "        q_train1, q_valid1 = gen_quanv(x_train, x_valid, 2,0.001) \n",
    "    if ql2 == 1:\n",
    "        q_train2, q_valid2 = gen_quanv(x_train, x_valid, 2,0.01)\n",
    "    if ql3 == 1:\n",
    "        q_train3, q_valid3 = gen_quanv(x_train, x_valid, 2,0.1) \n",
    "    if ql4 == 1:\n",
    "        q_train4, q_valid4 = gen_quanv(x_train, x_valid, 2,0.2) \n",
    "else:\n",
    "    if ql0 == 1:\n",
    "        q_train0 = np.load(SAVE_PATH + \"20n_q_train_speech.npy\")\n",
    "        q_valid0 = np.load(SAVE_PATH + \"20n_q_test_speech.npy\")\n",
    "    if ql1 == 1:\n",
    "        q_train1 = np.load(SAVE_PATH + \"20.001n_q_train_speech.npy\")\n",
    "        q_valid1 = np.load(SAVE_PATH + \"20.001n_q_test_speech.npy\")\n",
    "    if ql2 == 1:\n",
    "        q_train2 = np.load(SAVE_PATH + \"20.01n_q_train_speech.npy\")\n",
    "        q_valid2 = np.load(SAVE_PATH + \"20.01n_q_test_speech.npy\")\n",
    "    if ql3 == 1:\n",
    "        q_train3 = np.load(SAVE_PATH + \"20.1n_q_train_speech.npy\")\n",
    "        q_valid3 = np.load(SAVE_PATH + \"20.1n_q_test_speech.npy\")\n",
    "    if ql4 == 1:\n",
    "        q_train4 = np.load(SAVE_PATH + \"20.2n_q_train_speech.npy\")\n",
    "        q_valid4 = np.load(SAVE_PATH + \"20.2n_q_test_speech.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8207f4b7",
   "metadata": {
    "id": "8207f4b7"
   },
   "outputs": [],
   "source": [
    "def search(list, platform):\n",
    "    for i in range(len(list)):\n",
    "        if list[i] == platform:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6a03854",
   "metadata": {
    "id": "e6a03854"
   },
   "outputs": [],
   "source": [
    "def searchIndex(list, platform):\n",
    "    for i in range(len(list)):\n",
    "        if list[i] == platform:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e91f0197",
   "metadata": {
    "id": "e91f0197"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthy_segment\n",
      "covid_segment\n"
     ]
    }
   ],
   "source": [
    "idx=[]\n",
    "thislist = []\n",
    "ii = 0\n",
    "for jj in range(len(y_train)):\n",
    "    label=labels[searchIndex(y_train[jj],1)]\n",
    "    if search(thislist, label) == False:\n",
    "        thislist.append(label)\n",
    "        print(label)\n",
    "        idx.append(jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e562dc6c",
   "metadata": {
    "id": "e562dc6c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.39187076e-05, -1.02721244e-05, -1.11247515e-05, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-1.76186606e-04, -1.50398723e-04, -5.40204192e-05, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-1.41717813e-02, -6.21717412e-02, -7.35780573e-02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [-1.76274080e-06, -5.28925934e-08, -1.65266378e-09, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-1.61681508e-06, -4.82893725e-08, -1.52642832e-09, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-1.13286175e-06, -3.40393520e-08, -2.08947526e-10, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "librosa.amplitude_to_db(q_train1[2,:,:,1], ref=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf39b443",
   "metadata": {
    "id": "bf39b443"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for i in range(4):\n",
    "    plt.subplot(5, 1, i+2)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(q_train1[0,:,:,1], ref=np.max))\n",
    "    plt.title('Channel '+str(i+1)+': Quantum Compressed Speech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6b80e9f",
   "metadata": {
    "id": "e6b80e9f"
   },
   "outputs": [],
   "source": [
    "#S_db=librosa.amplitude_to_db(x_train[0,:,:,0],ref=np.max)\n",
    "#plt.figure()\n",
    "#librosa.display.specshow(S_db)\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5f92b51",
   "metadata": {
    "id": "a5f92b51"
   },
   "outputs": [],
   "source": [
    "#for jj in range(len(idx)):\n",
    "    #show_speech(x_train, q_train, False, idx[jj], tmp = labels[searchIndex(y_train[jj],1)])\n",
    "    #show_stft_speech(x_train, q_train, False, idx[jj], tmp = labels[searchIndex(y_train[jj],1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7eeb5b0a",
   "metadata": {
    "id": "7eeb5b0a"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=90)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    #%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12ab5c06",
   "metadata": {
    "id": "12ab5c06"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "import scipy\n",
    "window = scipy.signal.hamming(1024, sym=False)\n",
    "\n",
    "rev3 = librosa.feature.inverse.mel_to_audio(x_train[0,:,:,0], sr=sr, n_fft=1024,\n",
    "                                                    hop_length=128,\n",
    "                                                    win_length=1024, window=window,\n",
    "                                                    center=True, pad_mode='reflect', power=1.0, n_iter=32, length=None)\n",
    "\n",
    "ipd.Audio(data=rev3, rate=sr) # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a1ca788",
   "metadata": {
    "id": "8a1ca788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages (2.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e06570a",
   "metadata": {
    "id": "4690617f"
   },
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "## For Quanv Exp.\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', \n",
    "                           verbose=1, patience=10, min_delta=0.0001)\n",
    "\n",
    "checkpoint = ModelCheckpoint('checkpoints/best_base_demo2.hdf5', monitor='val_accuracy', \n",
    "                             verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "if net == 0:\n",
    "    modelx = dense_Model(x_train[0], labels)\n",
    "elif net == 1:\n",
    "    modelx = attrnn_Model(x_train[0], labels)\n",
    "\n",
    "modelx.summary()\n",
    "\n",
    "x_history = modelx.fit(\n",
    "    x=x_train, \n",
    "    y=y_train,\n",
    "    epochs=eps, \n",
    "    callbacks=[checkpoint], \n",
    "    batch_size=bsize, \n",
    "    validation_data=(x_valid,y_valid)\n",
    ")\n",
    "\n",
    "\n",
    "keras.models.save_model(modelx, 'checkpoints/'+ data_ix + '_base_model_demo2.hdf5') \n",
    "modelx.save('checkpoints/'+ data_ix + '_base_demo2.hdf5')\n",
    "\n",
    "print(\"=== Batch Size: \", bsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b0f2c58",
   "metadata": {
    "id": "2b0f2c58"
   },
   "outputs": [],
   "source": [
    "y_test=np.argmax(y_valid, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f507d7",
   "metadata": {
    "id": "16c77438"
   },
   "source": [
    "y_pred=modelx.predict(x_valid)\n",
    "y_pred1 = (y_pred > 0.5) \n",
    "y_pred=modelx.predict(x_train)\n",
    "y_pred2 = (y_pred > 0.5) \n",
    "\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "print('\\Base Train Accuracy: {:.2f}\\n'.format(accuracy_score(y_train, y_pred2)))\n",
    "print('\\Base Accuracy: {:.2f}\\n'.format(accuracy_score(y_valid, y_pred1)))\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "plot_confusion_matrix(cm , \n",
    "                      normalize    = False,\n",
    "                      target_names = labels,\n",
    "                      title        = \"Baseline Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02e3c61",
   "metadata": {
    "id": "262cf63d"
   },
   "source": [
    "modelx=keras.models.load_model('checkpoints/best_base_demo2.hdf5') \n",
    "y_pred=modelx.predict(x_valid)\n",
    "y_pred1 = (y_pred > 0.5) \n",
    "y_pred=modelx.predict(x_train)\n",
    "y_pred2 = (y_pred > 0.5) \n",
    "\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "print('\\Base Train Accuracy: {:.2f}\\n'.format(accuracy_score(y_train, y_pred2)))\n",
    "print('\\Base Accuracy: {:.2f}\\n'.format(accuracy_score(y_valid, y_pred1)))\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "plot_confusion_matrix(cm , \n",
    "                      normalize    = False,\n",
    "                      target_names = labels,\n",
    "                      title        = \"Best Baseline Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0fc10c",
   "metadata": {
    "id": "9e974489"
   },
   "source": [
    "## For Quanv Exp.\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', \n",
    "                           verbose=1, patience=10, min_delta=0.0001)\n",
    "\n",
    "checkpoint = ModelCheckpoint('checkpoints/best_conv_demo2.hdf5', monitor='val_accuracy', \n",
    "                             verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "if net == 0:\n",
    "    modelc= dense_Model(x_train[0], labels)\n",
    "elif net == 1:\n",
    "    modelc = attrnn_Model(x_train[0], labels,use_cnn=True)\n",
    "    \n",
    "\n",
    "#modelc = keras.models.load_model('checkpoints/0910_1843_base_sp2cmd.hdf5')\n",
    "modelc.summary()\n",
    "\n",
    "c_history = modelc.fit(\n",
    "    x=x_train, \n",
    "    y=y_train,\n",
    "    epochs=eps, \n",
    "    callbacks=[checkpoint], \n",
    "    batch_size=bsize, \n",
    "    validation_data=(x_valid,y_valid)\n",
    ")\n",
    "\n",
    "keras.models.save_model(modelc, 'checkpoints/'+ data_ix + '_conv_model_demo2.hdf5') \n",
    "modelc.save('checkpoints/'+ data_ix + '_conv_demo2.hdf5')\n",
    "\n",
    "print(\"=== Batch Size: \", bsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb69e00f",
   "metadata": {
    "id": "1702a867"
   },
   "source": [
    "y_pred=modelc.predict(x_valid)\n",
    "y_pred1 = (y_pred > 0.5) \n",
    "y_pred=modelc.predict(x_train)\n",
    "y_pred2 = (y_pred > 0.5) \n",
    "\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "y_test=np.argmax(y_valid, axis=1)\n",
    "\n",
    "print('\\nConv Train Accuracy: {:.2f}\\n'.format(accuracy_score(y_train, y_pred2)))\n",
    "print('\\nConv Accuracy: {:.2f}\\n'.format(accuracy_score(y_valid, y_pred1)))\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plot_confusion_matrix(cm , \n",
    "                      normalize    = False,\n",
    "                      target_names = labels,\n",
    "                      title        = \"Conv Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39c23dc",
   "metadata": {
    "id": "cef76dfa"
   },
   "source": [
    "modelc=keras.models.load_model('checkpoints/best_conv_demo2.hdf5') \n",
    "y_pred=modelc.predict(x_valid)\n",
    "y_pred1 = (y_pred > 0.5) \n",
    "y_pred=modelc.predict(x_train)\n",
    "y_pred2 = (y_pred > 0.5) \n",
    "\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "y_test=np.argmax(y_valid, axis=1)\n",
    "\n",
    "print('\\nConv Train Accuracy: {:.2f}\\n'.format(accuracy_score(y_train, y_pred2)))\n",
    "print('\\nConv Accuracy: {:.2f}\\n'.format(accuracy_score(y_valid, y_pred1)))\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plot_confusion_matrix(cm , \n",
    "                      normalize    = False,\n",
    "                      target_names = labels,\n",
    "                      title        = \"Best Conv Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3b082ad8-7d54-4e0d-b2c4-f361c3e9740b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 30, 63, 2)]  0           []                               \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 30, 63, 2)   8           ['input_8[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " permute_3 (Permute)            (None, 63, 30, 2)    0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " ConvUp (Conv2D)                (None, 63, 30, 16)   176         ['permute_3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 63, 30, 16)  64          ['ConvUp[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " ConvDown1 (Conv2D)             (None, 63, 30, 32)   2592        ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 63, 30, 32)  128         ['ConvDown1[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " ConvDown2 (Conv2D)             (None, 63, 30, 16)   2576        ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 63, 30, 16)  64          ['ConvDown2[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 63, 30, 32)   0           ['batch_normalization_16[0][0]', \n",
      "                                                                  'batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " ConvMerge (Conv2D)             (None, 63, 30, 1)    161         ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 63, 30, 1)   4           ['ConvMerge[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " squeeze_last_dim (Lambda)      (None, 63, 30)       0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " bidirectional_6 (Bidirectional  (None, 63, 128)     48640       ['squeeze_last_dim[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_7 (Bidirectional  (None, 63, 128)     98816       ['bidirectional_6[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, 128)          0           ['bidirectional_7[0][0]']        \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 128)          16512       ['lambda_3[0][0]']               \n",
      "                                                                                                  \n",
      " dot_6 (Dot)                    (None, 63)           0           ['dense_9[0][0]',                \n",
      "                                                                  'bidirectional_7[0][0]']        \n",
      "                                                                                                  \n",
      " attSoftmax (Softmax)           (None, 63)           0           ['dot_6[0][0]']                  \n",
      "                                                                                                  \n",
      " dot_7 (Dot)                    (None, 128)          0           ['attSoftmax[0][0]',             \n",
      "                                                                  'bidirectional_7[0][0]']        \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 64)           8256        ['dot_7[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 32)           2080        ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 2)            66          ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 180,143\n",
      "Trainable params: 180,009\n",
      "Non-trainable params: 134\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gueha\\anaconda3\\envs\\quantum\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.6960 - accuracy: 0.5349\n",
      "Epoch 1: val_accuracy improved from -inf to 0.48837, saving model to checkpoints\\best_quanv_demo20.hdf5\n",
      "43/43 [==============================] - 15s 151ms/step - loss: 0.6960 - accuracy: 0.5349 - val_loss: 0.7133 - val_accuracy: 0.4884\n",
      "Epoch 2/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6827 - accuracy: 0.5610\n",
      "Epoch 2: val_accuracy did not improve from 0.48837\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.6827 - accuracy: 0.5610 - val_loss: 0.6942 - val_accuracy: 0.4709\n",
      "Epoch 3/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6672 - accuracy: 0.5916\n",
      "Epoch 3: val_accuracy improved from 0.48837 to 0.51163, saving model to checkpoints\\best_quanv_demo20.hdf5\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.6672 - accuracy: 0.5916 - val_loss: 0.7191 - val_accuracy: 0.5116\n",
      "Epoch 4/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6505 - accuracy: 0.6076\n",
      "Epoch 4: val_accuracy improved from 0.51163 to 0.52326, saving model to checkpoints\\best_quanv_demo20.hdf5\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.6505 - accuracy: 0.6076 - val_loss: 0.6986 - val_accuracy: 0.5233\n",
      "Epoch 5/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6408 - accuracy: 0.6250\n",
      "Epoch 5: val_accuracy did not improve from 0.52326\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.6408 - accuracy: 0.6250 - val_loss: 0.7464 - val_accuracy: 0.5174\n",
      "Epoch 6/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6298 - accuracy: 0.6177\n",
      "Epoch 6: val_accuracy improved from 0.52326 to 0.56395, saving model to checkpoints\\best_quanv_demo20.hdf5\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.6298 - accuracy: 0.6177 - val_loss: 0.6857 - val_accuracy: 0.5640\n",
      "Epoch 7/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6026 - accuracy: 0.6265\n",
      "Epoch 7: val_accuracy did not improve from 0.56395\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.6026 - accuracy: 0.6265 - val_loss: 0.7459 - val_accuracy: 0.5407\n",
      "Epoch 8/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5906 - accuracy: 0.6701\n",
      "Epoch 8: val_accuracy improved from 0.56395 to 0.59884, saving model to checkpoints\\best_quanv_demo20.hdf5\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.5906 - accuracy: 0.6701 - val_loss: 0.6795 - val_accuracy: 0.5988\n",
      "Epoch 9/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5584 - accuracy: 0.7064\n",
      "Epoch 9: val_accuracy did not improve from 0.59884\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.5584 - accuracy: 0.7064 - val_loss: 0.7617 - val_accuracy: 0.5465\n",
      "Epoch 10/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5886 - accuracy: 0.6613\n",
      "Epoch 10: val_accuracy improved from 0.59884 to 0.61047, saving model to checkpoints\\best_quanv_demo20.hdf5\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.5886 - accuracy: 0.6613 - val_loss: 0.6641 - val_accuracy: 0.6105\n",
      "Epoch 11/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5165 - accuracy: 0.7326\n",
      "Epoch 11: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.5165 - accuracy: 0.7326 - val_loss: 0.7672 - val_accuracy: 0.5349\n",
      "Epoch 12/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5212 - accuracy: 0.7078\n",
      "Epoch 12: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.5212 - accuracy: 0.7078 - val_loss: 0.7635 - val_accuracy: 0.5698\n",
      "Epoch 13/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4716 - accuracy: 0.7602\n",
      "Epoch 13: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 97ms/step - loss: 0.4716 - accuracy: 0.7602 - val_loss: 0.8809 - val_accuracy: 0.5814\n",
      "Epoch 14/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4634 - accuracy: 0.7558\n",
      "Epoch 14: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.4634 - accuracy: 0.7558 - val_loss: 0.8236 - val_accuracy: 0.6047\n",
      "Epoch 15/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4514 - accuracy: 0.7602\n",
      "Epoch 15: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.4514 - accuracy: 0.7602 - val_loss: 0.8072 - val_accuracy: 0.5698\n",
      "Epoch 16/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4501 - accuracy: 0.7834\n",
      "Epoch 16: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.4501 - accuracy: 0.7834 - val_loss: 0.8369 - val_accuracy: 0.6105\n",
      "Epoch 17/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4147 - accuracy: 0.7863\n",
      "Epoch 17: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.4147 - accuracy: 0.7863 - val_loss: 0.9092 - val_accuracy: 0.5465\n",
      "Epoch 18/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4127 - accuracy: 0.7922\n",
      "Epoch 18: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.4127 - accuracy: 0.7922 - val_loss: 0.9046 - val_accuracy: 0.5698\n",
      "Epoch 19/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4074 - accuracy: 0.7951\n",
      "Epoch 19: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.4074 - accuracy: 0.7951 - val_loss: 1.0839 - val_accuracy: 0.5988\n",
      "Epoch 20/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3504 - accuracy: 0.8343\n",
      "Epoch 20: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.3504 - accuracy: 0.8343 - val_loss: 0.9293 - val_accuracy: 0.5291\n",
      "Epoch 21/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3560 - accuracy: 0.8198\n",
      "Epoch 21: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.3560 - accuracy: 0.8198 - val_loss: 1.2113 - val_accuracy: 0.5698\n",
      "Epoch 22/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3001 - accuracy: 0.8634\n",
      "Epoch 22: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.3001 - accuracy: 0.8634 - val_loss: 1.0698 - val_accuracy: 0.5640\n",
      "Epoch 23/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3251 - accuracy: 0.8517\n",
      "Epoch 23: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.3251 - accuracy: 0.8517 - val_loss: 0.8328 - val_accuracy: 0.5930\n",
      "Epoch 24/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2999 - accuracy: 0.8605\n",
      "Epoch 24: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.2999 - accuracy: 0.8605 - val_loss: 1.2703 - val_accuracy: 0.5523\n",
      "Epoch 25/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2983 - accuracy: 0.8648\n",
      "Epoch 25: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.2983 - accuracy: 0.8648 - val_loss: 1.1803 - val_accuracy: 0.5698\n",
      "Epoch 26/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3587 - accuracy: 0.8299\n",
      "Epoch 26: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 97ms/step - loss: 0.3587 - accuracy: 0.8299 - val_loss: 1.0914 - val_accuracy: 0.5465\n",
      "Epoch 27/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2370 - accuracy: 0.8997\n",
      "Epoch 27: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.2370 - accuracy: 0.8997 - val_loss: 1.2248 - val_accuracy: 0.5814\n",
      "Epoch 28/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2668 - accuracy: 0.8619\n",
      "Epoch 28: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.2668 - accuracy: 0.8619 - val_loss: 1.0976 - val_accuracy: 0.6105\n",
      "Epoch 29/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2773 - accuracy: 0.8823\n",
      "Epoch 29: val_accuracy did not improve from 0.61047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 4s 94ms/step - loss: 0.2773 - accuracy: 0.8823 - val_loss: 1.2068 - val_accuracy: 0.5407\n",
      "Epoch 30/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1630 - accuracy: 0.9273\n",
      "Epoch 30: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.1630 - accuracy: 0.9273 - val_loss: 1.6491 - val_accuracy: 0.5756\n",
      "Epoch 31/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1698 - accuracy: 0.9186\n",
      "Epoch 31: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.1698 - accuracy: 0.9186 - val_loss: 1.5208 - val_accuracy: 0.5349\n",
      "Epoch 32/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2189 - accuracy: 0.9041\n",
      "Epoch 32: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2189 - accuracy: 0.9041 - val_loss: 1.7170 - val_accuracy: 0.5291\n",
      "Epoch 33/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3163 - accuracy: 0.8765\n",
      "Epoch 33: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.3163 - accuracy: 0.8765 - val_loss: 0.8930 - val_accuracy: 0.5640\n",
      "Epoch 34/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2229 - accuracy: 0.9041\n",
      "Epoch 34: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.2229 - accuracy: 0.9041 - val_loss: 1.2968 - val_accuracy: 0.5581\n",
      "Epoch 35/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.9244\n",
      "Epoch 35: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.1775 - accuracy: 0.9244 - val_loss: 1.5874 - val_accuracy: 0.5291\n",
      "Epoch 36/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2395 - accuracy: 0.8895\n",
      "Epoch 36: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.2395 - accuracy: 0.8895 - val_loss: 1.2264 - val_accuracy: 0.5988\n",
      "Epoch 37/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1854 - accuracy: 0.9215\n",
      "Epoch 37: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.1854 - accuracy: 0.9215 - val_loss: 1.6399 - val_accuracy: 0.5814\n",
      "Epoch 38/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2627 - accuracy: 0.8881\n",
      "Epoch 38: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.2627 - accuracy: 0.8881 - val_loss: 0.9960 - val_accuracy: 0.5581\n",
      "Epoch 39/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2501 - accuracy: 0.8808\n",
      "Epoch 39: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.2501 - accuracy: 0.8808 - val_loss: 1.4326 - val_accuracy: 0.5291\n",
      "Epoch 40/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2371 - accuracy: 0.9041\n",
      "Epoch 40: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.2371 - accuracy: 0.9041 - val_loss: 1.4009 - val_accuracy: 0.5872\n",
      "Epoch 41/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.9375\n",
      "Epoch 41: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.1387 - accuracy: 0.9375 - val_loss: 1.8392 - val_accuracy: 0.5640\n",
      "Epoch 42/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1430 - accuracy: 0.9375\n",
      "Epoch 42: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.1430 - accuracy: 0.9375 - val_loss: 1.4813 - val_accuracy: 0.5407\n",
      "Epoch 43/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1877 - accuracy: 0.9244\n",
      "Epoch 43: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.1877 - accuracy: 0.9244 - val_loss: 1.3651 - val_accuracy: 0.5465\n",
      "Epoch 44/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1505 - accuracy: 0.9390\n",
      "Epoch 44: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.1505 - accuracy: 0.9390 - val_loss: 1.5653 - val_accuracy: 0.5814\n",
      "Epoch 45/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1684 - accuracy: 0.9142\n",
      "Epoch 45: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.1684 - accuracy: 0.9142 - val_loss: 1.3966 - val_accuracy: 0.5930\n",
      "Epoch 46/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1528 - accuracy: 0.9375\n",
      "Epoch 46: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.1528 - accuracy: 0.9375 - val_loss: 1.7474 - val_accuracy: 0.5058\n",
      "Epoch 47/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1524 - accuracy: 0.9390\n",
      "Epoch 47: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.1524 - accuracy: 0.9390 - val_loss: 1.4571 - val_accuracy: 0.5814\n",
      "Epoch 48/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.9593\n",
      "Epoch 48: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0844 - accuracy: 0.9593 - val_loss: 1.9272 - val_accuracy: 0.5523\n",
      "Epoch 49/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9724\n",
      "Epoch 49: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0507 - accuracy: 0.9724 - val_loss: 1.9979 - val_accuracy: 0.5465\n",
      "Epoch 50/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.9491\n",
      "Epoch 50: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0975 - accuracy: 0.9491 - val_loss: 2.0437 - val_accuracy: 0.5640\n",
      "Epoch 51/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.9651\n",
      "Epoch 51: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0654 - accuracy: 0.9651 - val_loss: 2.1348 - val_accuracy: 0.5814\n",
      "Epoch 52/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1004 - accuracy: 0.9491\n",
      "Epoch 52: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.1004 - accuracy: 0.9491 - val_loss: 1.9111 - val_accuracy: 0.5872\n",
      "Epoch 53/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1430 - accuracy: 0.9491\n",
      "Epoch 53: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.1430 - accuracy: 0.9491 - val_loss: 1.7887 - val_accuracy: 0.5581\n",
      "Epoch 54/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1146 - accuracy: 0.9448\n",
      "Epoch 54: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.1146 - accuracy: 0.9448 - val_loss: 1.8801 - val_accuracy: 0.5930\n",
      "Epoch 55/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9506\n",
      "Epoch 55: val_accuracy did not improve from 0.61047\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.1200 - accuracy: 0.9506 - val_loss: 1.6678 - val_accuracy: 0.5814\n",
      "Epoch 56/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1498 - accuracy: 0.9302\n",
      "Epoch 56: val_accuracy improved from 0.61047 to 0.61628, saving model to checkpoints\\best_quanv_demo20.hdf5\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.1498 - accuracy: 0.9302 - val_loss: 1.4270 - val_accuracy: 0.6163\n",
      "Epoch 57/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1318 - accuracy: 0.9506\n",
      "Epoch 57: val_accuracy did not improve from 0.61628\n",
      "43/43 [==============================] - 4s 97ms/step - loss: 0.1318 - accuracy: 0.9506 - val_loss: 1.4138 - val_accuracy: 0.5640\n",
      "Epoch 58/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.9651\n",
      "Epoch 58: val_accuracy did not improve from 0.61628\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0719 - accuracy: 0.9651 - val_loss: 1.9346 - val_accuracy: 0.5872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9709\n",
      "Epoch 59: val_accuracy did not improve from 0.61628\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0536 - accuracy: 0.9709 - val_loss: 2.0783 - val_accuracy: 0.5988\n",
      "Epoch 60/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1260 - accuracy: 0.9564\n",
      "Epoch 60: val_accuracy improved from 0.61628 to 0.63372, saving model to checkpoints\\best_quanv_demo20.hdf5\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.1260 - accuracy: 0.9564 - val_loss: 1.5608 - val_accuracy: 0.6337\n",
      "Epoch 61/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.9273\n",
      "Epoch 61: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 97ms/step - loss: 0.1726 - accuracy: 0.9273 - val_loss: 1.4891 - val_accuracy: 0.5233\n",
      "Epoch 62/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 0.9622\n",
      "Epoch 62: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0988 - accuracy: 0.9622 - val_loss: 1.6996 - val_accuracy: 0.6163\n",
      "Epoch 63/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 0.9491\n",
      "Epoch 63: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.1134 - accuracy: 0.9491 - val_loss: 1.7733 - val_accuracy: 0.5523\n",
      "Epoch 64/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0649 - accuracy: 0.9637\n",
      "Epoch 64: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0649 - accuracy: 0.9637 - val_loss: 1.9854 - val_accuracy: 0.5698\n",
      "Epoch 65/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9826\n",
      "Epoch 65: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0369 - accuracy: 0.9826 - val_loss: 2.3788 - val_accuracy: 0.5698\n",
      "Epoch 66/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9666\n",
      "Epoch 66: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0739 - accuracy: 0.9666 - val_loss: 2.2857 - val_accuracy: 0.5872\n",
      "Epoch 67/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.9448\n",
      "Epoch 67: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.1096 - accuracy: 0.9448 - val_loss: 1.6471 - val_accuracy: 0.6105\n",
      "Epoch 68/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1212 - accuracy: 0.9433\n",
      "Epoch 68: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.1212 - accuracy: 0.9433 - val_loss: 1.5099 - val_accuracy: 0.5988\n",
      "Epoch 69/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9520\n",
      "Epoch 69: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0965 - accuracy: 0.9520 - val_loss: 1.6329 - val_accuracy: 0.6221\n",
      "Epoch 70/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9738\n",
      "Epoch 70: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0567 - accuracy: 0.9738 - val_loss: 1.6966 - val_accuracy: 0.6047\n",
      "Epoch 71/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9767\n",
      "Epoch 71: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0461 - accuracy: 0.9767 - val_loss: 1.8542 - val_accuracy: 0.5698\n",
      "Epoch 72/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9753\n",
      "Epoch 72: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0492 - accuracy: 0.9753 - val_loss: 2.0346 - val_accuracy: 0.5814\n",
      "Epoch 73/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1630 - accuracy: 0.9346\n",
      "Epoch 73: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.1630 - accuracy: 0.9346 - val_loss: 1.5715 - val_accuracy: 0.5814\n",
      "Epoch 74/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1383 - accuracy: 0.9404\n",
      "Epoch 74: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.1383 - accuracy: 0.9404 - val_loss: 1.5647 - val_accuracy: 0.5814\n",
      "Epoch 75/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.9535\n",
      "Epoch 75: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0909 - accuracy: 0.9535 - val_loss: 1.5953 - val_accuracy: 0.5756\n",
      "Epoch 76/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.9520\n",
      "Epoch 76: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.1041 - accuracy: 0.9520 - val_loss: 1.6690 - val_accuracy: 0.6279\n",
      "Epoch 77/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9695\n",
      "Epoch 77: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0642 - accuracy: 0.9695 - val_loss: 1.7026 - val_accuracy: 0.6047\n",
      "Epoch 78/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0760 - accuracy: 0.9651\n",
      "Epoch 78: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0760 - accuracy: 0.9651 - val_loss: 1.6319 - val_accuracy: 0.6163\n",
      "Epoch 79/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0649 - accuracy: 0.9680\n",
      "Epoch 79: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0649 - accuracy: 0.9680 - val_loss: 1.7857 - val_accuracy: 0.6163\n",
      "Epoch 80/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2008 - accuracy: 0.9172\n",
      "Epoch 80: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.2008 - accuracy: 0.9172 - val_loss: 1.4104 - val_accuracy: 0.5872\n",
      "Epoch 81/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 0.9622\n",
      "Epoch 81: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0814 - accuracy: 0.9622 - val_loss: 1.7022 - val_accuracy: 0.5814\n",
      "Epoch 82/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9637\n",
      "Epoch 82: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0652 - accuracy: 0.9637 - val_loss: 1.8912 - val_accuracy: 0.5523\n",
      "Epoch 83/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9709\n",
      "Epoch 83: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0450 - accuracy: 0.9709 - val_loss: 2.1326 - val_accuracy: 0.5756\n",
      "Epoch 84/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9767\n",
      "Epoch 84: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0447 - accuracy: 0.9767 - val_loss: 2.2675 - val_accuracy: 0.5349\n",
      "Epoch 85/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9738\n",
      "Epoch 85: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0460 - accuracy: 0.9738 - val_loss: 2.3719 - val_accuracy: 0.5640\n",
      "Epoch 86/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9738\n",
      "Epoch 86: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0632 - accuracy: 0.9738 - val_loss: 2.2469 - val_accuracy: 0.5988\n",
      "Epoch 87/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.9709\n",
      "Epoch 87: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0891 - accuracy: 0.9709 - val_loss: 2.1644 - val_accuracy: 0.5523\n",
      "Epoch 88/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.9608\n",
      "Epoch 88: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.1007 - accuracy: 0.9608 - val_loss: 2.1578 - val_accuracy: 0.5465\n",
      "Epoch 89/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1766 - accuracy: 0.9259\n",
      "Epoch 89: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.1766 - accuracy: 0.9259 - val_loss: 1.5487 - val_accuracy: 0.5814\n",
      "Epoch 90/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1276 - accuracy: 0.9462\n",
      "Epoch 90: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.1276 - accuracy: 0.9462 - val_loss: 1.5105 - val_accuracy: 0.6163\n",
      "Epoch 91/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 0.9680\n",
      "Epoch 91: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0573 - accuracy: 0.9680 - val_loss: 1.8190 - val_accuracy: 0.5581\n",
      "Epoch 92/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9811\n",
      "Epoch 92: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0339 - accuracy: 0.9811 - val_loss: 2.1371 - val_accuracy: 0.5465\n",
      "Epoch 93/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.9738\n",
      "Epoch 93: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0378 - accuracy: 0.9738 - val_loss: 2.4786 - val_accuracy: 0.5465\n",
      "Epoch 94/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1122 - accuracy: 0.9593\n",
      "Epoch 94: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.1122 - accuracy: 0.9593 - val_loss: 2.0248 - val_accuracy: 0.5814\n",
      "Epoch 95/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1898 - accuracy: 0.9360\n",
      "Epoch 95: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.1898 - accuracy: 0.9360 - val_loss: 1.5408 - val_accuracy: 0.5523\n",
      "Epoch 96/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9709\n",
      "Epoch 96: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0648 - accuracy: 0.9709 - val_loss: 2.1520 - val_accuracy: 0.5465\n",
      "Epoch 97/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.9593\n",
      "Epoch 97: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0878 - accuracy: 0.9593 - val_loss: 1.8278 - val_accuracy: 0.5872\n",
      "Epoch 98/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.9709\n",
      "Epoch 98: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0858 - accuracy: 0.9709 - val_loss: 2.0643 - val_accuracy: 0.5872\n",
      "Epoch 99/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9637\n",
      "Epoch 99: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0728 - accuracy: 0.9637 - val_loss: 1.9465 - val_accuracy: 0.5988\n",
      "Epoch 100/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.9709\n",
      "Epoch 100: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0673 - accuracy: 0.9709 - val_loss: 1.9370 - val_accuracy: 0.5698\n",
      "Epoch 101/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9738\n",
      "Epoch 101: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0528 - accuracy: 0.9738 - val_loss: 1.8789 - val_accuracy: 0.6279\n",
      "Epoch 102/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9811\n",
      "Epoch 102: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0442 - accuracy: 0.9811 - val_loss: 2.0034 - val_accuracy: 0.6163\n",
      "Epoch 103/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9826\n",
      "Epoch 103: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0305 - accuracy: 0.9826 - val_loss: 2.2409 - val_accuracy: 0.5988\n",
      "Epoch 104/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9811\n",
      "Epoch 104: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0301 - accuracy: 0.9811 - val_loss: 2.1902 - val_accuracy: 0.6105\n",
      "Epoch 105/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9826\n",
      "Epoch 105: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.0263 - accuracy: 0.9826 - val_loss: 2.2614 - val_accuracy: 0.6105\n",
      "Epoch 106/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9797\n",
      "Epoch 106: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0268 - accuracy: 0.9797 - val_loss: 2.3071 - val_accuracy: 0.6163\n",
      "Epoch 107/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9855\n",
      "Epoch 107: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0265 - accuracy: 0.9855 - val_loss: 2.4284 - val_accuracy: 0.6337\n",
      "Epoch 108/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9797\n",
      "Epoch 108: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0246 - accuracy: 0.9797 - val_loss: 2.4736 - val_accuracy: 0.6163\n",
      "Epoch 109/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9855\n",
      "Epoch 109: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0250 - accuracy: 0.9855 - val_loss: 2.4905 - val_accuracy: 0.6105\n",
      "Epoch 110/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9840\n",
      "Epoch 110: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0258 - accuracy: 0.9840 - val_loss: 2.5333 - val_accuracy: 0.6047\n",
      "Epoch 111/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9797\n",
      "Epoch 111: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0250 - accuracy: 0.9797 - val_loss: 2.5340 - val_accuracy: 0.5988\n",
      "Epoch 112/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9811\n",
      "Epoch 112: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0254 - accuracy: 0.9811 - val_loss: 2.5097 - val_accuracy: 0.5988\n",
      "Epoch 113/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9855\n",
      "Epoch 113: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0250 - accuracy: 0.9855 - val_loss: 2.5550 - val_accuracy: 0.6047\n",
      "Epoch 114/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9826\n",
      "Epoch 114: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0237 - accuracy: 0.9826 - val_loss: 2.5888 - val_accuracy: 0.5988\n",
      "Epoch 115/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9826\n",
      "Epoch 115: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0252 - accuracy: 0.9826 - val_loss: 2.6264 - val_accuracy: 0.5872\n",
      "Epoch 116/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9782\n",
      "Epoch 116: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0413 - accuracy: 0.9782 - val_loss: 2.6625 - val_accuracy: 0.5988\n",
      "Epoch 117/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 0.9724\n",
      "Epoch 117: val_accuracy did not improve from 0.63372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0871 - accuracy: 0.9724 - val_loss: 2.0836 - val_accuracy: 0.6047\n",
      "Epoch 118/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.9622\n",
      "Epoch 118: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0826 - accuracy: 0.9622 - val_loss: 1.9661 - val_accuracy: 0.6105\n",
      "Epoch 119/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9840\n",
      "Epoch 119: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0358 - accuracy: 0.9840 - val_loss: 2.3940 - val_accuracy: 0.5698\n",
      "Epoch 120/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9753\n",
      "Epoch 120: val_accuracy improved from 0.63372 to 0.65116, saving model to checkpoints\\best_quanv_demo20.hdf5\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0551 - accuracy: 0.9753 - val_loss: 1.7728 - val_accuracy: 0.6512\n",
      "Epoch 121/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 0.9709\n",
      "Epoch 121: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.0573 - accuracy: 0.9709 - val_loss: 1.9775 - val_accuracy: 0.5988\n",
      "Epoch 122/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9738\n",
      "Epoch 122: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0538 - accuracy: 0.9738 - val_loss: 2.3526 - val_accuracy: 0.5814\n",
      "Epoch 123/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9826\n",
      "Epoch 123: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0364 - accuracy: 0.9826 - val_loss: 2.2136 - val_accuracy: 0.6395\n",
      "Epoch 124/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9811\n",
      "Epoch 124: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0302 - accuracy: 0.9811 - val_loss: 2.3185 - val_accuracy: 0.6337\n",
      "Epoch 125/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9855\n",
      "Epoch 125: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0248 - accuracy: 0.9855 - val_loss: 2.4151 - val_accuracy: 0.6221\n",
      "Epoch 126/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9913\n",
      "Epoch 126: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0214 - accuracy: 0.9913 - val_loss: 2.4522 - val_accuracy: 0.6221\n",
      "Epoch 127/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9927\n",
      "Epoch 127: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 2.6219 - val_accuracy: 0.6163\n",
      "Epoch 128/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9884\n",
      "Epoch 128: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0253 - accuracy: 0.9884 - val_loss: 2.6170 - val_accuracy: 0.6395\n",
      "Epoch 129/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9898\n",
      "Epoch 129: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0201 - accuracy: 0.9898 - val_loss: 2.6874 - val_accuracy: 0.6221\n",
      "Epoch 130/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9927\n",
      "Epoch 130: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0166 - accuracy: 0.9927 - val_loss: 2.7162 - val_accuracy: 0.6105\n",
      "Epoch 131/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9913\n",
      "Epoch 131: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0228 - accuracy: 0.9913 - val_loss: 2.8428 - val_accuracy: 0.6047\n",
      "Epoch 132/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.9738\n",
      "Epoch 132: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0976 - accuracy: 0.9738 - val_loss: 1.9392 - val_accuracy: 0.6395\n",
      "Epoch 133/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.9709\n",
      "Epoch 133: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0808 - accuracy: 0.9709 - val_loss: 1.9945 - val_accuracy: 0.5872\n",
      "Epoch 134/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9840\n",
      "Epoch 134: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0477 - accuracy: 0.9840 - val_loss: 2.0118 - val_accuracy: 0.6105\n",
      "Epoch 135/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.9637\n",
      "Epoch 135: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0950 - accuracy: 0.9637 - val_loss: 2.1080 - val_accuracy: 0.5814\n",
      "Epoch 136/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0478 - accuracy: 0.9797\n",
      "Epoch 136: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0478 - accuracy: 0.9797 - val_loss: 2.4593 - val_accuracy: 0.5988\n",
      "Epoch 137/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9942\n",
      "Epoch 137: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0209 - accuracy: 0.9942 - val_loss: 2.8368 - val_accuracy: 0.5698\n",
      "Epoch 138/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9927\n",
      "Epoch 138: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0192 - accuracy: 0.9927 - val_loss: 3.0200 - val_accuracy: 0.5930\n",
      "Epoch 139/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9927\n",
      "Epoch 139: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0177 - accuracy: 0.9927 - val_loss: 3.0783 - val_accuracy: 0.5930\n",
      "Epoch 140/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9884\n",
      "Epoch 140: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.0231 - accuracy: 0.9884 - val_loss: 3.2122 - val_accuracy: 0.5814\n",
      "Epoch 141/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9898\n",
      "Epoch 141: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0207 - accuracy: 0.9898 - val_loss: 3.0835 - val_accuracy: 0.5698\n",
      "Epoch 142/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9898\n",
      "Epoch 142: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0276 - accuracy: 0.9898 - val_loss: 3.0032 - val_accuracy: 0.5465\n",
      "Epoch 143/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9913\n",
      "Epoch 143: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0213 - accuracy: 0.9913 - val_loss: 3.3631 - val_accuracy: 0.5814\n",
      "Epoch 144/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9956\n",
      "Epoch 144: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0111 - accuracy: 0.9956 - val_loss: 3.4222 - val_accuracy: 0.5756\n",
      "Epoch 145/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.9767\n",
      "Epoch 145: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0630 - accuracy: 0.9767 - val_loss: 2.9574 - val_accuracy: 0.5814\n",
      "Epoch 146/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9782\n",
      "Epoch 146: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0497 - accuracy: 0.9782 - val_loss: 2.8062 - val_accuracy: 0.5291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9826\n",
      "Epoch 147: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0468 - accuracy: 0.9826 - val_loss: 2.9656 - val_accuracy: 0.5233\n",
      "Epoch 148/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9811\n",
      "Epoch 148: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0459 - accuracy: 0.9811 - val_loss: 2.4101 - val_accuracy: 0.5523\n",
      "Epoch 149/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9927\n",
      "Epoch 149: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0155 - accuracy: 0.9927 - val_loss: 2.5979 - val_accuracy: 0.5407\n",
      "Epoch 150/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9971\n",
      "Epoch 150: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 2.8253 - val_accuracy: 0.5523\n",
      "Epoch 151/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9956\n",
      "Epoch 151: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0101 - accuracy: 0.9956 - val_loss: 3.1289 - val_accuracy: 0.5349\n",
      "Epoch 152/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9942\n",
      "Epoch 152: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0160 - accuracy: 0.9942 - val_loss: 3.1263 - val_accuracy: 0.5407\n",
      "Epoch 153/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9956\n",
      "Epoch 153: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.0071 - accuracy: 0.9956 - val_loss: 3.2140 - val_accuracy: 0.5407\n",
      "Epoch 154/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9971\n",
      "Epoch 154: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 3.1796 - val_accuracy: 0.5465\n",
      "Epoch 155/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9942\n",
      "Epoch 155: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0113 - accuracy: 0.9942 - val_loss: 3.3610 - val_accuracy: 0.5291\n",
      "Epoch 156/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9797\n",
      "Epoch 156: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0602 - accuracy: 0.9797 - val_loss: 2.2299 - val_accuracy: 0.6105\n",
      "Epoch 157/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9637\n",
      "Epoch 157: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.1124 - accuracy: 0.9637 - val_loss: 2.0189 - val_accuracy: 0.5523\n",
      "Epoch 158/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.9695\n",
      "Epoch 158: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0620 - accuracy: 0.9695 - val_loss: 2.1529 - val_accuracy: 0.5640\n",
      "Epoch 159/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9927\n",
      "Epoch 159: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0263 - accuracy: 0.9927 - val_loss: 2.6434 - val_accuracy: 0.5407\n",
      "Epoch 160/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9985\n",
      "Epoch 160: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0101 - accuracy: 0.9985 - val_loss: 2.7116 - val_accuracy: 0.5407\n",
      "Epoch 161/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9985\n",
      "Epoch 161: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 2.9829 - val_accuracy: 0.5349\n",
      "Epoch 162/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9985\n",
      "Epoch 162: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 3.1082 - val_accuracy: 0.5349\n",
      "Epoch 163/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9971\n",
      "Epoch 163: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0079 - accuracy: 0.9971 - val_loss: 3.1829 - val_accuracy: 0.5407\n",
      "Epoch 164/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9956\n",
      "Epoch 164: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.0094 - accuracy: 0.9956 - val_loss: 3.2081 - val_accuracy: 0.5407\n",
      "Epoch 165/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9956\n",
      "Epoch 165: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0062 - accuracy: 0.9956 - val_loss: 3.2680 - val_accuracy: 0.5349\n",
      "Epoch 166/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9971\n",
      "Epoch 166: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0053 - accuracy: 0.9971 - val_loss: 3.3273 - val_accuracy: 0.5349\n",
      "Epoch 167/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 167: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.3812 - val_accuracy: 0.5407\n",
      "Epoch 168/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9956\n",
      "Epoch 168: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0077 - accuracy: 0.9956 - val_loss: 3.4203 - val_accuracy: 0.5349\n",
      "Epoch 169/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9898\n",
      "Epoch 169: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0255 - accuracy: 0.9898 - val_loss: 3.3409 - val_accuracy: 0.5349\n",
      "Epoch 170/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9840\n",
      "Epoch 170: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0404 - accuracy: 0.9840 - val_loss: 2.9424 - val_accuracy: 0.5407\n",
      "Epoch 171/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9884\n",
      "Epoch 171: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0302 - accuracy: 0.9884 - val_loss: 3.0039 - val_accuracy: 0.5581\n",
      "Epoch 172/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.9709\n",
      "Epoch 172: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0717 - accuracy: 0.9709 - val_loss: 2.5806 - val_accuracy: 0.5698\n",
      "Epoch 173/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9695\n",
      "Epoch 173: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0674 - accuracy: 0.9695 - val_loss: 2.1388 - val_accuracy: 0.5581\n",
      "Epoch 174/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.9753\n",
      "Epoch 174: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0758 - accuracy: 0.9753 - val_loss: 2.1664 - val_accuracy: 0.5872\n",
      "Epoch 175/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.9869\n",
      "Epoch 175: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0282 - accuracy: 0.9869 - val_loss: 2.0734 - val_accuracy: 0.5872\n",
      "Epoch 176/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9956\n",
      "Epoch 176: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0091 - accuracy: 0.9956 - val_loss: 2.3218 - val_accuracy: 0.5756\n",
      "Epoch 177/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9971\n",
      "Epoch 177: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0063 - accuracy: 0.9971 - val_loss: 2.4895 - val_accuracy: 0.5756\n",
      "Epoch 178/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9971\n",
      "Epoch 178: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 2.5212 - val_accuracy: 0.5756\n",
      "Epoch 179/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9942\n",
      "Epoch 179: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0122 - accuracy: 0.9942 - val_loss: 2.5358 - val_accuracy: 0.5581\n",
      "Epoch 180/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9971\n",
      "Epoch 180: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 2.7701 - val_accuracy: 0.5291\n",
      "Epoch 181/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9942\n",
      "Epoch 181: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 2.5044 - val_accuracy: 0.5872\n",
      "Epoch 182/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9840\n",
      "Epoch 182: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0447 - accuracy: 0.9840 - val_loss: 2.4784 - val_accuracy: 0.6163\n",
      "Epoch 183/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9884\n",
      "Epoch 183: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0495 - accuracy: 0.9884 - val_loss: 2.3201 - val_accuracy: 0.5930\n",
      "Epoch 184/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.9680\n",
      "Epoch 184: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0928 - accuracy: 0.9680 - val_loss: 1.8178 - val_accuracy: 0.5930\n",
      "Epoch 185/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9942\n",
      "Epoch 185: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0319 - accuracy: 0.9942 - val_loss: 2.2573 - val_accuracy: 0.5581\n",
      "Epoch 186/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9956\n",
      "Epoch 186: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0104 - accuracy: 0.9956 - val_loss: 2.5079 - val_accuracy: 0.5581\n",
      "Epoch 187/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9985\n",
      "Epoch 187: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 2.6982 - val_accuracy: 0.5465\n",
      "Epoch 188/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9985\n",
      "Epoch 188: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 2.8024 - val_accuracy: 0.5523\n",
      "Epoch 189/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9985\n",
      "Epoch 189: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 2.8096 - val_accuracy: 0.5523\n",
      "Epoch 190/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 190: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9406 - val_accuracy: 0.5523\n",
      "Epoch 191/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 191: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.0108 - val_accuracy: 0.5523\n",
      "Epoch 192/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 6.5302e-04 - accuracy: 1.0000\n",
      "Epoch 192: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 6.5302e-04 - accuracy: 1.0000 - val_loss: 3.0383 - val_accuracy: 0.5581\n",
      "Epoch 193/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 193: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.0551 - val_accuracy: 0.5581\n",
      "Epoch 194/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9985\n",
      "Epoch 194: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0032 - accuracy: 0.9985 - val_loss: 3.1620 - val_accuracy: 0.5581\n",
      "Epoch 195/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9956\n",
      "Epoch 195: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 3.1383 - val_accuracy: 0.5640\n",
      "Epoch 196/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9971\n",
      "Epoch 196: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 3.0061 - val_accuracy: 0.5465\n",
      "Epoch 197/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9985\n",
      "Epoch 197: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0028 - accuracy: 0.9985 - val_loss: 3.0006 - val_accuracy: 0.5640\n",
      "Epoch 198/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 198: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.0148 - val_accuracy: 0.5756\n",
      "Epoch 199/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9985\n",
      "Epoch 199: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0032 - accuracy: 0.9985 - val_loss: 3.1412 - val_accuracy: 0.5581\n",
      "Epoch 200/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 200: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 3.0837 - val_accuracy: 0.5756\n",
      "Epoch 201/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9971\n",
      "Epoch 201: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 3.0815 - val_accuracy: 0.5756\n",
      "Epoch 202/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9985\n",
      "Epoch 202: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0115 - accuracy: 0.9985 - val_loss: 3.1461 - val_accuracy: 0.5872\n",
      "Epoch 203/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 203: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.1407 - val_accuracy: 0.5930\n",
      "Epoch 204/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 204: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.1552 - val_accuracy: 0.5814\n",
      "Epoch 205/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9956\n",
      "Epoch 205: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0060 - accuracy: 0.9956 - val_loss: 2.9550 - val_accuracy: 0.5581\n",
      "Epoch 206/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9898\n",
      "Epoch 206: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0422 - accuracy: 0.9898 - val_loss: 2.5872 - val_accuracy: 0.6105\n",
      "Epoch 207/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9971\n",
      "Epoch 207: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0163 - accuracy: 0.9971 - val_loss: 2.4004 - val_accuracy: 0.6047\n",
      "Epoch 208/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 208: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.5786 - val_accuracy: 0.5756\n",
      "Epoch 209/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9985\n",
      "Epoch 209: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 2.7358 - val_accuracy: 0.5640\n",
      "Epoch 210/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9884\n",
      "Epoch 210: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0270 - accuracy: 0.9884 - val_loss: 3.0402 - val_accuracy: 0.5698\n",
      "Epoch 211/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9811\n",
      "Epoch 211: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0563 - accuracy: 0.9811 - val_loss: 2.7891 - val_accuracy: 0.5291\n",
      "Epoch 212/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9927\n",
      "Epoch 212: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0245 - accuracy: 0.9927 - val_loss: 2.5178 - val_accuracy: 0.5523\n",
      "Epoch 213/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9913\n",
      "Epoch 213: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.0218 - accuracy: 0.9913 - val_loss: 2.4296 - val_accuracy: 0.5698\n",
      "Epoch 214/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9971\n",
      "Epoch 214: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 2.5680 - val_accuracy: 0.6047\n",
      "Epoch 215/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 215: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.7782 - val_accuracy: 0.5814\n",
      "Epoch 216/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9971\n",
      "Epoch 216: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0046 - accuracy: 0.9971 - val_loss: 2.9204 - val_accuracy: 0.5523\n",
      "Epoch 217/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 217: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.9874 - val_accuracy: 0.5581\n",
      "Epoch 218/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 218: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.1223 - val_accuracy: 0.5465\n",
      "Epoch 219/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9985\n",
      "Epoch 219: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0022 - accuracy: 0.9985 - val_loss: 3.1731 - val_accuracy: 0.5640\n",
      "Epoch 220/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.2957e-04 - accuracy: 1.0000\n",
      "Epoch 220: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 5.2957e-04 - accuracy: 1.0000 - val_loss: 3.1940 - val_accuracy: 0.5698\n",
      "Epoch 221/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.0008e-04 - accuracy: 1.0000\n",
      "Epoch 221: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 3.0008e-04 - accuracy: 1.0000 - val_loss: 3.2208 - val_accuracy: 0.5698\n",
      "Epoch 222/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.5055e-04 - accuracy: 1.0000\n",
      "Epoch 222: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 2.5055e-04 - accuracy: 1.0000 - val_loss: 3.2330 - val_accuracy: 0.5814\n",
      "Epoch 223/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.1874e-04 - accuracy: 1.0000\n",
      "Epoch 223: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 3.1874e-04 - accuracy: 1.0000 - val_loss: 3.2509 - val_accuracy: 0.5814\n",
      "Epoch 224/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.1962e-04 - accuracy: 1.0000\n",
      "Epoch 224: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 2.1962e-04 - accuracy: 1.0000 - val_loss: 3.2718 - val_accuracy: 0.5814\n",
      "Epoch 225/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.6554e-04 - accuracy: 1.0000\n",
      "Epoch 225: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 1.6554e-04 - accuracy: 1.0000 - val_loss: 3.2908 - val_accuracy: 0.5756\n",
      "Epoch 226/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.2417e-04 - accuracy: 1.0000\n",
      "Epoch 226: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 3.2417e-04 - accuracy: 1.0000 - val_loss: 3.3020 - val_accuracy: 0.5756\n",
      "Epoch 227/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.7485e-04 - accuracy: 1.0000\n",
      "Epoch 227: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 1.7485e-04 - accuracy: 1.0000 - val_loss: 3.3202 - val_accuracy: 0.5756\n",
      "Epoch 228/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.5629e-04 - accuracy: 1.0000\n",
      "Epoch 228: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 1.5629e-04 - accuracy: 1.0000 - val_loss: 3.3341 - val_accuracy: 0.5814\n",
      "Epoch 229/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.6978e-04 - accuracy: 1.0000\n",
      "Epoch 229: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 1.6978e-04 - accuracy: 1.0000 - val_loss: 3.3515 - val_accuracy: 0.5814\n",
      "Epoch 230/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.2082e-04 - accuracy: 1.0000\n",
      "Epoch 230: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 1.2082e-04 - accuracy: 1.0000 - val_loss: 3.3637 - val_accuracy: 0.5814\n",
      "Epoch 231/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.2824e-04 - accuracy: 1.0000\n",
      "Epoch 231: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 1.2824e-04 - accuracy: 1.0000 - val_loss: 3.3736 - val_accuracy: 0.5814\n",
      "Epoch 232/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 9.8109e-05 - accuracy: 1.0000\n",
      "Epoch 232: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 9.8109e-05 - accuracy: 1.0000 - val_loss: 3.3865 - val_accuracy: 0.5814\n",
      "Epoch 233/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.8304e-04 - accuracy: 1.0000\n",
      "Epoch 233: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 2.8304e-04 - accuracy: 1.0000 - val_loss: 3.3897 - val_accuracy: 0.5698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.1508e-04 - accuracy: 1.0000\n",
      "Epoch 234: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 3.1508e-04 - accuracy: 1.0000 - val_loss: 3.4542 - val_accuracy: 0.5698\n",
      "Epoch 235/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.1601e-04 - accuracy: 1.0000\n",
      "Epoch 235: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 1.1601e-04 - accuracy: 1.0000 - val_loss: 3.5409 - val_accuracy: 0.5756\n",
      "Epoch 236/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.1905e-04 - accuracy: 1.0000\n",
      "Epoch 236: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 1.1905e-04 - accuracy: 1.0000 - val_loss: 3.5442 - val_accuracy: 0.5698\n",
      "Epoch 237/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 8.6989e-05 - accuracy: 1.0000\n",
      "Epoch 237: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 8.6989e-05 - accuracy: 1.0000 - val_loss: 3.5469 - val_accuracy: 0.5756\n",
      "Epoch 238/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.4206e-04 - accuracy: 1.0000\n",
      "Epoch 238: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 1.4206e-04 - accuracy: 1.0000 - val_loss: 3.5591 - val_accuracy: 0.5640\n",
      "Epoch 239/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.9914e-04 - accuracy: 1.0000\n",
      "Epoch 239: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 3s 75ms/step - loss: 1.9914e-04 - accuracy: 1.0000 - val_loss: 3.5639 - val_accuracy: 0.5698\n",
      "Epoch 240/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 6.7298e-05 - accuracy: 1.0000\n",
      "Epoch 240: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 6.7298e-05 - accuracy: 1.0000 - val_loss: 3.5765 - val_accuracy: 0.5698\n",
      "Epoch 241/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.4274e-05 - accuracy: 1.0000\n",
      "Epoch 241: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 5.4274e-05 - accuracy: 1.0000 - val_loss: 3.5824 - val_accuracy: 0.5698\n",
      "Epoch 242/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 9.9964e-05 - accuracy: 1.0000\n",
      "Epoch 242: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 9.9964e-05 - accuracy: 1.0000 - val_loss: 3.5920 - val_accuracy: 0.5698\n",
      "Epoch 243/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 6.6681e-05 - accuracy: 1.0000\n",
      "Epoch 243: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 6.6681e-05 - accuracy: 1.0000 - val_loss: 3.5965 - val_accuracy: 0.5756\n",
      "Epoch 244/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.5925e-04 - accuracy: 1.0000\n",
      "Epoch 244: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 1.5925e-04 - accuracy: 1.0000 - val_loss: 3.6367 - val_accuracy: 0.5640\n",
      "Epoch 245/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.0859e-05 - accuracy: 1.0000\n",
      "Epoch 245: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 97ms/step - loss: 5.0859e-05 - accuracy: 1.0000 - val_loss: 3.6428 - val_accuracy: 0.5640\n",
      "Epoch 246/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.1174e-04 - accuracy: 1.0000\n",
      "Epoch 246: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 2.1174e-04 - accuracy: 1.0000 - val_loss: 3.6337 - val_accuracy: 0.5698\n",
      "Epoch 247/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 8.4573e-05 - accuracy: 1.0000\n",
      "Epoch 247: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 8.4573e-05 - accuracy: 1.0000 - val_loss: 3.6435 - val_accuracy: 0.5698\n",
      "Epoch 248/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 4.9634e-05 - accuracy: 1.0000\n",
      "Epoch 248: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 4.9634e-05 - accuracy: 1.0000 - val_loss: 3.6514 - val_accuracy: 0.5756\n",
      "Epoch 249/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 4.8117e-05 - accuracy: 1.0000\n",
      "Epoch 249: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 4.8117e-05 - accuracy: 1.0000 - val_loss: 3.6589 - val_accuracy: 0.5756\n",
      "Epoch 250/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.7078e-04 - accuracy: 1.0000\n",
      "Epoch 250: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 2.7078e-04 - accuracy: 1.0000 - val_loss: 3.6839 - val_accuracy: 0.5814\n",
      "=== Batch Size:  16\n"
     ]
    }
   ],
   "source": [
    "if ql0 == 1:\n",
    "    ## For Quanv Exp.\n",
    "    early_stop = EarlyStopping(monitor='val_loss', mode='min', \n",
    "                               verbose=1, patience=10, min_delta=0.0001)\n",
    "\n",
    "    checkpoint = ModelCheckpoint('checkpoints/best_quanv_demo20.hdf5', monitor='val_accuracy', \n",
    "                                 verbose=1, save_best_only=True, mode='max')\n",
    "    if net == 0:\n",
    "        modelq = dense_Model(x_train[0], labels)\n",
    "    elif net == 1:\n",
    "        modelq0 = attrnn_Model(q_train0[0], labels)\n",
    "\n",
    "    modelq1.summary()\n",
    "\n",
    "    q_history0 = modelq0.fit(\n",
    "        x=q_train0, \n",
    "        y=y_train,\n",
    "        epochs=eps, \n",
    "        callbacks=[checkpoint], \n",
    "        batch_size=bsize, \n",
    "        validation_data=(q_valid0,y_valid)\n",
    "    )\n",
    "\n",
    "    keras.models.save_model(modelq0, 'checkpoints/'+ data_ix + '_quanv_model_demo20.hdf5') \n",
    "    modelq1.save('checkpoints/'+ data_ix + '_demo20.hdf5')\n",
    "\n",
    "    print(\"=== Batch Size: \", bsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f7064b70",
   "metadata": {
    "id": "f7064b70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_18 (InputLayer)          [(None, 30, 63, 2)]  0           []                               \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 30, 63, 2)   8           ['input_18[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " permute_8 (Permute)            (None, 63, 30, 2)    0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " ConvUp (Conv2D)                (None, 63, 30, 16)   176         ['permute_8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 63, 30, 16)  64          ['ConvUp[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " ConvDown1 (Conv2D)             (None, 63, 30, 32)   2592        ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 63, 30, 32)  128         ['ConvDown1[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " ConvDown2 (Conv2D)             (None, 63, 30, 16)   2576        ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 63, 30, 16)  64          ['ConvDown2[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 63, 30, 32)   0           ['batch_normalization_41[0][0]', \n",
      "                                                                  'batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " ConvMerge (Conv2D)             (None, 63, 30, 1)    161         ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 63, 30, 1)   4           ['ConvMerge[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " squeeze_last_dim (Lambda)      (None, 63, 30)       0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " bidirectional_16 (Bidirectiona  (None, 63, 128)     48640       ['squeeze_last_dim[0][0]']       \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " bidirectional_17 (Bidirectiona  (None, 63, 128)     98816       ['bidirectional_16[0][0]']       \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " lambda_8 (Lambda)              (None, 128)          0           ['bidirectional_17[0][0]']       \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 128)          16512       ['lambda_8[0][0]']               \n",
      "                                                                                                  \n",
      " dot_16 (Dot)                   (None, 63)           0           ['dense_24[0][0]',               \n",
      "                                                                  'bidirectional_17[0][0]']       \n",
      "                                                                                                  \n",
      " attSoftmax (Softmax)           (None, 63)           0           ['dot_16[0][0]']                 \n",
      "                                                                                                  \n",
      " dot_17 (Dot)                   (None, 128)          0           ['attSoftmax[0][0]',             \n",
      "                                                                  'bidirectional_17[0][0]']       \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 64)           8256        ['dot_17[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 32)           2080        ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 2)            66          ['dense_26[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 180,143\n",
      "Trainable params: 180,009\n",
      "Non-trainable params: 134\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6917 - accuracy: 0.5247\n",
      "Epoch 1: val_accuracy improved from -inf to 0.51163, saving model to checkpoints\\best_quanv_demo21.hdf5\n",
      "43/43 [==============================] - 15s 137ms/step - loss: 0.6917 - accuracy: 0.5247 - val_loss: 0.7083 - val_accuracy: 0.5116\n",
      "Epoch 2/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6769 - accuracy: 0.5407\n",
      "Epoch 2: val_accuracy did not improve from 0.51163\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.6769 - accuracy: 0.5407 - val_loss: 0.7081 - val_accuracy: 0.4884\n",
      "Epoch 3/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6578 - accuracy: 0.5814\n",
      "Epoch 3: val_accuracy did not improve from 0.51163\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.6578 - accuracy: 0.5814 - val_loss: 0.7212 - val_accuracy: 0.5000\n",
      "Epoch 4/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6454 - accuracy: 0.6221\n",
      "Epoch 4: val_accuracy did not improve from 0.51163\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.6454 - accuracy: 0.6221 - val_loss: 0.6925 - val_accuracy: 0.4826\n",
      "Epoch 5/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6228 - accuracy: 0.6366\n",
      "Epoch 5: val_accuracy improved from 0.51163 to 0.55233, saving model to checkpoints\\best_quanv_demo21.hdf5\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.6228 - accuracy: 0.6366 - val_loss: 0.7248 - val_accuracy: 0.5523\n",
      "Epoch 6/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6253 - accuracy: 0.6410\n",
      "Epoch 6: val_accuracy improved from 0.55233 to 0.59302, saving model to checkpoints\\best_quanv_demo21.hdf5\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.6253 - accuracy: 0.6410 - val_loss: 0.7987 - val_accuracy: 0.5930\n",
      "Epoch 7/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6045 - accuracy: 0.6788\n",
      "Epoch 7: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.6045 - accuracy: 0.6788 - val_loss: 1.0613 - val_accuracy: 0.5116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5998 - accuracy: 0.6773\n",
      "Epoch 8: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.5998 - accuracy: 0.6773 - val_loss: 0.6772 - val_accuracy: 0.5756\n",
      "Epoch 9/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5746 - accuracy: 0.6904\n",
      "Epoch 9: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.5746 - accuracy: 0.6904 - val_loss: 0.9280 - val_accuracy: 0.5116\n",
      "Epoch 10/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5569 - accuracy: 0.7006\n",
      "Epoch 10: val_accuracy improved from 0.59302 to 0.62791, saving model to checkpoints\\best_quanv_demo21.hdf5\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.5569 - accuracy: 0.7006 - val_loss: 0.6290 - val_accuracy: 0.6279\n",
      "Epoch 11/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4886 - accuracy: 0.7267\n",
      "Epoch 11: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.4886 - accuracy: 0.7267 - val_loss: 0.6992 - val_accuracy: 0.5058\n",
      "Epoch 12/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4885 - accuracy: 0.7544\n",
      "Epoch 12: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.4885 - accuracy: 0.7544 - val_loss: 0.8101 - val_accuracy: 0.5233\n",
      "Epoch 13/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4426 - accuracy: 0.7791\n",
      "Epoch 13: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.4426 - accuracy: 0.7791 - val_loss: 0.7945 - val_accuracy: 0.5407\n",
      "Epoch 14/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4221 - accuracy: 0.7907\n",
      "Epoch 14: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.4221 - accuracy: 0.7907 - val_loss: 0.6926 - val_accuracy: 0.5814\n",
      "Epoch 15/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4392 - accuracy: 0.7965\n",
      "Epoch 15: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.4392 - accuracy: 0.7965 - val_loss: 1.0396 - val_accuracy: 0.4535\n",
      "Epoch 16/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4028 - accuracy: 0.8183\n",
      "Epoch 16: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.4028 - accuracy: 0.8183 - val_loss: 1.1122 - val_accuracy: 0.4884\n",
      "Epoch 17/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3724 - accuracy: 0.8154\n",
      "Epoch 17: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.3724 - accuracy: 0.8154 - val_loss: 0.9159 - val_accuracy: 0.5872\n",
      "Epoch 18/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2923 - accuracy: 0.8663\n",
      "Epoch 18: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.2923 - accuracy: 0.8663 - val_loss: 1.2949 - val_accuracy: 0.5349\n",
      "Epoch 19/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3203 - accuracy: 0.8677\n",
      "Epoch 19: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.3203 - accuracy: 0.8677 - val_loss: 0.9007 - val_accuracy: 0.5988\n",
      "Epoch 20/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2982 - accuracy: 0.8794\n",
      "Epoch 20: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.2982 - accuracy: 0.8794 - val_loss: 0.9114 - val_accuracy: 0.5000\n",
      "Epoch 21/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2710 - accuracy: 0.8866\n",
      "Epoch 21: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2710 - accuracy: 0.8866 - val_loss: 1.2944 - val_accuracy: 0.4942\n",
      "Epoch 22/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2142 - accuracy: 0.9070\n",
      "Epoch 22: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.2142 - accuracy: 0.9070 - val_loss: 1.2609 - val_accuracy: 0.5988\n",
      "Epoch 23/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1521 - accuracy: 0.9477\n",
      "Epoch 23: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1521 - accuracy: 0.9477 - val_loss: 1.2000 - val_accuracy: 0.5116\n",
      "Epoch 24/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2304 - accuracy: 0.9084\n",
      "Epoch 24: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.2304 - accuracy: 0.9084 - val_loss: 1.8784 - val_accuracy: 0.5116\n",
      "Epoch 25/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2397 - accuracy: 0.8997\n",
      "Epoch 25: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.2397 - accuracy: 0.8997 - val_loss: 1.2072 - val_accuracy: 0.5291\n",
      "Epoch 26/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2017 - accuracy: 0.9230\n",
      "Epoch 26: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.2017 - accuracy: 0.9230 - val_loss: 1.2072 - val_accuracy: 0.5814\n",
      "Epoch 27/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2071 - accuracy: 0.9186\n",
      "Epoch 27: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.2071 - accuracy: 0.9186 - val_loss: 1.2457 - val_accuracy: 0.5988\n",
      "Epoch 28/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1662 - accuracy: 0.9360\n",
      "Epoch 28: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1662 - accuracy: 0.9360 - val_loss: 0.9659 - val_accuracy: 0.5407\n",
      "Epoch 29/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1403 - accuracy: 0.9564\n",
      "Epoch 29: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.1403 - accuracy: 0.9564 - val_loss: 1.6811 - val_accuracy: 0.5465\n",
      "Epoch 30/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1749 - accuracy: 0.9419\n",
      "Epoch 30: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1749 - accuracy: 0.9419 - val_loss: 0.9629 - val_accuracy: 0.6163\n",
      "Epoch 31/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2128 - accuracy: 0.9012\n",
      "Epoch 31: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.2128 - accuracy: 0.9012 - val_loss: 0.9404 - val_accuracy: 0.5581\n",
      "Epoch 32/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1425 - accuracy: 0.9448\n",
      "Epoch 32: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1425 - accuracy: 0.9448 - val_loss: 1.2616 - val_accuracy: 0.5291\n",
      "Epoch 33/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9637\n",
      "Epoch 33: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0847 - accuracy: 0.9637 - val_loss: 1.6733 - val_accuracy: 0.5349\n",
      "Epoch 34/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2206 - accuracy: 0.9142\n",
      "Epoch 34: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.2206 - accuracy: 0.9142 - val_loss: 1.1700 - val_accuracy: 0.5174\n",
      "Epoch 35/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1067 - accuracy: 0.9564\n",
      "Epoch 35: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1067 - accuracy: 0.9564 - val_loss: 1.0536 - val_accuracy: 0.6047\n",
      "Epoch 36/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9738\n",
      "Epoch 36: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0661 - accuracy: 0.9738 - val_loss: 1.5939 - val_accuracy: 0.5465\n",
      "Epoch 37/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9956\n",
      "Epoch 37: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0182 - accuracy: 0.9956 - val_loss: 1.9908 - val_accuracy: 0.5291\n",
      "Epoch 38/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1272 - accuracy: 0.9520\n",
      "Epoch 38: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1272 - accuracy: 0.9520 - val_loss: 1.8065 - val_accuracy: 0.5930\n",
      "Epoch 39/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1422 - accuracy: 0.9346\n",
      "Epoch 39: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1422 - accuracy: 0.9346 - val_loss: 0.9975 - val_accuracy: 0.5523\n",
      "Epoch 40/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.9564\n",
      "Epoch 40: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1294 - accuracy: 0.9564 - val_loss: 1.3619 - val_accuracy: 0.5756\n",
      "Epoch 41/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9797\n",
      "Epoch 41: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0499 - accuracy: 0.9797 - val_loss: 1.4291 - val_accuracy: 0.5640\n",
      "Epoch 42/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.9578\n",
      "Epoch 42: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1084 - accuracy: 0.9578 - val_loss: 0.8268 - val_accuracy: 0.5814\n",
      "Epoch 43/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.9491\n",
      "Epoch 43: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1114 - accuracy: 0.9491 - val_loss: 1.5806 - val_accuracy: 0.5407\n",
      "Epoch 44/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9724\n",
      "Epoch 44: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0667 - accuracy: 0.9724 - val_loss: 1.3261 - val_accuracy: 0.5407\n",
      "Epoch 45/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9666\n",
      "Epoch 45: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0838 - accuracy: 0.9666 - val_loss: 1.1623 - val_accuracy: 0.5116\n",
      "Epoch 46/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1382 - accuracy: 0.9520\n",
      "Epoch 46: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1382 - accuracy: 0.9520 - val_loss: 1.1201 - val_accuracy: 0.5872\n",
      "Epoch 47/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.9695\n",
      "Epoch 47: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0755 - accuracy: 0.9695 - val_loss: 2.1527 - val_accuracy: 0.5174\n",
      "Epoch 48/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 0.9738\n",
      "Epoch 48: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0693 - accuracy: 0.9738 - val_loss: 1.7176 - val_accuracy: 0.5988\n",
      "Epoch 49/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9884\n",
      "Epoch 49: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0396 - accuracy: 0.9884 - val_loss: 2.5664 - val_accuracy: 0.5116\n",
      "Epoch 50/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9724\n",
      "Epoch 50: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0707 - accuracy: 0.9724 - val_loss: 1.5580 - val_accuracy: 0.5988\n",
      "Epoch 51/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1167 - accuracy: 0.9491\n",
      "Epoch 51: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1167 - accuracy: 0.9491 - val_loss: 1.1288 - val_accuracy: 0.5756\n",
      "Epoch 52/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1273 - accuracy: 0.9549\n",
      "Epoch 52: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.1273 - accuracy: 0.9549 - val_loss: 1.1559 - val_accuracy: 0.5349\n",
      "Epoch 53/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.9738\n",
      "Epoch 53: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0639 - accuracy: 0.9738 - val_loss: 1.3082 - val_accuracy: 0.4942\n",
      "Epoch 54/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0734 - accuracy: 0.9767\n",
      "Epoch 54: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0734 - accuracy: 0.9767 - val_loss: 1.7302 - val_accuracy: 0.5988\n",
      "Epoch 55/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9869\n",
      "Epoch 55: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0419 - accuracy: 0.9869 - val_loss: 1.4993 - val_accuracy: 0.6279\n",
      "Epoch 56/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9855\n",
      "Epoch 56: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0434 - accuracy: 0.9855 - val_loss: 1.2429 - val_accuracy: 0.5756\n",
      "Epoch 57/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9913\n",
      "Epoch 57: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0410 - accuracy: 0.9913 - val_loss: 1.4021 - val_accuracy: 0.5814\n",
      "Epoch 58/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9927\n",
      "Epoch 58: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0187 - accuracy: 0.9927 - val_loss: 1.6858 - val_accuracy: 0.5523\n",
      "Epoch 59/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9840\n",
      "Epoch 59: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0481 - accuracy: 0.9840 - val_loss: 2.4850 - val_accuracy: 0.5349\n",
      "Epoch 60/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0478 - accuracy: 0.9826\n",
      "Epoch 60: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0478 - accuracy: 0.9826 - val_loss: 2.2737 - val_accuracy: 0.5698\n",
      "Epoch 61/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.9608\n",
      "Epoch 61: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1142 - accuracy: 0.9608 - val_loss: 2.5095 - val_accuracy: 0.5058\n",
      "Epoch 62/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9811\n",
      "Epoch 62: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0794 - accuracy: 0.9811 - val_loss: 1.6288 - val_accuracy: 0.5640\n",
      "Epoch 63/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9898\n",
      "Epoch 63: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0331 - accuracy: 0.9898 - val_loss: 1.6050 - val_accuracy: 0.5407\n",
      "Epoch 64/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9811\n",
      "Epoch 64: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0865 - accuracy: 0.9811 - val_loss: 1.6219 - val_accuracy: 0.5233\n",
      "Epoch 65/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0723 - accuracy: 0.9782\n",
      "Epoch 65: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0723 - accuracy: 0.9782 - val_loss: 1.9586 - val_accuracy: 0.5291\n",
      "Epoch 66/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9927\n",
      "Epoch 66: val_accuracy did not improve from 0.62791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0264 - accuracy: 0.9927 - val_loss: 2.0064 - val_accuracy: 0.4826\n",
      "Epoch 67/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9942\n",
      "Epoch 67: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0147 - accuracy: 0.9942 - val_loss: 2.2608 - val_accuracy: 0.5116\n",
      "Epoch 68/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9971\n",
      "Epoch 68: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 2.2790 - val_accuracy: 0.5058\n",
      "Epoch 69/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 0.9738\n",
      "Epoch 69: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0702 - accuracy: 0.9738 - val_loss: 2.3920 - val_accuracy: 0.5233\n",
      "Epoch 70/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1629 - accuracy: 0.9404\n",
      "Epoch 70: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1629 - accuracy: 0.9404 - val_loss: 1.4254 - val_accuracy: 0.5872\n",
      "Epoch 71/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.9535\n",
      "Epoch 71: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1393 - accuracy: 0.9535 - val_loss: 3.0387 - val_accuracy: 0.5174\n",
      "Epoch 72/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9782\n",
      "Epoch 72: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0689 - accuracy: 0.9782 - val_loss: 2.9189 - val_accuracy: 0.5349\n",
      "Epoch 73/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9927\n",
      "Epoch 73: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0266 - accuracy: 0.9927 - val_loss: 5.1788 - val_accuracy: 0.5116\n",
      "Epoch 74/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9971\n",
      "Epoch 74: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 2.0952 - val_accuracy: 0.5988\n",
      "Epoch 75/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 75: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 2.4857 - val_accuracy: 0.5930\n",
      "Epoch 76/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9738\n",
      "Epoch 76: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0843 - accuracy: 0.9738 - val_loss: 1.9161 - val_accuracy: 0.6105\n",
      "Epoch 77/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9855\n",
      "Epoch 77: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0440 - accuracy: 0.9855 - val_loss: 2.0524 - val_accuracy: 0.5581\n",
      "Epoch 78/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9942\n",
      "Epoch 78: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0240 - accuracy: 0.9942 - val_loss: 1.6555 - val_accuracy: 0.5465\n",
      "Epoch 79/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9898\n",
      "Epoch 79: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0474 - accuracy: 0.9898 - val_loss: 3.6243 - val_accuracy: 0.5291\n",
      "Epoch 80/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9927\n",
      "Epoch 80: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 2.0844 - val_accuracy: 0.5407\n",
      "Epoch 81/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9971\n",
      "Epoch 81: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 3.0392 - val_accuracy: 0.5349\n",
      "Epoch 82/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9985\n",
      "Epoch 82: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0029 - accuracy: 0.9985 - val_loss: 3.0755 - val_accuracy: 0.5291\n",
      "Epoch 83/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 83: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.3630 - val_accuracy: 0.5407\n",
      "Epoch 84/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9956\n",
      "Epoch 84: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0072 - accuracy: 0.9956 - val_loss: 3.7673 - val_accuracy: 0.5640\n",
      "Epoch 85/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.9855\n",
      "Epoch 85: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0400 - accuracy: 0.9855 - val_loss: 3.9147 - val_accuracy: 0.5349\n",
      "Epoch 86/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2002 - accuracy: 0.9230\n",
      "Epoch 86: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.2002 - accuracy: 0.9230 - val_loss: 2.3546 - val_accuracy: 0.5465\n",
      "Epoch 87/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1298 - accuracy: 0.9549\n",
      "Epoch 87: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.1298 - accuracy: 0.9549 - val_loss: 1.4507 - val_accuracy: 0.5872\n",
      "Epoch 88/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9826\n",
      "Epoch 88: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0423 - accuracy: 0.9826 - val_loss: 1.8853 - val_accuracy: 0.5930\n",
      "Epoch 89/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9898\n",
      "Epoch 89: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0302 - accuracy: 0.9898 - val_loss: 1.9722 - val_accuracy: 0.5640\n",
      "Epoch 90/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9898\n",
      "Epoch 90: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0290 - accuracy: 0.9898 - val_loss: 3.3272 - val_accuracy: 0.5698\n",
      "Epoch 91/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9956\n",
      "Epoch 91: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0195 - accuracy: 0.9956 - val_loss: 2.5673 - val_accuracy: 0.5581\n",
      "Epoch 92/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.9898\n",
      "Epoch 92: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0282 - accuracy: 0.9898 - val_loss: 2.0657 - val_accuracy: 0.6163\n",
      "Epoch 93/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9971\n",
      "Epoch 93: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0193 - accuracy: 0.9971 - val_loss: 2.1449 - val_accuracy: 0.5465\n",
      "Epoch 94/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9971\n",
      "Epoch 94: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0197 - accuracy: 0.9971 - val_loss: 1.6608 - val_accuracy: 0.5930\n",
      "Epoch 95/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9826\n",
      "Epoch 95: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0536 - accuracy: 0.9826 - val_loss: 1.6993 - val_accuracy: 0.5872\n",
      "Epoch 96/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9767\n",
      "Epoch 96: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0471 - accuracy: 0.9767 - val_loss: 3.4992 - val_accuracy: 0.5349\n",
      "Epoch 97/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9869\n",
      "Epoch 97: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0447 - accuracy: 0.9869 - val_loss: 3.3165 - val_accuracy: 0.5407\n",
      "Epoch 98/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9840\n",
      "Epoch 98: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0485 - accuracy: 0.9840 - val_loss: 1.6292 - val_accuracy: 0.5233\n",
      "Epoch 99/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9927\n",
      "Epoch 99: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0348 - accuracy: 0.9927 - val_loss: 3.3373 - val_accuracy: 0.5523\n",
      "Epoch 100/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9985\n",
      "Epoch 100: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 1.7813 - val_accuracy: 0.5756\n",
      "Epoch 101/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 101: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8485 - val_accuracy: 0.5581\n",
      "Epoch 102/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9985\n",
      "Epoch 102: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0126 - accuracy: 0.9985 - val_loss: 3.5308 - val_accuracy: 0.5523\n",
      "Epoch 103/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 103: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6428 - val_accuracy: 0.5756\n",
      "Epoch 104/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 104: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.8929 - val_accuracy: 0.5523\n",
      "Epoch 105/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.5208e-04 - accuracy: 1.0000\n",
      "Epoch 105: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 5.5208e-04 - accuracy: 1.0000 - val_loss: 2.3420 - val_accuracy: 0.5930\n",
      "Epoch 106/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 8.5763e-04 - accuracy: 1.0000\n",
      "Epoch 106: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 8.5763e-04 - accuracy: 1.0000 - val_loss: 2.3792 - val_accuracy: 0.5872\n",
      "Epoch 107/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.5621e-04 - accuracy: 1.0000\n",
      "Epoch 107: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 3.5621e-04 - accuracy: 1.0000 - val_loss: 2.5068 - val_accuracy: 0.5872\n",
      "Epoch 108/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.8794e-04 - accuracy: 1.0000\n",
      "Epoch 108: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 3.8794e-04 - accuracy: 1.0000 - val_loss: 2.4937 - val_accuracy: 0.5814\n",
      "Epoch 109/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.0378e-04 - accuracy: 1.0000\n",
      "Epoch 109: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 2.0378e-04 - accuracy: 1.0000 - val_loss: 2.5987 - val_accuracy: 0.5814\n",
      "Epoch 110/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.6337e-04 - accuracy: 1.0000\n",
      "Epoch 110: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 1.6337e-04 - accuracy: 1.0000 - val_loss: 2.6690 - val_accuracy: 0.5872\n",
      "Epoch 111/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.7852e-04 - accuracy: 1.0000\n",
      "Epoch 111: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 3.7852e-04 - accuracy: 1.0000 - val_loss: 2.6812 - val_accuracy: 0.5756\n",
      "Epoch 112/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.6908e-04 - accuracy: 1.0000\n",
      "Epoch 112: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 1.6908e-04 - accuracy: 1.0000 - val_loss: 2.7180 - val_accuracy: 0.5698\n",
      "Epoch 113/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.1289e-04 - accuracy: 1.0000\n",
      "Epoch 113: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 3.1289e-04 - accuracy: 1.0000 - val_loss: 2.8155 - val_accuracy: 0.5756\n",
      "Epoch 114/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.0029e-04 - accuracy: 1.0000\n",
      "Epoch 114: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 2.0029e-04 - accuracy: 1.0000 - val_loss: 2.8654 - val_accuracy: 0.5756\n",
      "Epoch 115/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.2028e-04 - accuracy: 1.0000\n",
      "Epoch 115: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 1.2028e-04 - accuracy: 1.0000 - val_loss: 2.8980 - val_accuracy: 0.5756\n",
      "Epoch 116/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.4121e-04 - accuracy: 1.0000\n",
      "Epoch 116: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 1.4121e-04 - accuracy: 1.0000 - val_loss: 2.9439 - val_accuracy: 0.5814\n",
      "Epoch 117/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 7.3020e-05 - accuracy: 1.0000\n",
      "Epoch 117: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 7.3020e-05 - accuracy: 1.0000 - val_loss: 2.9807 - val_accuracy: 0.5814\n",
      "Epoch 118/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 9.4928e-05 - accuracy: 1.0000\n",
      "Epoch 118: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 9.4928e-05 - accuracy: 1.0000 - val_loss: 3.0046 - val_accuracy: 0.5814\n",
      "Epoch 119/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.0076e-04 - accuracy: 1.0000\n",
      "Epoch 119: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 1.0076e-04 - accuracy: 1.0000 - val_loss: 3.0329 - val_accuracy: 0.5814\n",
      "Epoch 120/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 9.2435e-05 - accuracy: 1.0000\n",
      "Epoch 120: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 9.2435e-05 - accuracy: 1.0000 - val_loss: 3.0510 - val_accuracy: 0.5814\n",
      "Epoch 121/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.1689e-04 - accuracy: 1.0000\n",
      "Epoch 121: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 1.1689e-04 - accuracy: 1.0000 - val_loss: 3.0828 - val_accuracy: 0.5814\n",
      "Epoch 122/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 9.1680e-05 - accuracy: 1.0000\n",
      "Epoch 122: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 9.1680e-05 - accuracy: 1.0000 - val_loss: 3.0991 - val_accuracy: 0.5814\n",
      "Epoch 123/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.0410e-04 - accuracy: 1.0000\n",
      "Epoch 123: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 2.0410e-04 - accuracy: 1.0000 - val_loss: 3.1422 - val_accuracy: 0.5756\n",
      "Epoch 124/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.3415e-04 - accuracy: 1.0000\n",
      "Epoch 124: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 1.3415e-04 - accuracy: 1.0000 - val_loss: 3.2054 - val_accuracy: 0.5756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.7023e-04 - accuracy: 1.0000\n",
      "Epoch 125: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 3.7023e-04 - accuracy: 1.0000 - val_loss: 3.2329 - val_accuracy: 0.5814\n",
      "Epoch 126/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9869\n",
      "Epoch 126: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0404 - accuracy: 0.9869 - val_loss: 3.0049 - val_accuracy: 0.5640\n",
      "Epoch 127/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9884\n",
      "Epoch 127: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0204 - accuracy: 0.9884 - val_loss: 1.8111 - val_accuracy: 0.5407\n",
      "Epoch 128/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9898\n",
      "Epoch 128: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0280 - accuracy: 0.9898 - val_loss: 1.8595 - val_accuracy: 0.5465\n",
      "Epoch 129/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9942\n",
      "Epoch 129: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0155 - accuracy: 0.9942 - val_loss: 1.6861 - val_accuracy: 0.5988\n",
      "Epoch 130/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 130: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.3393 - val_accuracy: 0.5465\n",
      "Epoch 131/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 131: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0053 - val_accuracy: 0.5698\n",
      "Epoch 132/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.9869\n",
      "Epoch 132: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0395 - accuracy: 0.9869 - val_loss: 2.0723 - val_accuracy: 0.5640\n",
      "Epoch 133/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9840\n",
      "Epoch 133: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0382 - accuracy: 0.9840 - val_loss: 2.2377 - val_accuracy: 0.5523\n",
      "Epoch 134/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 0.9826\n",
      "Epoch 134: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0644 - accuracy: 0.9826 - val_loss: 2.1337 - val_accuracy: 0.5465\n",
      "Epoch 135/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9738\n",
      "Epoch 135: val_accuracy improved from 0.62791 to 0.64535, saving model to checkpoints\\best_quanv_demo21.hdf5\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0570 - accuracy: 0.9738 - val_loss: 1.8577 - val_accuracy: 0.6453\n",
      "Epoch 136/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.9826\n",
      "Epoch 136: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0612 - accuracy: 0.9826 - val_loss: 1.4807 - val_accuracy: 0.5581\n",
      "Epoch 137/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9985\n",
      "Epoch 137: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0116 - accuracy: 0.9985 - val_loss: 1.6048 - val_accuracy: 0.6047\n",
      "Epoch 138/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9971\n",
      "Epoch 138: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0112 - accuracy: 0.9971 - val_loss: 1.6752 - val_accuracy: 0.6047\n",
      "Epoch 139/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9985\n",
      "Epoch 139: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 1.7820 - val_accuracy: 0.5814\n",
      "Epoch 140/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9898\n",
      "Epoch 140: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0392 - accuracy: 0.9898 - val_loss: 2.1721 - val_accuracy: 0.5814\n",
      "Epoch 141/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9942\n",
      "Epoch 141: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0257 - accuracy: 0.9942 - val_loss: 1.9024 - val_accuracy: 0.6105\n",
      "Epoch 142/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 142: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.0473 - val_accuracy: 0.6163\n",
      "Epoch 143/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 143: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9669 - val_accuracy: 0.6163\n",
      "Epoch 144/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.4163e-04 - accuracy: 1.0000\n",
      "Epoch 144: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 5.4163e-04 - accuracy: 1.0000 - val_loss: 1.9532 - val_accuracy: 0.6163\n",
      "Epoch 145/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.9324e-04 - accuracy: 1.0000\n",
      "Epoch 145: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 3.9324e-04 - accuracy: 1.0000 - val_loss: 1.9569 - val_accuracy: 0.6221\n",
      "Epoch 146/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 9.6803e-04 - accuracy: 1.0000\n",
      "Epoch 146: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 9.6803e-04 - accuracy: 1.0000 - val_loss: 1.9272 - val_accuracy: 0.6047\n",
      "Epoch 147/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.3975e-04 - accuracy: 1.0000\n",
      "Epoch 147: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 5.3975e-04 - accuracy: 1.0000 - val_loss: 1.9574 - val_accuracy: 0.6105\n",
      "Epoch 148/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.1180e-04 - accuracy: 1.0000\n",
      "Epoch 148: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 3.1180e-04 - accuracy: 1.0000 - val_loss: 2.0009 - val_accuracy: 0.6105\n",
      "Epoch 149/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.2721e-04 - accuracy: 1.0000\n",
      "Epoch 149: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 2.2721e-04 - accuracy: 1.0000 - val_loss: 2.0039 - val_accuracy: 0.6163\n",
      "Epoch 150/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.9656e-04 - accuracy: 1.0000\n",
      "Epoch 150: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 1.9656e-04 - accuracy: 1.0000 - val_loss: 2.0110 - val_accuracy: 0.6163\n",
      "Epoch 151/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.8574e-04 - accuracy: 1.0000\n",
      "Epoch 151: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 1.8574e-04 - accuracy: 1.0000 - val_loss: 2.0237 - val_accuracy: 0.6105\n",
      "Epoch 152/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.7871e-04 - accuracy: 1.0000\n",
      "Epoch 152: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 1.7871e-04 - accuracy: 1.0000 - val_loss: 2.0284 - val_accuracy: 0.6105\n",
      "Epoch 153/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.0397e-04 - accuracy: 1.0000\n",
      "Epoch 153: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 2.0397e-04 - accuracy: 1.0000 - val_loss: 2.0412 - val_accuracy: 0.6105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.3982e-04 - accuracy: 1.0000\n",
      "Epoch 154: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 1.3982e-04 - accuracy: 1.0000 - val_loss: 2.0531 - val_accuracy: 0.6105\n",
      "Epoch 155/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 155: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.1557 - val_accuracy: 0.5814\n",
      "Epoch 156/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 4.2047e-04 - accuracy: 1.0000\n",
      "Epoch 156: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 4.2047e-04 - accuracy: 1.0000 - val_loss: 2.1561 - val_accuracy: 0.5756\n",
      "Epoch 157/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.5074e-04 - accuracy: 1.0000\n",
      "Epoch 157: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 3.5074e-04 - accuracy: 1.0000 - val_loss: 2.2150 - val_accuracy: 0.5698\n",
      "Epoch 158/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.6652e-04 - accuracy: 1.0000\n",
      "Epoch 158: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 1.6652e-04 - accuracy: 1.0000 - val_loss: 2.2465 - val_accuracy: 0.5814\n",
      "Epoch 159/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.1136e-04 - accuracy: 1.0000\n",
      "Epoch 159: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 2.1136e-04 - accuracy: 1.0000 - val_loss: 2.2744 - val_accuracy: 0.5814\n",
      "Epoch 160/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.3760e-04 - accuracy: 1.0000\n",
      "Epoch 160: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 2.3760e-04 - accuracy: 1.0000 - val_loss: 2.2800 - val_accuracy: 0.5814\n",
      "Epoch 161/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.0121e-04 - accuracy: 1.0000\n",
      "Epoch 161: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 1.0121e-04 - accuracy: 1.0000 - val_loss: 2.2919 - val_accuracy: 0.5814\n",
      "Epoch 162/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.4046e-04 - accuracy: 1.0000\n",
      "Epoch 162: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 1.4046e-04 - accuracy: 1.0000 - val_loss: 2.3072 - val_accuracy: 0.5814\n",
      "Epoch 163/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9985\n",
      "Epoch 163: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0029 - accuracy: 0.9985 - val_loss: 2.5747 - val_accuracy: 0.5756\n",
      "Epoch 164/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9985\n",
      "Epoch 164: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0034 - accuracy: 0.9985 - val_loss: 2.7746 - val_accuracy: 0.5814\n",
      "Epoch 165/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 165: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.0386 - val_accuracy: 0.6221\n",
      "Epoch 166/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.9473e-04 - accuracy: 1.0000\n",
      "Epoch 166: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 5.9473e-04 - accuracy: 1.0000 - val_loss: 2.0091 - val_accuracy: 0.6221\n",
      "Epoch 167/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.1136e-04 - accuracy: 1.0000\n",
      "Epoch 167: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 3.1136e-04 - accuracy: 1.0000 - val_loss: 1.9886 - val_accuracy: 0.6221\n",
      "Epoch 168/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 168: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.2493 - val_accuracy: 0.5581\n",
      "Epoch 169/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9927\n",
      "Epoch 169: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0334 - accuracy: 0.9927 - val_loss: 1.8072 - val_accuracy: 0.5872\n",
      "Epoch 170/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9942\n",
      "Epoch 170: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 1.8289 - val_accuracy: 0.6047\n",
      "Epoch 171/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9942\n",
      "Epoch 171: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0102 - accuracy: 0.9942 - val_loss: 1.7539 - val_accuracy: 0.6105\n",
      "Epoch 172/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9971\n",
      "Epoch 172: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 1.7969 - val_accuracy: 0.5930\n",
      "Epoch 173/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9927\n",
      "Epoch 173: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0322 - accuracy: 0.9927 - val_loss: 2.1863 - val_accuracy: 0.5930\n",
      "Epoch 174/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9942\n",
      "Epoch 174: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 2.3842 - val_accuracy: 0.5465\n",
      "Epoch 175/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9971\n",
      "Epoch 175: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 1.9866 - val_accuracy: 0.5814\n",
      "Epoch 176/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9971\n",
      "Epoch 176: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0109 - accuracy: 0.9971 - val_loss: 2.3524 - val_accuracy: 0.6047\n",
      "Epoch 177/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 177: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.4818 - val_accuracy: 0.5581\n",
      "Epoch 178/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.7355e-04 - accuracy: 1.0000\n",
      "Epoch 178: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 3.7355e-04 - accuracy: 1.0000 - val_loss: 2.3638 - val_accuracy: 0.5756\n",
      "Epoch 179/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.2523e-04 - accuracy: 1.0000\n",
      "Epoch 179: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 3.2523e-04 - accuracy: 1.0000 - val_loss: 2.3612 - val_accuracy: 0.5756\n",
      "Epoch 180/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9985\n",
      "Epoch 180: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 2.1950 - val_accuracy: 0.5581\n",
      "Epoch 181/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 181: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 82ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.8245 - val_accuracy: 0.5523\n",
      "Epoch 182/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9985\n",
      "Epoch 182: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0017 - accuracy: 0.9985 - val_loss: 2.2064 - val_accuracy: 0.5814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.1759e-04 - accuracy: 1.0000\n",
      "Epoch 183: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 82ms/step - loss: 5.1759e-04 - accuracy: 1.0000 - val_loss: 2.3051 - val_accuracy: 0.5756\n",
      "Epoch 184/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9985\n",
      "Epoch 184: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0018 - accuracy: 0.9985 - val_loss: 1.9054 - val_accuracy: 0.5872\n",
      "Epoch 185/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 185: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.0335 - val_accuracy: 0.6047\n",
      "Epoch 186/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.1567e-04 - accuracy: 1.0000\n",
      "Epoch 186: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 2.1567e-04 - accuracy: 1.0000 - val_loss: 2.0877 - val_accuracy: 0.5872\n",
      "Epoch 187/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.2693e-04 - accuracy: 1.0000\n",
      "Epoch 187: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 2.2693e-04 - accuracy: 1.0000 - val_loss: 2.1279 - val_accuracy: 0.5930\n",
      "Epoch 188/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9985\n",
      "Epoch 188: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 2.3207 - val_accuracy: 0.5988\n",
      "Epoch 189/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 8.3722e-04 - accuracy: 1.0000\n",
      "Epoch 189: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 8.3722e-04 - accuracy: 1.0000 - val_loss: 2.4597 - val_accuracy: 0.5872\n",
      "Epoch 190/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 6.9075e-04 - accuracy: 1.0000\n",
      "Epoch 190: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 6.9075e-04 - accuracy: 1.0000 - val_loss: 2.5442 - val_accuracy: 0.5930\n",
      "Epoch 191/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 6.9569e-04 - accuracy: 1.0000\n",
      "Epoch 191: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 6.9569e-04 - accuracy: 1.0000 - val_loss: 3.6634 - val_accuracy: 0.5291\n",
      "Epoch 192/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9956\n",
      "Epoch 192: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 2.2328 - val_accuracy: 0.5523\n",
      "Epoch 193/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9985\n",
      "Epoch 193: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0031 - accuracy: 0.9985 - val_loss: 1.8668 - val_accuracy: 0.5930\n",
      "Epoch 194/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9985\n",
      "Epoch 194: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0023 - accuracy: 0.9985 - val_loss: 2.1965 - val_accuracy: 0.5640\n",
      "Epoch 195/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 195: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.2538 - val_accuracy: 0.5756\n",
      "Epoch 196/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9985\n",
      "Epoch 196: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0022 - accuracy: 0.9985 - val_loss: 2.0798 - val_accuracy: 0.5465\n",
      "Epoch 197/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 197: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.3139 - val_accuracy: 0.5581\n",
      "Epoch 198/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9985\n",
      "Epoch 198: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0024 - accuracy: 0.9985 - val_loss: 2.2800 - val_accuracy: 0.5349\n",
      "Epoch 199/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9956\n",
      "Epoch 199: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 82ms/step - loss: 0.0180 - accuracy: 0.9956 - val_loss: 2.1453 - val_accuracy: 0.5581\n",
      "Epoch 200/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9869\n",
      "Epoch 200: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0433 - accuracy: 0.9869 - val_loss: 2.5538 - val_accuracy: 0.6105\n",
      "Epoch 201/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9898\n",
      "Epoch 201: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0382 - accuracy: 0.9898 - val_loss: 2.2167 - val_accuracy: 0.5698\n",
      "Epoch 202/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.9782\n",
      "Epoch 202: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0628 - accuracy: 0.9782 - val_loss: 1.9619 - val_accuracy: 0.5930\n",
      "Epoch 203/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0379 - accuracy: 0.9913\n",
      "Epoch 203: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0379 - accuracy: 0.9913 - val_loss: 1.7553 - val_accuracy: 0.5814\n",
      "Epoch 204/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9971\n",
      "Epoch 204: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 2.3493 - val_accuracy: 0.5930\n",
      "Epoch 205/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 205: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.2188 - val_accuracy: 0.6047\n",
      "Epoch 206/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9985\n",
      "Epoch 206: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0033 - accuracy: 0.9985 - val_loss: 2.0372 - val_accuracy: 0.5814\n",
      "Epoch 207/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9956\n",
      "Epoch 207: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 2.2990 - val_accuracy: 0.5872\n",
      "Epoch 208/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9942\n",
      "Epoch 208: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0291 - accuracy: 0.9942 - val_loss: 2.2180 - val_accuracy: 0.5233\n",
      "Epoch 209/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9913\n",
      "Epoch 209: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0228 - accuracy: 0.9913 - val_loss: 1.8308 - val_accuracy: 0.5698\n",
      "Epoch 210/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9855\n",
      "Epoch 210: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0281 - accuracy: 0.9855 - val_loss: 1.9616 - val_accuracy: 0.5698\n",
      "Epoch 211/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9913\n",
      "Epoch 211: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0161 - accuracy: 0.9913 - val_loss: 3.1387 - val_accuracy: 0.5640\n",
      "Epoch 212/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9971\n",
      "Epoch 212: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 2.6219 - val_accuracy: 0.5581\n",
      "Epoch 213/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9956\n",
      "Epoch 213: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0086 - accuracy: 0.9956 - val_loss: 3.0856 - val_accuracy: 0.5523\n",
      "Epoch 214/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9985\n",
      "Epoch 214: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0034 - accuracy: 0.9985 - val_loss: 3.2640 - val_accuracy: 0.5581\n",
      "Epoch 215/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 215: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2241 - val_accuracy: 0.5640\n",
      "Epoch 216/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9985\n",
      "Epoch 216: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0026 - accuracy: 0.9985 - val_loss: 3.1115 - val_accuracy: 0.5640\n",
      "Epoch 217/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 217: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.9975 - val_accuracy: 0.5640\n",
      "Epoch 218/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.9339e-04 - accuracy: 1.0000\n",
      "Epoch 218: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 3.9339e-04 - accuracy: 1.0000 - val_loss: 2.9534 - val_accuracy: 0.5640\n",
      "Epoch 219/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 8.3031e-04 - accuracy: 1.0000\n",
      "Epoch 219: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 8.3031e-04 - accuracy: 1.0000 - val_loss: 3.0489 - val_accuracy: 0.5581\n",
      "Epoch 220/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9956\n",
      "Epoch 220: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0073 - accuracy: 0.9956 - val_loss: 2.7144 - val_accuracy: 0.5581\n",
      "Epoch 221/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9971\n",
      "Epoch 221: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 2.9837 - val_accuracy: 0.5814\n",
      "Epoch 222/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9956\n",
      "Epoch 222: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0060 - accuracy: 0.9956 - val_loss: 2.2438 - val_accuracy: 0.5930\n",
      "Epoch 223/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9913\n",
      "Epoch 223: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0346 - accuracy: 0.9913 - val_loss: 2.7128 - val_accuracy: 0.5872\n",
      "Epoch 224/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9942\n",
      "Epoch 224: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 3.2273 - val_accuracy: 0.5465\n",
      "Epoch 225/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 225: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.6330 - val_accuracy: 0.5698\n",
      "Epoch 226/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 6.8295e-04 - accuracy: 1.0000\n",
      "Epoch 226: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 6.8295e-04 - accuracy: 1.0000 - val_loss: 2.7965 - val_accuracy: 0.5640\n",
      "Epoch 227/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.8143e-04 - accuracy: 1.0000\n",
      "Epoch 227: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 2.8143e-04 - accuracy: 1.0000 - val_loss: 2.8294 - val_accuracy: 0.5465\n",
      "Epoch 228/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.9343e-04 - accuracy: 1.0000\n",
      "Epoch 228: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 3.9343e-04 - accuracy: 1.0000 - val_loss: 2.8299 - val_accuracy: 0.5465\n",
      "Epoch 229/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 6.2251e-04 - accuracy: 1.0000\n",
      "Epoch 229: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 6.2251e-04 - accuracy: 1.0000 - val_loss: 2.7534 - val_accuracy: 0.5640\n",
      "Epoch 230/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 6.2352e-04 - accuracy: 1.0000\n",
      "Epoch 230: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 6.2352e-04 - accuracy: 1.0000 - val_loss: 2.6792 - val_accuracy: 0.5698\n",
      "Epoch 231/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.4785e-04 - accuracy: 1.0000\n",
      "Epoch 231: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 82ms/step - loss: 2.4785e-04 - accuracy: 1.0000 - val_loss: 2.7454 - val_accuracy: 0.5756\n",
      "Epoch 232/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.7047e-04 - accuracy: 1.0000\n",
      "Epoch 232: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 1.7047e-04 - accuracy: 1.0000 - val_loss: 2.7665 - val_accuracy: 0.5756\n",
      "Epoch 233/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.1066e-04 - accuracy: 1.0000\n",
      "Epoch 233: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 3.1066e-04 - accuracy: 1.0000 - val_loss: 2.8239 - val_accuracy: 0.5698\n",
      "Epoch 234/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.5108e-04 - accuracy: 1.0000\n",
      "Epoch 234: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 2.5108e-04 - accuracy: 1.0000 - val_loss: 2.8214 - val_accuracy: 0.5756\n",
      "Epoch 235/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.8657e-04 - accuracy: 1.0000\n",
      "Epoch 235: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 1.8657e-04 - accuracy: 1.0000 - val_loss: 2.8637 - val_accuracy: 0.5698\n",
      "Epoch 236/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.7705e-04 - accuracy: 1.0000\n",
      "Epoch 236: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 1.7705e-04 - accuracy: 1.0000 - val_loss: 2.9210 - val_accuracy: 0.5640\n",
      "Epoch 237/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.1177e-04 - accuracy: 1.0000\n",
      "Epoch 237: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 1.1177e-04 - accuracy: 1.0000 - val_loss: 2.9549 - val_accuracy: 0.5523\n",
      "Epoch 238/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.1160e-04 - accuracy: 1.0000\n",
      "Epoch 238: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 1.1160e-04 - accuracy: 1.0000 - val_loss: 2.9942 - val_accuracy: 0.5523\n",
      "Epoch 239/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.6762e-04 - accuracy: 1.0000\n",
      "Epoch 239: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 1.6762e-04 - accuracy: 1.0000 - val_loss: 3.0230 - val_accuracy: 0.5523\n",
      "Epoch 240/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.2425e-04 - accuracy: 1.0000\n",
      "Epoch 240: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 1.2425e-04 - accuracy: 1.0000 - val_loss: 3.0373 - val_accuracy: 0.5523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 6.9197e-05 - accuracy: 1.0000\n",
      "Epoch 241: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 6.9197e-05 - accuracy: 1.0000 - val_loss: 3.0557 - val_accuracy: 0.5523\n",
      "Epoch 242/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 7.0872e-05 - accuracy: 1.0000\n",
      "Epoch 242: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 7.0872e-05 - accuracy: 1.0000 - val_loss: 3.0724 - val_accuracy: 0.5523\n",
      "Epoch 243/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 6.9893e-05 - accuracy: 1.0000\n",
      "Epoch 243: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 6.9893e-05 - accuracy: 1.0000 - val_loss: 3.0954 - val_accuracy: 0.5523\n",
      "Epoch 244/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 9.1348e-05 - accuracy: 1.0000\n",
      "Epoch 244: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 9.1348e-05 - accuracy: 1.0000 - val_loss: 3.1252 - val_accuracy: 0.5523\n",
      "Epoch 245/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 8.2158e-05 - accuracy: 1.0000\n",
      "Epoch 245: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 8.2158e-05 - accuracy: 1.0000 - val_loss: 3.1480 - val_accuracy: 0.5523\n",
      "Epoch 246/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 9.0935e-05 - accuracy: 1.0000\n",
      "Epoch 246: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 9.0935e-05 - accuracy: 1.0000 - val_loss: 3.1661 - val_accuracy: 0.5523\n",
      "Epoch 247/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 7.3538e-05 - accuracy: 1.0000\n",
      "Epoch 247: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 7.3538e-05 - accuracy: 1.0000 - val_loss: 3.1843 - val_accuracy: 0.5523\n",
      "Epoch 248/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.7727e-05 - accuracy: 1.0000\n",
      "Epoch 248: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 5.7727e-05 - accuracy: 1.0000 - val_loss: 3.2083 - val_accuracy: 0.5523\n",
      "Epoch 249/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.9917e-04 - accuracy: 1.0000\n",
      "Epoch 249: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 1.9917e-04 - accuracy: 1.0000 - val_loss: 3.1513 - val_accuracy: 0.5581\n",
      "Epoch 250/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 7.5263e-05 - accuracy: 1.0000\n",
      "Epoch 250: val_accuracy did not improve from 0.64535\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 7.5263e-05 - accuracy: 1.0000 - val_loss: 3.1560 - val_accuracy: 0.5581\n",
      "=== Batch Size:  16\n"
     ]
    }
   ],
   "source": [
    "if ql1 == 1:\n",
    "    ## For Quanv Exp.\n",
    "    early_stop = EarlyStopping(monitor='val_loss', mode='min', \n",
    "                               verbose=1, patience=10, min_delta=0.0001)\n",
    "\n",
    "    checkpoint = ModelCheckpoint('checkpoints/best_quanv_demo21.hdf5', monitor='val_accuracy', \n",
    "                                 verbose=1, save_best_only=True, mode='max')\n",
    "    if net == 0:\n",
    "        modelq = dense_Model(x_train[0], labels)\n",
    "    elif net == 1:\n",
    "        modelq1 = attrnn_Model(q_train1[0], labels)\n",
    "\n",
    "    modelq1.summary()\n",
    "\n",
    "    q_history1 = modelq1.fit(\n",
    "        x=q_train1, \n",
    "        y=y_train,\n",
    "        epochs=eps, \n",
    "        callbacks=[checkpoint], \n",
    "        batch_size=bsize, \n",
    "        validation_data=(q_valid1,y_valid)\n",
    "    )\n",
    "\n",
    "    keras.models.save_model(modelq1, 'checkpoints/'+ data_ix + '_quanv_model_demo21.hdf5') \n",
    "    modelq1.save('checkpoints/'+ data_ix + '_demo21.hdf5')\n",
    "\n",
    "    print(\"=== Batch Size: \", bsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ZcMJ3332vKDs",
   "metadata": {
    "id": "ZcMJ3332vKDs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_20 (InputLayer)          [(None, 30, 63, 2)]  0           []                               \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 30, 63, 2)   8           ['input_20[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " permute_9 (Permute)            (None, 63, 30, 2)    0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " ConvUp (Conv2D)                (None, 63, 30, 16)   176         ['permute_9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 63, 30, 16)  64          ['ConvUp[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " ConvDown1 (Conv2D)             (None, 63, 30, 32)   2592        ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 63, 30, 32)  128         ['ConvDown1[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " ConvDown2 (Conv2D)             (None, 63, 30, 16)   2576        ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 63, 30, 16)  64          ['ConvDown2[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 63, 30, 32)   0           ['batch_normalization_46[0][0]', \n",
      "                                                                  'batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " ConvMerge (Conv2D)             (None, 63, 30, 1)    161         ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 63, 30, 1)   4           ['ConvMerge[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " squeeze_last_dim (Lambda)      (None, 63, 30)       0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " bidirectional_18 (Bidirectiona  (None, 63, 128)     48640       ['squeeze_last_dim[0][0]']       \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " bidirectional_19 (Bidirectiona  (None, 63, 128)     98816       ['bidirectional_18[0][0]']       \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " lambda_9 (Lambda)              (None, 128)          0           ['bidirectional_19[0][0]']       \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 128)          16512       ['lambda_9[0][0]']               \n",
      "                                                                                                  \n",
      " dot_18 (Dot)                   (None, 63)           0           ['dense_27[0][0]',               \n",
      "                                                                  'bidirectional_19[0][0]']       \n",
      "                                                                                                  \n",
      " attSoftmax (Softmax)           (None, 63)           0           ['dot_18[0][0]']                 \n",
      "                                                                                                  \n",
      " dot_19 (Dot)                   (None, 128)          0           ['attSoftmax[0][0]',             \n",
      "                                                                  'bidirectional_19[0][0]']       \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 64)           8256        ['dot_19[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 32)           2080        ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 2)            66          ['dense_29[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 180,143\n",
      "Trainable params: 180,009\n",
      "Non-trainable params: 134\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6899 - accuracy: 0.5480\n",
      "Epoch 1: val_accuracy improved from -inf to 0.48837, saving model to checkpoints\\best_quanv_demo22.hdf5\n",
      "43/43 [==============================] - 9s 116ms/step - loss: 0.6899 - accuracy: 0.5480 - val_loss: 0.6973 - val_accuracy: 0.4884\n",
      "Epoch 2/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6686 - accuracy: 0.5756\n",
      "Epoch 2: val_accuracy improved from 0.48837 to 0.51163, saving model to checkpoints\\best_quanv_demo22.hdf5\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.6686 - accuracy: 0.5756 - val_loss: 0.7312 - val_accuracy: 0.5116\n",
      "Epoch 3/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6488 - accuracy: 0.6134\n",
      "Epoch 3: val_accuracy did not improve from 0.51163\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.6488 - accuracy: 0.6134 - val_loss: 0.7072 - val_accuracy: 0.4884\n",
      "Epoch 4/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6326 - accuracy: 0.6410\n",
      "Epoch 4: val_accuracy improved from 0.51163 to 0.52326, saving model to checkpoints\\best_quanv_demo22.hdf5\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.6326 - accuracy: 0.6410 - val_loss: 0.6971 - val_accuracy: 0.5233\n",
      "Epoch 5/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5968 - accuracy: 0.6570\n",
      "Epoch 5: val_accuracy did not improve from 0.52326\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.5968 - accuracy: 0.6570 - val_loss: 0.6894 - val_accuracy: 0.5233\n",
      "Epoch 6/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5685 - accuracy: 0.6904\n",
      "Epoch 6: val_accuracy improved from 0.52326 to 0.52907, saving model to checkpoints\\best_quanv_demo22.hdf5\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.5685 - accuracy: 0.6904 - val_loss: 0.7010 - val_accuracy: 0.5291\n",
      "Epoch 7/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5308 - accuracy: 0.7267\n",
      "Epoch 7: val_accuracy did not improve from 0.52907\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.5308 - accuracy: 0.7267 - val_loss: 0.7049 - val_accuracy: 0.5233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5243 - accuracy: 0.7238\n",
      "Epoch 8: val_accuracy improved from 0.52907 to 0.54651, saving model to checkpoints\\best_quanv_demo22.hdf5\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.5243 - accuracy: 0.7238 - val_loss: 0.7122 - val_accuracy: 0.5465\n",
      "Epoch 9/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4517 - accuracy: 0.7747\n",
      "Epoch 9: val_accuracy improved from 0.54651 to 0.56977, saving model to checkpoints\\best_quanv_demo22.hdf5\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.4517 - accuracy: 0.7747 - val_loss: 0.7381 - val_accuracy: 0.5698\n",
      "Epoch 10/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4210 - accuracy: 0.7994\n",
      "Epoch 10: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.4210 - accuracy: 0.7994 - val_loss: 0.9453 - val_accuracy: 0.5291\n",
      "Epoch 11/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3582 - accuracy: 0.8372\n",
      "Epoch 11: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.3582 - accuracy: 0.8372 - val_loss: 0.9824 - val_accuracy: 0.5465\n",
      "Epoch 12/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3847 - accuracy: 0.8270\n",
      "Epoch 12: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.3847 - accuracy: 0.8270 - val_loss: 0.9436 - val_accuracy: 0.5523\n",
      "Epoch 13/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2938 - accuracy: 0.8735\n",
      "Epoch 13: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.2938 - accuracy: 0.8735 - val_loss: 0.7896 - val_accuracy: 0.5465\n",
      "Epoch 14/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3450 - accuracy: 0.8416\n",
      "Epoch 14: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.3450 - accuracy: 0.8416 - val_loss: 1.0111 - val_accuracy: 0.5698\n",
      "Epoch 15/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3059 - accuracy: 0.8648\n",
      "Epoch 15: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.3059 - accuracy: 0.8648 - val_loss: 1.8524 - val_accuracy: 0.5116\n",
      "Epoch 16/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3253 - accuracy: 0.8517\n",
      "Epoch 16: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.3253 - accuracy: 0.8517 - val_loss: 0.8824 - val_accuracy: 0.5233\n",
      "Epoch 17/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2471 - accuracy: 0.8953\n",
      "Epoch 17: val_accuracy improved from 0.56977 to 0.57558, saving model to checkpoints\\best_quanv_demo22.hdf5\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.2471 - accuracy: 0.8953 - val_loss: 1.1330 - val_accuracy: 0.5756\n",
      "Epoch 18/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2229 - accuracy: 0.8924\n",
      "Epoch 18: val_accuracy improved from 0.57558 to 0.60465, saving model to checkpoints\\best_quanv_demo22.hdf5\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.2229 - accuracy: 0.8924 - val_loss: 0.9701 - val_accuracy: 0.6047\n",
      "Epoch 19/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1283 - accuracy: 0.9564\n",
      "Epoch 19: val_accuracy did not improve from 0.60465\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1283 - accuracy: 0.9564 - val_loss: 1.3495 - val_accuracy: 0.5000\n",
      "Epoch 20/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0991 - accuracy: 0.9608\n",
      "Epoch 20: val_accuracy improved from 0.60465 to 0.62791, saving model to checkpoints\\best_quanv_demo22.hdf5\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0991 - accuracy: 0.9608 - val_loss: 1.2053 - val_accuracy: 0.6279\n",
      "Epoch 21/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.9593\n",
      "Epoch 21: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1012 - accuracy: 0.9593 - val_loss: 1.6718 - val_accuracy: 0.5349\n",
      "Epoch 22/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2870 - accuracy: 0.8808\n",
      "Epoch 22: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.2870 - accuracy: 0.8808 - val_loss: 1.2486 - val_accuracy: 0.5116\n",
      "Epoch 23/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2494 - accuracy: 0.8881\n",
      "Epoch 23: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.2494 - accuracy: 0.8881 - val_loss: 1.2015 - val_accuracy: 0.4942\n",
      "Epoch 24/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1400 - accuracy: 0.9520\n",
      "Epoch 24: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.1400 - accuracy: 0.9520 - val_loss: 1.3431 - val_accuracy: 0.6105\n",
      "Epoch 25/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1783 - accuracy: 0.9317\n",
      "Epoch 25: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.1783 - accuracy: 0.9317 - val_loss: 1.3694 - val_accuracy: 0.5523\n",
      "Epoch 26/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1732 - accuracy: 0.9346\n",
      "Epoch 26: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.1732 - accuracy: 0.9346 - val_loss: 1.5525 - val_accuracy: 0.5291\n",
      "Epoch 27/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1816 - accuracy: 0.9331\n",
      "Epoch 27: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.1816 - accuracy: 0.9331 - val_loss: 1.1966 - val_accuracy: 0.6279\n",
      "Epoch 28/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 0.9578\n",
      "Epoch 28: val_accuracy did not improve from 0.62791\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1078 - accuracy: 0.9578 - val_loss: 3.5401 - val_accuracy: 0.5116\n",
      "Epoch 29/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1417 - accuracy: 0.9477\n",
      "Epoch 29: val_accuracy improved from 0.62791 to 0.63372, saving model to checkpoints\\best_quanv_demo22.hdf5\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1417 - accuracy: 0.9477 - val_loss: 1.2438 - val_accuracy: 0.6337\n",
      "Epoch 30/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9695\n",
      "Epoch 30: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0965 - accuracy: 0.9695 - val_loss: 1.4163 - val_accuracy: 0.5930\n",
      "Epoch 31/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9797\n",
      "Epoch 31: val_accuracy did not improve from 0.63372\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0527 - accuracy: 0.9797 - val_loss: 1.7826 - val_accuracy: 0.5349\n",
      "Epoch 32/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9753\n",
      "Epoch 32: val_accuracy improved from 0.63372 to 0.65116, saving model to checkpoints\\best_quanv_demo22.hdf5\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0645 - accuracy: 0.9753 - val_loss: 1.2583 - val_accuracy: 0.6512\n",
      "Epoch 33/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1335 - accuracy: 0.9535\n",
      "Epoch 33: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.1335 - accuracy: 0.9535 - val_loss: 1.2079 - val_accuracy: 0.6221\n",
      "Epoch 34/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.9520\n",
      "Epoch 34: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.1159 - accuracy: 0.9520 - val_loss: 1.4417 - val_accuracy: 0.6047\n",
      "Epoch 35/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0959 - accuracy: 0.9622\n",
      "Epoch 35: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0959 - accuracy: 0.9622 - val_loss: 1.3854 - val_accuracy: 0.6105\n",
      "Epoch 36/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.1222 - accuracy: 0.9506\n",
      "Epoch 36: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1222 - accuracy: 0.9506 - val_loss: 1.5041 - val_accuracy: 0.5523\n",
      "Epoch 37/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9840\n",
      "Epoch 37: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0423 - accuracy: 0.9840 - val_loss: 1.6485 - val_accuracy: 0.5640\n",
      "Epoch 38/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9942\n",
      "Epoch 38: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0137 - accuracy: 0.9942 - val_loss: 1.6928 - val_accuracy: 0.6163\n",
      "Epoch 39/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9971\n",
      "Epoch 39: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 1.7624 - val_accuracy: 0.6163\n",
      "Epoch 40/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9927\n",
      "Epoch 40: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0175 - accuracy: 0.9927 - val_loss: 3.1534 - val_accuracy: 0.5174\n",
      "Epoch 41/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9942\n",
      "Epoch 41: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0227 - accuracy: 0.9942 - val_loss: 1.6935 - val_accuracy: 0.5581\n",
      "Epoch 42/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9942\n",
      "Epoch 42: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0344 - accuracy: 0.9942 - val_loss: 1.8534 - val_accuracy: 0.5000\n",
      "Epoch 43/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9826\n",
      "Epoch 43: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0528 - accuracy: 0.9826 - val_loss: 1.7542 - val_accuracy: 0.6047\n",
      "Epoch 44/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.9695\n",
      "Epoch 44: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0909 - accuracy: 0.9695 - val_loss: 1.8691 - val_accuracy: 0.5756\n",
      "Epoch 45/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.9564\n",
      "Epoch 45: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0956 - accuracy: 0.9564 - val_loss: 1.2889 - val_accuracy: 0.6337\n",
      "Epoch 46/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.9724\n",
      "Epoch 46: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0688 - accuracy: 0.9724 - val_loss: 1.7135 - val_accuracy: 0.5407\n",
      "Epoch 47/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 0.9767\n",
      "Epoch 47: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0579 - accuracy: 0.9767 - val_loss: 1.6005 - val_accuracy: 0.6047\n",
      "Epoch 48/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9884\n",
      "Epoch 48: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0407 - accuracy: 0.9884 - val_loss: 1.8151 - val_accuracy: 0.6047\n",
      "Epoch 49/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.9709\n",
      "Epoch 49: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0834 - accuracy: 0.9709 - val_loss: 1.5678 - val_accuracy: 0.6047\n",
      "Epoch 50/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.9840\n",
      "Epoch 50: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0458 - accuracy: 0.9840 - val_loss: 1.8417 - val_accuracy: 0.6047\n",
      "Epoch 51/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9855\n",
      "Epoch 51: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0452 - accuracy: 0.9855 - val_loss: 1.8085 - val_accuracy: 0.5872\n",
      "Epoch 52/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9840\n",
      "Epoch 52: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0461 - accuracy: 0.9840 - val_loss: 2.3906 - val_accuracy: 0.5407\n",
      "Epoch 53/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 0.9811\n",
      "Epoch 53: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0520 - accuracy: 0.9811 - val_loss: 1.9778 - val_accuracy: 0.5581\n",
      "Epoch 54/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9869\n",
      "Epoch 54: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0409 - accuracy: 0.9869 - val_loss: 1.8300 - val_accuracy: 0.5930\n",
      "Epoch 55/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9869\n",
      "Epoch 55: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0304 - accuracy: 0.9869 - val_loss: 1.9095 - val_accuracy: 0.5698\n",
      "Epoch 56/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9767\n",
      "Epoch 56: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0555 - accuracy: 0.9767 - val_loss: 2.0097 - val_accuracy: 0.5407\n",
      "Epoch 57/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9840\n",
      "Epoch 57: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0438 - accuracy: 0.9840 - val_loss: 1.7202 - val_accuracy: 0.6105\n",
      "Epoch 58/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 0.9826\n",
      "Epoch 58: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0532 - accuracy: 0.9826 - val_loss: 2.5066 - val_accuracy: 0.5000\n",
      "Epoch 59/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0694 - accuracy: 0.9811\n",
      "Epoch 59: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0694 - accuracy: 0.9811 - val_loss: 1.6230 - val_accuracy: 0.5930\n",
      "Epoch 60/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0660 - accuracy: 0.9797\n",
      "Epoch 60: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0660 - accuracy: 0.9797 - val_loss: 1.3851 - val_accuracy: 0.6279\n",
      "Epoch 61/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9927\n",
      "Epoch 61: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0159 - accuracy: 0.9927 - val_loss: 1.7310 - val_accuracy: 0.6279\n",
      "Epoch 62/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9942\n",
      "Epoch 62: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0129 - accuracy: 0.9942 - val_loss: 1.8912 - val_accuracy: 0.6395\n",
      "Epoch 63/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9985\n",
      "Epoch 63: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 1.8649 - val_accuracy: 0.5581\n",
      "Epoch 64/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9971\n",
      "Epoch 64: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0077 - accuracy: 0.9971 - val_loss: 2.0331 - val_accuracy: 0.5872\n",
      "Epoch 65/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9985\n",
      "Epoch 65: val_accuracy did not improve from 0.65116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0024 - accuracy: 0.9985 - val_loss: 2.1354 - val_accuracy: 0.6221\n",
      "Epoch 66/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 66: val_accuracy did not improve from 0.65116\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.9212 - val_accuracy: 0.6512\n",
      "Epoch 67/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.3163e-04 - accuracy: 1.0000\n",
      "Epoch 67: val_accuracy improved from 0.65116 to 0.66279, saving model to checkpoints\\best_quanv_demo22.hdf5\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 5.3163e-04 - accuracy: 1.0000 - val_loss: 1.9148 - val_accuracy: 0.6628\n",
      "Epoch 68/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9985\n",
      "Epoch 68: val_accuracy did not improve from 0.66279\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0034 - accuracy: 0.9985 - val_loss: 2.1232 - val_accuracy: 0.6105\n",
      "Epoch 69/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9971\n",
      "Epoch 69: val_accuracy did not improve from 0.66279\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 1.9954 - val_accuracy: 0.6570\n",
      "Epoch 70/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9971\n",
      "Epoch 70: val_accuracy did not improve from 0.66279\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0077 - accuracy: 0.9971 - val_loss: 2.2529 - val_accuracy: 0.5930\n",
      "Epoch 71/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 4.6224e-04 - accuracy: 1.0000\n",
      "Epoch 71: val_accuracy did not improve from 0.66279\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 4.6224e-04 - accuracy: 1.0000 - val_loss: 2.0713 - val_accuracy: 0.6337\n",
      "Epoch 72/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9985  \n",
      "Epoch 72: val_accuracy did not improve from 0.66279\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0032 - accuracy: 0.9985 - val_loss: 1.9851 - val_accuracy: 0.6105\n",
      "Epoch 73/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9913\n",
      "Epoch 73: val_accuracy did not improve from 0.66279\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0218 - accuracy: 0.9913 - val_loss: 2.0390 - val_accuracy: 0.6570\n",
      "Epoch 74/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 74: val_accuracy did not improve from 0.66279\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.3378 - val_accuracy: 0.6337\n",
      "Epoch 75/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9898\n",
      "Epoch 75: val_accuracy did not improve from 0.66279\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0245 - accuracy: 0.9898 - val_loss: 2.2496 - val_accuracy: 0.6628\n",
      "Epoch 76/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9840\n",
      "Epoch 76: val_accuracy improved from 0.66279 to 0.66860, saving model to checkpoints\\best_quanv_demo22.hdf5\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0508 - accuracy: 0.9840 - val_loss: 1.7785 - val_accuracy: 0.6686\n",
      "Epoch 77/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9869\n",
      "Epoch 77: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0274 - accuracy: 0.9869 - val_loss: 2.0418 - val_accuracy: 0.5581\n",
      "Epoch 78/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9826\n",
      "Epoch 78: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0492 - accuracy: 0.9826 - val_loss: 1.7674 - val_accuracy: 0.6163\n",
      "Epoch 79/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9898\n",
      "Epoch 79: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0413 - accuracy: 0.9898 - val_loss: 1.9266 - val_accuracy: 0.5814\n",
      "Epoch 80/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9956\n",
      "Epoch 80: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0309 - accuracy: 0.9956 - val_loss: 1.9196 - val_accuracy: 0.5814\n",
      "Epoch 81/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9956\n",
      "Epoch 81: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0189 - accuracy: 0.9956 - val_loss: 2.8304 - val_accuracy: 0.5233\n",
      "Epoch 82/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 82: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.8338 - val_accuracy: 0.6163\n",
      "Epoch 83/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9942\n",
      "Epoch 83: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0153 - accuracy: 0.9942 - val_loss: 2.3475 - val_accuracy: 0.5640\n",
      "Epoch 84/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9855\n",
      "Epoch 84: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0468 - accuracy: 0.9855 - val_loss: 2.1796 - val_accuracy: 0.5291\n",
      "Epoch 85/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.9811\n",
      "Epoch 85: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0818 - accuracy: 0.9811 - val_loss: 1.4740 - val_accuracy: 0.5349\n",
      "Epoch 86/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9971\n",
      "Epoch 86: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 1.7849 - val_accuracy: 0.5174\n",
      "Epoch 87/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 87: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 2.0328 - val_accuracy: 0.5465\n",
      "Epoch 88/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9942\n",
      "Epoch 88: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0110 - accuracy: 0.9942 - val_loss: 2.1155 - val_accuracy: 0.5814\n",
      "Epoch 89/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9884\n",
      "Epoch 89: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0255 - accuracy: 0.9884 - val_loss: 1.9026 - val_accuracy: 0.5581\n",
      "Epoch 90/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9840\n",
      "Epoch 90: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0447 - accuracy: 0.9840 - val_loss: 4.6222 - val_accuracy: 0.4942\n",
      "Epoch 91/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9680\n",
      "Epoch 91: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0944 - accuracy: 0.9680 - val_loss: 1.8964 - val_accuracy: 0.5174\n",
      "Epoch 92/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.9826\n",
      "Epoch 92: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0629 - accuracy: 0.9826 - val_loss: 2.3085 - val_accuracy: 0.5233\n",
      "Epoch 93/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9898\n",
      "Epoch 93: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0434 - accuracy: 0.9898 - val_loss: 1.5278 - val_accuracy: 0.5640\n",
      "Epoch 94/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9898\n",
      "Epoch 94: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0262 - accuracy: 0.9898 - val_loss: 1.6074 - val_accuracy: 0.5581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 95: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.6772 - val_accuracy: 0.6221\n",
      "Epoch 96/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 96: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.7327 - val_accuracy: 0.6512\n",
      "Epoch 97/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9985\n",
      "Epoch 97: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0035 - accuracy: 0.9985 - val_loss: 1.7748 - val_accuracy: 0.6628\n",
      "Epoch 98/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9956\n",
      "Epoch 98: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0055 - accuracy: 0.9956 - val_loss: 1.8255 - val_accuracy: 0.6279\n",
      "Epoch 99/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9971\n",
      "Epoch 99: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 1.9943 - val_accuracy: 0.6105\n",
      "Epoch 100/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9985\n",
      "Epoch 100: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0029 - accuracy: 0.9985 - val_loss: 1.8957 - val_accuracy: 0.6105\n",
      "Epoch 101/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 101: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9530 - val_accuracy: 0.6047\n",
      "Epoch 102/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 6.8291e-04 - accuracy: 1.0000\n",
      "Epoch 102: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 6.8291e-04 - accuracy: 1.0000 - val_loss: 2.0715 - val_accuracy: 0.6163\n",
      "Epoch 103/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.0201e-04 - accuracy: 1.0000\n",
      "Epoch 103: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 5.0201e-04 - accuracy: 1.0000 - val_loss: 2.0830 - val_accuracy: 0.6163\n",
      "Epoch 104/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.4500e-04 - accuracy: 1.0000\n",
      "Epoch 104: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 3.4500e-04 - accuracy: 1.0000 - val_loss: 2.1418 - val_accuracy: 0.6279\n",
      "Epoch 105/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9985\n",
      "Epoch 105: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0022 - accuracy: 0.9985 - val_loss: 2.0178 - val_accuracy: 0.6512\n",
      "Epoch 106/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.0927e-04 - accuracy: 1.0000\n",
      "Epoch 106: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 5.0927e-04 - accuracy: 1.0000 - val_loss: 2.0795 - val_accuracy: 0.6570\n",
      "Epoch 107/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 4.4636e-04 - accuracy: 1.0000\n",
      "Epoch 107: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 4.4636e-04 - accuracy: 1.0000 - val_loss: 2.1182 - val_accuracy: 0.6512\n",
      "Epoch 108/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.6339e-04 - accuracy: 1.0000\n",
      "Epoch 108: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 1.6339e-04 - accuracy: 1.0000 - val_loss: 2.1438 - val_accuracy: 0.6570\n",
      "Epoch 109/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.6108e-04 - accuracy: 1.0000\n",
      "Epoch 109: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 3.6108e-04 - accuracy: 1.0000 - val_loss: 2.1698 - val_accuracy: 0.6570\n",
      "Epoch 110/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.1039e-04 - accuracy: 1.0000\n",
      "Epoch 110: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 2.1039e-04 - accuracy: 1.0000 - val_loss: 2.1839 - val_accuracy: 0.6628\n",
      "Epoch 111/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.4399e-04 - accuracy: 1.0000\n",
      "Epoch 111: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 3.4399e-04 - accuracy: 1.0000 - val_loss: 2.2832 - val_accuracy: 0.6395\n",
      "Epoch 112/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.4093e-04 - accuracy: 1.0000\n",
      "Epoch 112: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 3.4093e-04 - accuracy: 1.0000 - val_loss: 2.2712 - val_accuracy: 0.6395\n",
      "Epoch 113/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.2433e-04 - accuracy: 1.0000\n",
      "Epoch 113: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 1.2433e-04 - accuracy: 1.0000 - val_loss: 2.3377 - val_accuracy: 0.6395\n",
      "Epoch 114/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9985\n",
      "Epoch 114: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0025 - accuracy: 0.9985 - val_loss: 2.9911 - val_accuracy: 0.5640\n",
      "Epoch 115/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.9942\n",
      "Epoch 115: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0224 - accuracy: 0.9942 - val_loss: 2.4907 - val_accuracy: 0.6163\n",
      "Epoch 116/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9985\n",
      "Epoch 116: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 2.3689 - val_accuracy: 0.6395\n",
      "Epoch 117/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 117: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.4594 - val_accuracy: 0.5930\n",
      "Epoch 118/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 9.1134e-04 - accuracy: 1.0000\n",
      "Epoch 118: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 9.1134e-04 - accuracy: 1.0000 - val_loss: 2.6422 - val_accuracy: 0.6047\n",
      "Epoch 119/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 6.4989e-04 - accuracy: 1.0000\n",
      "Epoch 119: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 6.4989e-04 - accuracy: 1.0000 - val_loss: 2.6499 - val_accuracy: 0.6105\n",
      "Epoch 120/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 120: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6281 - val_accuracy: 0.6047\n",
      "Epoch 121/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 7.2717e-04 - accuracy: 1.0000\n",
      "Epoch 121: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 7.2717e-04 - accuracy: 1.0000 - val_loss: 2.7454 - val_accuracy: 0.5930\n",
      "Epoch 122/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 4.5399e-04 - accuracy: 1.0000\n",
      "Epoch 122: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 4.5399e-04 - accuracy: 1.0000 - val_loss: 2.7277 - val_accuracy: 0.5233\n",
      "Epoch 123/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 123: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8592 - val_accuracy: 0.5872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9985\n",
      "Epoch 124: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0036 - accuracy: 0.9985 - val_loss: 2.7608 - val_accuracy: 0.6105\n",
      "Epoch 125/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 125: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7873 - val_accuracy: 0.6047\n",
      "Epoch 126/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9913\n",
      "Epoch 126: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0204 - accuracy: 0.9913 - val_loss: 3.5513 - val_accuracy: 0.5640\n",
      "Epoch 127/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.9709\n",
      "Epoch 127: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.1037 - accuracy: 0.9709 - val_loss: 1.8430 - val_accuracy: 0.5814\n",
      "Epoch 128/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9898\n",
      "Epoch 128: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0313 - accuracy: 0.9898 - val_loss: 2.2200 - val_accuracy: 0.5581\n",
      "Epoch 129/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 129: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.9288 - val_accuracy: 0.6337\n",
      "Epoch 130/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9956\n",
      "Epoch 130: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0087 - accuracy: 0.9956 - val_loss: 1.9710 - val_accuracy: 0.6395\n",
      "Epoch 131/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9927\n",
      "Epoch 131: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0281 - accuracy: 0.9927 - val_loss: 2.1482 - val_accuracy: 0.5872\n",
      "Epoch 132/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9971\n",
      "Epoch 132: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0076 - accuracy: 0.9971 - val_loss: 2.2052 - val_accuracy: 0.6047\n",
      "Epoch 133/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9942\n",
      "Epoch 133: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0127 - accuracy: 0.9942 - val_loss: 2.5482 - val_accuracy: 0.5988\n",
      "Epoch 134/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9971\n",
      "Epoch 134: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0144 - accuracy: 0.9971 - val_loss: 2.4481 - val_accuracy: 0.6337\n",
      "Epoch 135/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 135: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0672 - val_accuracy: 0.6221\n",
      "Epoch 136/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9985  \n",
      "Epoch 136: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 2.2998 - val_accuracy: 0.5814\n",
      "Epoch 137/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9898\n",
      "Epoch 137: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0263 - accuracy: 0.9898 - val_loss: 2.1505 - val_accuracy: 0.5756\n",
      "Epoch 138/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9985\n",
      "Epoch 138: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 2.5506 - val_accuracy: 0.5407\n",
      "Epoch 139/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9985\n",
      "Epoch 139: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0112 - accuracy: 0.9985 - val_loss: 2.3016 - val_accuracy: 0.5814\n",
      "Epoch 140/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 140: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.4754 - val_accuracy: 0.5872\n",
      "Epoch 141/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 9.4752e-04 - accuracy: 1.0000\n",
      "Epoch 141: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 9.4752e-04 - accuracy: 1.0000 - val_loss: 2.4879 - val_accuracy: 0.5930\n",
      "Epoch 142/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.6162e-04 - accuracy: 1.0000\n",
      "Epoch 142: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 3.6162e-04 - accuracy: 1.0000 - val_loss: 2.4887 - val_accuracy: 0.5872\n",
      "Epoch 143/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.4241e-04 - accuracy: 1.0000\n",
      "Epoch 143: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 3.4241e-04 - accuracy: 1.0000 - val_loss: 2.4534 - val_accuracy: 0.5872\n",
      "Epoch 144/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 7.3752e-04 - accuracy: 1.0000\n",
      "Epoch 144: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 7.3752e-04 - accuracy: 1.0000 - val_loss: 2.3648 - val_accuracy: 0.6395\n",
      "Epoch 145/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.2132e-04 - accuracy: 1.0000\n",
      "Epoch 145: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 2.2132e-04 - accuracy: 1.0000 - val_loss: 2.3691 - val_accuracy: 0.6163\n",
      "Epoch 146/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9985\n",
      "Epoch 146: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0030 - accuracy: 0.9985 - val_loss: 2.5393 - val_accuracy: 0.6047\n",
      "Epoch 147/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9971\n",
      "Epoch 147: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0062 - accuracy: 0.9971 - val_loss: 2.5689 - val_accuracy: 0.5640\n",
      "Epoch 148/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.7838e-04 - accuracy: 1.0000\n",
      "Epoch 148: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 1.7838e-04 - accuracy: 1.0000 - val_loss: 2.6450 - val_accuracy: 0.6047\n",
      "Epoch 149/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9956\n",
      "Epoch 149: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0181 - accuracy: 0.9956 - val_loss: 2.3411 - val_accuracy: 0.6047\n",
      "Epoch 150/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9971\n",
      "Epoch 150: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0045 - accuracy: 0.9971 - val_loss: 2.6133 - val_accuracy: 0.6047\n",
      "Epoch 151/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9971\n",
      "Epoch 151: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0051 - accuracy: 0.9971 - val_loss: 2.4829 - val_accuracy: 0.5756\n",
      "Epoch 152/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 152: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.3523 - val_accuracy: 0.6163\n",
      "Epoch 153/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 8.1467e-04 - accuracy: 1.0000\n",
      "Epoch 153: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 8.1467e-04 - accuracy: 1.0000 - val_loss: 2.4121 - val_accuracy: 0.6163\n",
      "Epoch 154/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.8285e-04 - accuracy: 1.0000\n",
      "Epoch 154: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 5.8285e-04 - accuracy: 1.0000 - val_loss: 2.4150 - val_accuracy: 0.6512\n",
      "Epoch 155/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 155: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.3908 - val_accuracy: 0.6221\n",
      "Epoch 156/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.4721e-04 - accuracy: 1.0000\n",
      "Epoch 156: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 2.4721e-04 - accuracy: 1.0000 - val_loss: 2.4243 - val_accuracy: 0.6221\n",
      "Epoch 157/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.3243e-04 - accuracy: 1.0000\n",
      "Epoch 157: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 2.3243e-04 - accuracy: 1.0000 - val_loss: 2.4580 - val_accuracy: 0.6279\n",
      "Epoch 158/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 158: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.0585 - val_accuracy: 0.5640\n",
      "Epoch 159/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 159: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 2.4795 - val_accuracy: 0.5988\n",
      "Epoch 160/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 7.8302e-04 - accuracy: 1.0000\n",
      "Epoch 160: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 7.8302e-04 - accuracy: 1.0000 - val_loss: 2.7522 - val_accuracy: 0.6163\n",
      "Epoch 161/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.1589e-04 - accuracy: 1.0000\n",
      "Epoch 161: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 2.1589e-04 - accuracy: 1.0000 - val_loss: 2.6592 - val_accuracy: 0.6163\n",
      "Epoch 162/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.3619e-04 - accuracy: 1.0000\n",
      "Epoch 162: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 3.3619e-04 - accuracy: 1.0000 - val_loss: 2.6231 - val_accuracy: 0.6105\n",
      "Epoch 163/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 4.1438e-04 - accuracy: 1.0000\n",
      "Epoch 163: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 4.1438e-04 - accuracy: 1.0000 - val_loss: 2.7987 - val_accuracy: 0.6105\n",
      "Epoch 164/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9985\n",
      "Epoch 164: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0015 - accuracy: 0.9985 - val_loss: 2.6456 - val_accuracy: 0.5872\n",
      "Epoch 165/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9971\n",
      "Epoch 165: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0136 - accuracy: 0.9971 - val_loss: 2.6336 - val_accuracy: 0.5407\n",
      "Epoch 166/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9855\n",
      "Epoch 166: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0365 - accuracy: 0.9855 - val_loss: 3.7366 - val_accuracy: 0.5174\n",
      "Epoch 167/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9971\n",
      "Epoch 167: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 2.9322 - val_accuracy: 0.5872\n",
      "Epoch 168/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9971\n",
      "Epoch 168: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0040 - accuracy: 0.9971 - val_loss: 2.3330 - val_accuracy: 0.5988\n",
      "Epoch 169/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9971\n",
      "Epoch 169: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0326 - accuracy: 0.9971 - val_loss: 2.4976 - val_accuracy: 0.5581\n",
      "Epoch 170/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9927\n",
      "Epoch 170: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0177 - accuracy: 0.9927 - val_loss: 2.1921 - val_accuracy: 0.6105\n",
      "Epoch 171/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9971\n",
      "Epoch 171: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 2.0363 - val_accuracy: 0.5872\n",
      "Epoch 172/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 172: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.0465 - val_accuracy: 0.5872\n",
      "Epoch 173/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 7.3042e-04 - accuracy: 1.0000\n",
      "Epoch 173: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 7.3042e-04 - accuracy: 1.0000 - val_loss: 2.0861 - val_accuracy: 0.6105\n",
      "Epoch 174/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.9302e-04 - accuracy: 1.0000\n",
      "Epoch 174: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 3.9302e-04 - accuracy: 1.0000 - val_loss: 2.1213 - val_accuracy: 0.6163\n",
      "Epoch 175/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9956\n",
      "Epoch 175: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 2.4280 - val_accuracy: 0.5523\n",
      "Epoch 176/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9971\n",
      "Epoch 176: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0063 - accuracy: 0.9971 - val_loss: 2.3234 - val_accuracy: 0.5930\n",
      "Epoch 177/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 177: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 2.4418 - val_accuracy: 0.5698\n",
      "Epoch 178/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 8.4180e-04 - accuracy: 1.0000\n",
      "Epoch 178: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 8.4180e-04 - accuracy: 1.0000 - val_loss: 2.5918 - val_accuracy: 0.5523\n",
      "Epoch 179/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 4.1670e-04 - accuracy: 1.0000\n",
      "Epoch 179: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 4.1670e-04 - accuracy: 1.0000 - val_loss: 2.6047 - val_accuracy: 0.5523\n",
      "Epoch 180/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9985  \n",
      "Epoch 180: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0017 - accuracy: 0.9985 - val_loss: 2.5209 - val_accuracy: 0.5581\n",
      "Epoch 181/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9985\n",
      "Epoch 181: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0020 - accuracy: 0.9985 - val_loss: 2.3833 - val_accuracy: 0.6105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.0361e-04 - accuracy: 1.0000\n",
      "Epoch 182: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 2.0361e-04 - accuracy: 1.0000 - val_loss: 2.3901 - val_accuracy: 0.6105\n",
      "Epoch 183/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.4773e-04 - accuracy: 1.0000\n",
      "Epoch 183: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 1.4773e-04 - accuracy: 1.0000 - val_loss: 2.4056 - val_accuracy: 0.6105\n",
      "Epoch 184/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 0.9855\n",
      "Epoch 184: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0541 - accuracy: 0.9855 - val_loss: 2.8544 - val_accuracy: 0.5058\n",
      "Epoch 185/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9913\n",
      "Epoch 185: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0507 - accuracy: 0.9913 - val_loss: 1.7729 - val_accuracy: 0.5988\n",
      "Epoch 186/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.9898\n",
      "Epoch 186: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0355 - accuracy: 0.9898 - val_loss: 1.6213 - val_accuracy: 0.5814\n",
      "Epoch 187/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9971\n",
      "Epoch 187: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 1.9884 - val_accuracy: 0.6105\n",
      "Epoch 188/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 188: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.1274 - val_accuracy: 0.5930\n",
      "Epoch 189/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 189: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 1.8949 - val_accuracy: 0.5988\n",
      "Epoch 190/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 190: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.8652 - val_accuracy: 0.6047\n",
      "Epoch 191/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9884\n",
      "Epoch 191: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0264 - accuracy: 0.9884 - val_loss: 2.2990 - val_accuracy: 0.5930\n",
      "Epoch 192/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9898\n",
      "Epoch 192: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0288 - accuracy: 0.9898 - val_loss: 2.0998 - val_accuracy: 0.5581\n",
      "Epoch 193/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9956\n",
      "Epoch 193: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0262 - accuracy: 0.9956 - val_loss: 2.1240 - val_accuracy: 0.5872\n",
      "Epoch 194/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9956\n",
      "Epoch 194: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 1.9839 - val_accuracy: 0.5814\n",
      "Epoch 195/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9898\n",
      "Epoch 195: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0210 - accuracy: 0.9898 - val_loss: 1.8453 - val_accuracy: 0.5930\n",
      "Epoch 196/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9971\n",
      "Epoch 196: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 2.0452 - val_accuracy: 0.5465\n",
      "Epoch 197/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9942\n",
      "Epoch 197: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0138 - accuracy: 0.9942 - val_loss: 2.1297 - val_accuracy: 0.5814\n",
      "Epoch 198/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9985\n",
      "Epoch 198: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 1.9206 - val_accuracy: 0.6337\n",
      "Epoch 199/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 199: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.0420 - val_accuracy: 0.5988\n",
      "Epoch 200/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 4.7268e-04 - accuracy: 1.0000\n",
      "Epoch 200: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 4.7268e-04 - accuracy: 1.0000 - val_loss: 2.0347 - val_accuracy: 0.6221\n",
      "Epoch 201/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 9.2822e-04 - accuracy: 1.0000\n",
      "Epoch 201: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 9.2822e-04 - accuracy: 1.0000 - val_loss: 2.1103 - val_accuracy: 0.6221\n",
      "Epoch 202/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.5789e-04 - accuracy: 1.0000\n",
      "Epoch 202: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 5.5789e-04 - accuracy: 1.0000 - val_loss: 2.1694 - val_accuracy: 0.6105\n",
      "Epoch 203/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 4.9645e-04 - accuracy: 1.0000\n",
      "Epoch 203: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 4.9645e-04 - accuracy: 1.0000 - val_loss: 2.1832 - val_accuracy: 0.6047\n",
      "Epoch 204/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 204: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.4788 - val_accuracy: 0.6453\n",
      "Epoch 205/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 4.3280e-04 - accuracy: 1.0000\n",
      "Epoch 205: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 4.3280e-04 - accuracy: 1.0000 - val_loss: 2.3526 - val_accuracy: 0.6163\n",
      "Epoch 206/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 4.7431e-04 - accuracy: 1.0000\n",
      "Epoch 206: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 4.7431e-04 - accuracy: 1.0000 - val_loss: 2.3159 - val_accuracy: 0.5988\n",
      "Epoch 207/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.9699e-04 - accuracy: 1.0000\n",
      "Epoch 207: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 2.9699e-04 - accuracy: 1.0000 - val_loss: 2.3096 - val_accuracy: 0.6105\n",
      "Epoch 208/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.9409e-04 - accuracy: 1.0000\n",
      "Epoch 208: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 3.9409e-04 - accuracy: 1.0000 - val_loss: 2.2846 - val_accuracy: 0.6105\n",
      "Epoch 209/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 6.9534e-04 - accuracy: 1.0000\n",
      "Epoch 209: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 6.9534e-04 - accuracy: 1.0000 - val_loss: 2.3912 - val_accuracy: 0.6105\n",
      "Epoch 210/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.8529e-04 - accuracy: 1.0000\n",
      "Epoch 210: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 1.8529e-04 - accuracy: 1.0000 - val_loss: 2.4246 - val_accuracy: 0.6163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 7.4700e-04 - accuracy: 1.0000\n",
      "Epoch 211: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 7.4700e-04 - accuracy: 1.0000 - val_loss: 2.3904 - val_accuracy: 0.6105\n",
      "Epoch 212/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.4130e-04 - accuracy: 1.0000\n",
      "Epoch 212: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 2.4130e-04 - accuracy: 1.0000 - val_loss: 2.4138 - val_accuracy: 0.6047\n",
      "Epoch 213/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.1468e-04 - accuracy: 1.0000\n",
      "Epoch 213: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 1.1468e-04 - accuracy: 1.0000 - val_loss: 2.4486 - val_accuracy: 0.6105\n",
      "Epoch 214/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.0048e-04 - accuracy: 1.0000\n",
      "Epoch 214: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 1.0048e-04 - accuracy: 1.0000 - val_loss: 2.4589 - val_accuracy: 0.6105\n",
      "Epoch 215/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 9.4578e-05 - accuracy: 1.0000\n",
      "Epoch 215: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 9.4578e-05 - accuracy: 1.0000 - val_loss: 2.4559 - val_accuracy: 0.6047\n",
      "Epoch 216/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 6.4079e-05 - accuracy: 1.0000\n",
      "Epoch 216: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 6.4079e-05 - accuracy: 1.0000 - val_loss: 2.4602 - val_accuracy: 0.6047\n",
      "Epoch 217/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 6.9445e-05 - accuracy: 1.0000\n",
      "Epoch 217: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 6.9445e-05 - accuracy: 1.0000 - val_loss: 2.4745 - val_accuracy: 0.6047\n",
      "Epoch 218/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.9285e-04 - accuracy: 1.0000\n",
      "Epoch 218: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 2.9285e-04 - accuracy: 1.0000 - val_loss: 2.4915 - val_accuracy: 0.6047\n",
      "Epoch 219/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.6415e-04 - accuracy: 1.0000\n",
      "Epoch 219: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 2.6415e-04 - accuracy: 1.0000 - val_loss: 2.4880 - val_accuracy: 0.6163\n",
      "Epoch 220/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 8.9495e-05 - accuracy: 1.0000\n",
      "Epoch 220: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 8.9495e-05 - accuracy: 1.0000 - val_loss: 2.5165 - val_accuracy: 0.6105\n",
      "Epoch 221/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.5287e-04 - accuracy: 1.0000\n",
      "Epoch 221: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 1.5287e-04 - accuracy: 1.0000 - val_loss: 2.5515 - val_accuracy: 0.6047\n",
      "Epoch 222/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.9628e-05 - accuracy: 1.0000\n",
      "Epoch 222: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 5.9628e-05 - accuracy: 1.0000 - val_loss: 2.5540 - val_accuracy: 0.6105\n",
      "Epoch 223/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 8.1924e-05 - accuracy: 1.0000\n",
      "Epoch 223: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 8.1924e-05 - accuracy: 1.0000 - val_loss: 2.5499 - val_accuracy: 0.6047\n",
      "Epoch 224/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 6.1341e-05 - accuracy: 1.0000\n",
      "Epoch 224: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 6.1341e-05 - accuracy: 1.0000 - val_loss: 2.5473 - val_accuracy: 0.6105\n",
      "Epoch 225/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.6120e-04 - accuracy: 1.0000\n",
      "Epoch 225: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 1.6120e-04 - accuracy: 1.0000 - val_loss: 2.5510 - val_accuracy: 0.6105\n",
      "Epoch 226/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 8.8530e-05 - accuracy: 1.0000\n",
      "Epoch 226: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 8.8530e-05 - accuracy: 1.0000 - val_loss: 2.5480 - val_accuracy: 0.6105\n",
      "Epoch 227/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 9.2729e-05 - accuracy: 1.0000\n",
      "Epoch 227: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 9.2729e-05 - accuracy: 1.0000 - val_loss: 2.5668 - val_accuracy: 0.6221\n",
      "Epoch 228/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 7.1735e-05 - accuracy: 1.0000\n",
      "Epoch 228: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 7.1735e-05 - accuracy: 1.0000 - val_loss: 2.5747 - val_accuracy: 0.6221\n",
      "Epoch 229/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 6.4983e-05 - accuracy: 1.0000\n",
      "Epoch 229: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 6.4983e-05 - accuracy: 1.0000 - val_loss: 2.5822 - val_accuracy: 0.6221\n",
      "Epoch 230/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 4.4473e-05 - accuracy: 1.0000\n",
      "Epoch 230: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 4.4473e-05 - accuracy: 1.0000 - val_loss: 2.5912 - val_accuracy: 0.6221\n",
      "Epoch 231/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 4.0193e-05 - accuracy: 1.0000\n",
      "Epoch 231: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 4.0193e-05 - accuracy: 1.0000 - val_loss: 2.5998 - val_accuracy: 0.6221\n",
      "Epoch 232/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 6.4742e-05 - accuracy: 1.0000\n",
      "Epoch 232: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 6.4742e-05 - accuracy: 1.0000 - val_loss: 2.5968 - val_accuracy: 0.6221\n",
      "Epoch 233/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.9326e-05 - accuracy: 1.0000\n",
      "Epoch 233: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 3.9326e-05 - accuracy: 1.0000 - val_loss: 2.6026 - val_accuracy: 0.6105\n",
      "Epoch 234/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.4761e-05 - accuracy: 1.0000\n",
      "Epoch 234: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 5.4761e-05 - accuracy: 1.0000 - val_loss: 2.6193 - val_accuracy: 0.6163\n",
      "Epoch 235/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.4345e-04 - accuracy: 1.0000\n",
      "Epoch 235: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 2.4345e-04 - accuracy: 1.0000 - val_loss: 2.6254 - val_accuracy: 0.6047\n",
      "Epoch 236/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.1266e-05 - accuracy: 1.0000\n",
      "Epoch 236: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 3.1266e-05 - accuracy: 1.0000 - val_loss: 2.6243 - val_accuracy: 0.6047\n",
      "Epoch 237/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 4.0780e-05 - accuracy: 1.0000\n",
      "Epoch 237: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 4.0780e-05 - accuracy: 1.0000 - val_loss: 2.6306 - val_accuracy: 0.6105\n",
      "Epoch 238/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.9869e-05 - accuracy: 1.0000\n",
      "Epoch 238: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 5.9869e-05 - accuracy: 1.0000 - val_loss: 2.6325 - val_accuracy: 0.6163\n",
      "Epoch 239/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9956\n",
      "Epoch 239: val_accuracy did not improve from 0.66860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0087 - accuracy: 0.9956 - val_loss: 3.2942 - val_accuracy: 0.5581\n",
      "Epoch 240/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.9797\n",
      "Epoch 240: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0976 - accuracy: 0.9797 - val_loss: 2.4438 - val_accuracy: 0.5465\n",
      "Epoch 241/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9840\n",
      "Epoch 241: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0401 - accuracy: 0.9840 - val_loss: 1.7356 - val_accuracy: 0.5698\n",
      "Epoch 242/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9942\n",
      "Epoch 242: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0135 - accuracy: 0.9942 - val_loss: 1.8824 - val_accuracy: 0.5756\n",
      "Epoch 243/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9971\n",
      "Epoch 243: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 1.9117 - val_accuracy: 0.5814\n",
      "Epoch 244/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9971\n",
      "Epoch 244: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0051 - accuracy: 0.9971 - val_loss: 1.9380 - val_accuracy: 0.5872\n",
      "Epoch 245/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 245: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9679 - val_accuracy: 0.6105\n",
      "Epoch 246/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 246: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.0372 - val_accuracy: 0.5814\n",
      "Epoch 247/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.3170e-04 - accuracy: 1.0000\n",
      "Epoch 247: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 5.3170e-04 - accuracy: 1.0000 - val_loss: 2.0631 - val_accuracy: 0.5930\n",
      "Epoch 248/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.8335e-04 - accuracy: 1.0000\n",
      "Epoch 248: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 3.8335e-04 - accuracy: 1.0000 - val_loss: 2.1185 - val_accuracy: 0.5872\n",
      "Epoch 249/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.3253e-04 - accuracy: 1.0000\n",
      "Epoch 249: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 3.3253e-04 - accuracy: 1.0000 - val_loss: 2.1568 - val_accuracy: 0.5930\n",
      "Epoch 250/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 250: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.1952 - val_accuracy: 0.5640\n",
      "=== Batch Size:  16\n"
     ]
    }
   ],
   "source": [
    "if ql2 == 1:\n",
    "    ## For Quanv Exp.\n",
    "    early_stop = EarlyStopping(monitor='val_loss', mode='min', \n",
    "                               verbose=1, patience=10, min_delta=0.0001)\n",
    "\n",
    "    checkpoint = ModelCheckpoint('checkpoints/best_quanv_demo22.hdf5', monitor='val_accuracy', \n",
    "                                 verbose=1, save_best_only=True, mode='max')\n",
    "    if net == 0:\n",
    "        modelq = dense_Model(x_train[0], labels)\n",
    "    elif net == 1:\n",
    "        modelq2 = attrnn_Model(q_train2[0], labels)\n",
    "    modelq2.summary()\n",
    "\n",
    "    q_history2 = modelq2.fit(\n",
    "        x=q_train2, \n",
    "        y=y_train,\n",
    "        epochs=eps, \n",
    "        callbacks=[checkpoint], \n",
    "        batch_size=bsize, \n",
    "        validation_data=(q_valid2,y_valid)\n",
    "    )\n",
    "\n",
    "    keras.models.save_model(modelq2, 'checkpoints/'+ data_ix + '_quanv_mode_demo22.hdf5') \n",
    "    modelq2.save('checkpoints/'+ data_ix + '_demo22.hdf5')\n",
    "\n",
    "    print(\"=== Batch Size: \", bsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "NZwyLcNwvNip",
   "metadata": {
    "id": "NZwyLcNwvNip"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_22 (InputLayer)          [(None, 30, 63, 2)]  0           []                               \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 30, 63, 2)   8           ['input_22[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " permute_10 (Permute)           (None, 63, 30, 2)    0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " ConvUp (Conv2D)                (None, 63, 30, 16)   176         ['permute_10[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 63, 30, 16)  64          ['ConvUp[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " ConvDown1 (Conv2D)             (None, 63, 30, 32)   2592        ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 63, 30, 32)  128         ['ConvDown1[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " ConvDown2 (Conv2D)             (None, 63, 30, 16)   2576        ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 63, 30, 16)  64          ['ConvDown2[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 63, 30, 32)   0           ['batch_normalization_51[0][0]', \n",
      "                                                                  'batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " ConvMerge (Conv2D)             (None, 63, 30, 1)    161         ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 63, 30, 1)   4           ['ConvMerge[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " squeeze_last_dim (Lambda)      (None, 63, 30)       0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " bidirectional_20 (Bidirectiona  (None, 63, 128)     48640       ['squeeze_last_dim[0][0]']       \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " bidirectional_21 (Bidirectiona  (None, 63, 128)     98816       ['bidirectional_20[0][0]']       \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " lambda_10 (Lambda)             (None, 128)          0           ['bidirectional_21[0][0]']       \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 128)          16512       ['lambda_10[0][0]']              \n",
      "                                                                                                  \n",
      " dot_20 (Dot)                   (None, 63)           0           ['dense_30[0][0]',               \n",
      "                                                                  'bidirectional_21[0][0]']       \n",
      "                                                                                                  \n",
      " attSoftmax (Softmax)           (None, 63)           0           ['dot_20[0][0]']                 \n",
      "                                                                                                  \n",
      " dot_21 (Dot)                   (None, 128)          0           ['attSoftmax[0][0]',             \n",
      "                                                                  'bidirectional_21[0][0]']       \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 64)           8256        ['dot_21[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 32)           2080        ['dense_31[0][0]']               \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 2)            66          ['dense_32[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 180,143\n",
      "Trainable params: 180,009\n",
      "Non-trainable params: 134\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6960 - accuracy: 0.5349\n",
      "Epoch 1: val_accuracy improved from -inf to 0.51163, saving model to checkpoints\\best_quanv_demo23.hdf5\n",
      "43/43 [==============================] - 13s 131ms/step - loss: 0.6960 - accuracy: 0.5349 - val_loss: 0.6942 - val_accuracy: 0.5116\n",
      "Epoch 2/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6844 - accuracy: 0.5683\n",
      "Epoch 2: val_accuracy did not improve from 0.51163\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.6844 - accuracy: 0.5683 - val_loss: 0.7059 - val_accuracy: 0.4884\n",
      "Epoch 3/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6794 - accuracy: 0.5669\n",
      "Epoch 3: val_accuracy improved from 0.51163 to 0.51744, saving model to checkpoints\\best_quanv_demo23.hdf5\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.6794 - accuracy: 0.5669 - val_loss: 0.6973 - val_accuracy: 0.5174\n",
      "Epoch 4/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6628 - accuracy: 0.5988\n",
      "Epoch 4: val_accuracy did not improve from 0.51744\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.6628 - accuracy: 0.5988 - val_loss: 0.6972 - val_accuracy: 0.5174\n",
      "Epoch 5/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6541 - accuracy: 0.6090\n",
      "Epoch 5: val_accuracy did not improve from 0.51744\n",
      "43/43 [==============================] - 3s 73ms/step - loss: 0.6541 - accuracy: 0.6090 - val_loss: 0.7038 - val_accuracy: 0.4826\n",
      "Epoch 6/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6305 - accuracy: 0.6410\n",
      "Epoch 6: val_accuracy improved from 0.51744 to 0.58140, saving model to checkpoints\\best_quanv_demo23.hdf5\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.6305 - accuracy: 0.6410 - val_loss: 0.6898 - val_accuracy: 0.5814\n",
      "Epoch 7/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6259 - accuracy: 0.6424\n",
      "Epoch 7: val_accuracy did not improve from 0.58140\n",
      "43/43 [==============================] - 2s 58ms/step - loss: 0.6259 - accuracy: 0.6424 - val_loss: 0.6871 - val_accuracy: 0.5523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6126 - accuracy: 0.6497\n",
      "Epoch 8: val_accuracy did not improve from 0.58140\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 0.6126 - accuracy: 0.6497 - val_loss: 0.6941 - val_accuracy: 0.5581\n",
      "Epoch 9/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5971 - accuracy: 0.6337\n",
      "Epoch 9: val_accuracy did not improve from 0.58140\n",
      "43/43 [==============================] - 3s 74ms/step - loss: 0.5971 - accuracy: 0.6337 - val_loss: 0.7043 - val_accuracy: 0.5291\n",
      "Epoch 10/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5600 - accuracy: 0.6933\n",
      "Epoch 10: val_accuracy did not improve from 0.58140\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.5600 - accuracy: 0.6933 - val_loss: 0.8298 - val_accuracy: 0.5581\n",
      "Epoch 11/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5934 - accuracy: 0.6555\n",
      "Epoch 11: val_accuracy did not improve from 0.58140\n",
      "43/43 [==============================] - 3s 82ms/step - loss: 0.5934 - accuracy: 0.6555 - val_loss: 0.7396 - val_accuracy: 0.5407\n",
      "Epoch 12/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5330 - accuracy: 0.7137\n",
      "Epoch 12: val_accuracy did not improve from 0.58140\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.5330 - accuracy: 0.7137 - val_loss: 0.9694 - val_accuracy: 0.4884\n",
      "Epoch 13/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5048 - accuracy: 0.7398\n",
      "Epoch 13: val_accuracy did not improve from 0.58140\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.5048 - accuracy: 0.7398 - val_loss: 1.5708 - val_accuracy: 0.4942\n",
      "Epoch 14/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4853 - accuracy: 0.7529\n",
      "Epoch 14: val_accuracy improved from 0.58140 to 0.58721, saving model to checkpoints\\best_quanv_demo23.hdf5\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.4853 - accuracy: 0.7529 - val_loss: 0.7410 - val_accuracy: 0.5872\n",
      "Epoch 15/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5013 - accuracy: 0.7456\n",
      "Epoch 15: val_accuracy improved from 0.58721 to 0.60465, saving model to checkpoints\\best_quanv_demo23.hdf5\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.5013 - accuracy: 0.7456 - val_loss: 0.7185 - val_accuracy: 0.6047\n",
      "Epoch 16/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4684 - accuracy: 0.7805\n",
      "Epoch 16: val_accuracy did not improve from 0.60465\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.4684 - accuracy: 0.7805 - val_loss: 0.8066 - val_accuracy: 0.5872\n",
      "Epoch 17/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4153 - accuracy: 0.8125\n",
      "Epoch 17: val_accuracy did not improve from 0.60465\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.4153 - accuracy: 0.8125 - val_loss: 0.9324 - val_accuracy: 0.5640\n",
      "Epoch 18/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4093 - accuracy: 0.8023\n",
      "Epoch 18: val_accuracy did not improve from 0.60465\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.4093 - accuracy: 0.8023 - val_loss: 0.9322 - val_accuracy: 0.5872\n",
      "Epoch 19/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3766 - accuracy: 0.8212\n",
      "Epoch 19: val_accuracy did not improve from 0.60465\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.3766 - accuracy: 0.8212 - val_loss: 1.0325 - val_accuracy: 0.5523\n",
      "Epoch 20/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3736 - accuracy: 0.8270\n",
      "Epoch 20: val_accuracy did not improve from 0.60465\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.3736 - accuracy: 0.8270 - val_loss: 1.8512 - val_accuracy: 0.4884\n",
      "Epoch 21/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3608 - accuracy: 0.8445\n",
      "Epoch 21: val_accuracy did not improve from 0.60465\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.3608 - accuracy: 0.8445 - val_loss: 1.5284 - val_accuracy: 0.5058\n",
      "Epoch 22/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3207 - accuracy: 0.8547\n",
      "Epoch 22: val_accuracy did not improve from 0.60465\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.3207 - accuracy: 0.8547 - val_loss: 2.8619 - val_accuracy: 0.4942\n",
      "Epoch 23/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3772 - accuracy: 0.8183\n",
      "Epoch 23: val_accuracy did not improve from 0.60465\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.3772 - accuracy: 0.8183 - val_loss: 0.9245 - val_accuracy: 0.4826\n",
      "Epoch 24/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3103 - accuracy: 0.8445\n",
      "Epoch 24: val_accuracy did not improve from 0.60465\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.3103 - accuracy: 0.8445 - val_loss: 1.0439 - val_accuracy: 0.5872\n",
      "Epoch 25/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2782 - accuracy: 0.8706\n",
      "Epoch 25: val_accuracy did not improve from 0.60465\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.2782 - accuracy: 0.8706 - val_loss: 1.0858 - val_accuracy: 0.5523\n",
      "Epoch 26/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3366 - accuracy: 0.8532\n",
      "Epoch 26: val_accuracy did not improve from 0.60465\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.3366 - accuracy: 0.8532 - val_loss: 1.2418 - val_accuracy: 0.5581\n",
      "Epoch 27/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3503 - accuracy: 0.8358\n",
      "Epoch 27: val_accuracy did not improve from 0.60465\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.3503 - accuracy: 0.8358 - val_loss: 1.0301 - val_accuracy: 0.5640\n",
      "Epoch 28/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2471 - accuracy: 0.8895\n",
      "Epoch 28: val_accuracy did not improve from 0.60465\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.2471 - accuracy: 0.8895 - val_loss: 1.1845 - val_accuracy: 0.5349\n",
      "Epoch 29/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2262 - accuracy: 0.8997\n",
      "Epoch 29: val_accuracy did not improve from 0.60465\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.2262 - accuracy: 0.8997 - val_loss: 1.1780 - val_accuracy: 0.5581\n",
      "Epoch 30/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2739 - accuracy: 0.8721\n",
      "Epoch 30: val_accuracy did not improve from 0.60465\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.2739 - accuracy: 0.8721 - val_loss: 1.1080 - val_accuracy: 0.5640\n",
      "Epoch 31/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1676 - accuracy: 0.9186\n",
      "Epoch 31: val_accuracy did not improve from 0.60465\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.1676 - accuracy: 0.9186 - val_loss: 0.9391 - val_accuracy: 0.5116\n",
      "Epoch 32/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2098 - accuracy: 0.9084\n",
      "Epoch 32: val_accuracy improved from 0.60465 to 0.66860, saving model to checkpoints\\best_quanv_demo23.hdf5\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.2098 - accuracy: 0.9084 - val_loss: 1.0569 - val_accuracy: 0.6686\n",
      "Epoch 33/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3127 - accuracy: 0.8692\n",
      "Epoch 33: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.3127 - accuracy: 0.8692 - val_loss: 0.7973 - val_accuracy: 0.6047\n",
      "Epoch 34/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1714 - accuracy: 0.9288\n",
      "Epoch 34: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.1714 - accuracy: 0.9288 - val_loss: 1.8289 - val_accuracy: 0.5581\n",
      "Epoch 35/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1056 - accuracy: 0.9564\n",
      "Epoch 35: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.1056 - accuracy: 0.9564 - val_loss: 1.4187 - val_accuracy: 0.5930\n",
      "Epoch 36/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1933 - accuracy: 0.9142\n",
      "Epoch 36: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.1933 - accuracy: 0.9142 - val_loss: 1.4273 - val_accuracy: 0.5756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2434 - accuracy: 0.8823\n",
      "Epoch 37: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.2434 - accuracy: 0.8823 - val_loss: 1.8828 - val_accuracy: 0.5233\n",
      "Epoch 38/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2335 - accuracy: 0.9070\n",
      "Epoch 38: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.2335 - accuracy: 0.9070 - val_loss: 1.2022 - val_accuracy: 0.5640\n",
      "Epoch 39/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2105 - accuracy: 0.9128\n",
      "Epoch 39: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.2105 - accuracy: 0.9128 - val_loss: 1.4294 - val_accuracy: 0.6105\n",
      "Epoch 40/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1488 - accuracy: 0.9302\n",
      "Epoch 40: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.1488 - accuracy: 0.9302 - val_loss: 1.8056 - val_accuracy: 0.5988\n",
      "Epoch 41/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1413 - accuracy: 0.9433\n",
      "Epoch 41: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.1413 - accuracy: 0.9433 - val_loss: 2.8183 - val_accuracy: 0.5116\n",
      "Epoch 42/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1631 - accuracy: 0.9390\n",
      "Epoch 42: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.1631 - accuracy: 0.9390 - val_loss: 1.6130 - val_accuracy: 0.5698\n",
      "Epoch 43/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1363 - accuracy: 0.9448\n",
      "Epoch 43: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.1363 - accuracy: 0.9448 - val_loss: 1.5283 - val_accuracy: 0.5465\n",
      "Epoch 44/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1459 - accuracy: 0.9331\n",
      "Epoch 44: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.1459 - accuracy: 0.9331 - val_loss: 1.8984 - val_accuracy: 0.5756\n",
      "Epoch 45/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.9608\n",
      "Epoch 45: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0975 - accuracy: 0.9608 - val_loss: 1.8573 - val_accuracy: 0.5523\n",
      "Epoch 46/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0840 - accuracy: 0.9680\n",
      "Epoch 46: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0840 - accuracy: 0.9680 - val_loss: 2.4303 - val_accuracy: 0.5581\n",
      "Epoch 47/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1186 - accuracy: 0.9491\n",
      "Epoch 47: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.1186 - accuracy: 0.9491 - val_loss: 1.9260 - val_accuracy: 0.5465\n",
      "Epoch 48/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9637\n",
      "Epoch 48: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0709 - accuracy: 0.9637 - val_loss: 2.2095 - val_accuracy: 0.5465\n",
      "Epoch 49/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 0.9695\n",
      "Epoch 49: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0559 - accuracy: 0.9695 - val_loss: 2.1541 - val_accuracy: 0.5930\n",
      "Epoch 50/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1291 - accuracy: 0.9477\n",
      "Epoch 50: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1291 - accuracy: 0.9477 - val_loss: 1.6975 - val_accuracy: 0.5872\n",
      "Epoch 51/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1525 - accuracy: 0.9244\n",
      "Epoch 51: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1525 - accuracy: 0.9244 - val_loss: 1.5832 - val_accuracy: 0.5872\n",
      "Epoch 52/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1208 - accuracy: 0.9390\n",
      "Epoch 52: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1208 - accuracy: 0.9390 - val_loss: 1.7394 - val_accuracy: 0.6047\n",
      "Epoch 53/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1197 - accuracy: 0.9564\n",
      "Epoch 53: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1197 - accuracy: 0.9564 - val_loss: 1.5947 - val_accuracy: 0.6163\n",
      "Epoch 54/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.9448\n",
      "Epoch 54: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1243 - accuracy: 0.9448 - val_loss: 1.8386 - val_accuracy: 0.5988\n",
      "Epoch 55/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1596 - accuracy: 0.9375\n",
      "Epoch 55: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.1596 - accuracy: 0.9375 - val_loss: 1.2564 - val_accuracy: 0.6279\n",
      "Epoch 56/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1671 - accuracy: 0.9273\n",
      "Epoch 56: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1671 - accuracy: 0.9273 - val_loss: 1.5513 - val_accuracy: 0.6047\n",
      "Epoch 57/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1085 - accuracy: 0.9506\n",
      "Epoch 57: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.1085 - accuracy: 0.9506 - val_loss: 1.6803 - val_accuracy: 0.5814\n",
      "Epoch 58/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9680\n",
      "Epoch 58: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0770 - accuracy: 0.9680 - val_loss: 1.9271 - val_accuracy: 0.5872\n",
      "Epoch 59/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9637\n",
      "Epoch 59: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0850 - accuracy: 0.9637 - val_loss: 1.8121 - val_accuracy: 0.5698\n",
      "Epoch 60/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0801 - accuracy: 0.9637\n",
      "Epoch 60: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0801 - accuracy: 0.9637 - val_loss: 1.8799 - val_accuracy: 0.5756\n",
      "Epoch 61/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0725 - accuracy: 0.9666\n",
      "Epoch 61: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0725 - accuracy: 0.9666 - val_loss: 1.9747 - val_accuracy: 0.5698\n",
      "Epoch 62/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9811\n",
      "Epoch 62: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0442 - accuracy: 0.9811 - val_loss: 2.0386 - val_accuracy: 0.5640\n",
      "Epoch 63/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9738\n",
      "Epoch 63: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0487 - accuracy: 0.9738 - val_loss: 2.3943 - val_accuracy: 0.5698\n",
      "Epoch 64/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9753\n",
      "Epoch 64: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0619 - accuracy: 0.9753 - val_loss: 2.2546 - val_accuracy: 0.5407\n",
      "Epoch 65/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9753\n",
      "Epoch 65: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0521 - accuracy: 0.9753 - val_loss: 2.1020 - val_accuracy: 0.5640\n",
      "Epoch 66/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9767\n",
      "Epoch 66: val_accuracy did not improve from 0.66860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0369 - accuracy: 0.9767 - val_loss: 2.2499 - val_accuracy: 0.5581\n",
      "Epoch 67/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9840\n",
      "Epoch 67: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0260 - accuracy: 0.9840 - val_loss: 2.4472 - val_accuracy: 0.5872\n",
      "Epoch 68/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9855\n",
      "Epoch 68: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0254 - accuracy: 0.9855 - val_loss: 2.5089 - val_accuracy: 0.5640\n",
      "Epoch 69/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9826\n",
      "Epoch 69: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0239 - accuracy: 0.9826 - val_loss: 2.5836 - val_accuracy: 0.5581\n",
      "Epoch 70/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9826\n",
      "Epoch 70: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0243 - accuracy: 0.9826 - val_loss: 2.5840 - val_accuracy: 0.5349\n",
      "Epoch 71/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9869\n",
      "Epoch 71: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0260 - accuracy: 0.9869 - val_loss: 2.5822 - val_accuracy: 0.5407\n",
      "Epoch 72/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9826\n",
      "Epoch 72: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0227 - accuracy: 0.9826 - val_loss: 2.6061 - val_accuracy: 0.5523\n",
      "Epoch 73/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9811\n",
      "Epoch 73: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0231 - accuracy: 0.9811 - val_loss: 2.6614 - val_accuracy: 0.5407\n",
      "Epoch 74/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9826\n",
      "Epoch 74: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0245 - accuracy: 0.9826 - val_loss: 2.6619 - val_accuracy: 0.5465\n",
      "Epoch 75/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9884\n",
      "Epoch 75: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0230 - accuracy: 0.9884 - val_loss: 2.7050 - val_accuracy: 0.5640\n",
      "Epoch 76/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9811\n",
      "Epoch 76: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0252 - accuracy: 0.9811 - val_loss: 2.6563 - val_accuracy: 0.5756\n",
      "Epoch 77/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9797\n",
      "Epoch 77: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0225 - accuracy: 0.9797 - val_loss: 2.6385 - val_accuracy: 0.5640\n",
      "Epoch 78/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9855\n",
      "Epoch 78: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0240 - accuracy: 0.9855 - val_loss: 2.6681 - val_accuracy: 0.5407\n",
      "Epoch 79/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9840\n",
      "Epoch 79: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0213 - accuracy: 0.9840 - val_loss: 2.6797 - val_accuracy: 0.5581\n",
      "Epoch 80/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9826\n",
      "Epoch 80: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0216 - accuracy: 0.9826 - val_loss: 2.6850 - val_accuracy: 0.5698\n",
      "Epoch 81/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9826\n",
      "Epoch 81: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0201 - accuracy: 0.9826 - val_loss: 2.7212 - val_accuracy: 0.5640\n",
      "Epoch 82/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9884\n",
      "Epoch 82: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0206 - accuracy: 0.9884 - val_loss: 2.7122 - val_accuracy: 0.5756\n",
      "Epoch 83/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9855\n",
      "Epoch 83: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0208 - accuracy: 0.9855 - val_loss: 2.7003 - val_accuracy: 0.5756\n",
      "Epoch 84/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9869\n",
      "Epoch 84: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0197 - accuracy: 0.9869 - val_loss: 2.7704 - val_accuracy: 0.5814\n",
      "Epoch 85/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9797\n",
      "Epoch 85: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0232 - accuracy: 0.9797 - val_loss: 2.7778 - val_accuracy: 0.5872\n",
      "Epoch 86/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9884\n",
      "Epoch 86: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0204 - accuracy: 0.9884 - val_loss: 2.8086 - val_accuracy: 0.5930\n",
      "Epoch 87/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9826\n",
      "Epoch 87: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0200 - accuracy: 0.9826 - val_loss: 2.8249 - val_accuracy: 0.5814\n",
      "Epoch 88/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9884\n",
      "Epoch 88: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0199 - accuracy: 0.9884 - val_loss: 2.8262 - val_accuracy: 0.6047\n",
      "Epoch 89/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9797\n",
      "Epoch 89: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0212 - accuracy: 0.9797 - val_loss: 2.8515 - val_accuracy: 0.5814\n",
      "Epoch 90/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9855\n",
      "Epoch 90: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0206 - accuracy: 0.9855 - val_loss: 2.8685 - val_accuracy: 0.5407\n",
      "Epoch 91/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9869\n",
      "Epoch 91: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0198 - accuracy: 0.9869 - val_loss: 2.9139 - val_accuracy: 0.5465\n",
      "Epoch 92/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9884\n",
      "Epoch 92: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0188 - accuracy: 0.9884 - val_loss: 2.9388 - val_accuracy: 0.5523\n",
      "Epoch 93/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9884\n",
      "Epoch 93: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0189 - accuracy: 0.9884 - val_loss: 2.9246 - val_accuracy: 0.5523\n",
      "Epoch 94/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9884\n",
      "Epoch 94: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0191 - accuracy: 0.9884 - val_loss: 2.9131 - val_accuracy: 0.5465\n",
      "Epoch 95/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9855\n",
      "Epoch 95: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0186 - accuracy: 0.9855 - val_loss: 2.9346 - val_accuracy: 0.5407\n",
      "Epoch 96/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9869\n",
      "Epoch 96: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0183 - accuracy: 0.9869 - val_loss: 2.9311 - val_accuracy: 0.5291\n",
      "Epoch 97/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9884\n",
      "Epoch 97: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0179 - accuracy: 0.9884 - val_loss: 2.9332 - val_accuracy: 0.5465\n",
      "Epoch 98/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9869\n",
      "Epoch 98: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0187 - accuracy: 0.9869 - val_loss: 2.9444 - val_accuracy: 0.5465\n",
      "Epoch 99/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9840\n",
      "Epoch 99: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0182 - accuracy: 0.9840 - val_loss: 2.9637 - val_accuracy: 0.5407\n",
      "Epoch 100/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9884\n",
      "Epoch 100: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0195 - accuracy: 0.9884 - val_loss: 3.0128 - val_accuracy: 0.5407\n",
      "Epoch 101/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9826\n",
      "Epoch 101: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0211 - accuracy: 0.9826 - val_loss: 3.0019 - val_accuracy: 0.5407\n",
      "Epoch 102/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9869\n",
      "Epoch 102: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0189 - accuracy: 0.9869 - val_loss: 2.9830 - val_accuracy: 0.5523\n",
      "Epoch 103/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9869\n",
      "Epoch 103: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0190 - accuracy: 0.9869 - val_loss: 2.9785 - val_accuracy: 0.5581\n",
      "Epoch 104/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9855\n",
      "Epoch 104: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0187 - accuracy: 0.9855 - val_loss: 2.9268 - val_accuracy: 0.5756\n",
      "Epoch 105/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9840\n",
      "Epoch 105: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0179 - accuracy: 0.9840 - val_loss: 2.9416 - val_accuracy: 0.5465\n",
      "Epoch 106/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9884\n",
      "Epoch 106: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0181 - accuracy: 0.9884 - val_loss: 2.9844 - val_accuracy: 0.5407\n",
      "Epoch 107/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9898\n",
      "Epoch 107: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0175 - accuracy: 0.9898 - val_loss: 2.9891 - val_accuracy: 0.5407\n",
      "Epoch 108/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9855\n",
      "Epoch 108: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0181 - accuracy: 0.9855 - val_loss: 3.0004 - val_accuracy: 0.5523\n",
      "Epoch 109/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9855\n",
      "Epoch 109: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0175 - accuracy: 0.9855 - val_loss: 3.0116 - val_accuracy: 0.5407\n",
      "Epoch 110/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9884\n",
      "Epoch 110: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0176 - accuracy: 0.9884 - val_loss: 3.0131 - val_accuracy: 0.5523\n",
      "Epoch 111/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9855\n",
      "Epoch 111: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0193 - accuracy: 0.9855 - val_loss: 3.0012 - val_accuracy: 0.5523\n",
      "Epoch 112/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9884\n",
      "Epoch 112: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0179 - accuracy: 0.9884 - val_loss: 3.0108 - val_accuracy: 0.5465\n",
      "Epoch 113/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9884\n",
      "Epoch 113: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0175 - accuracy: 0.9884 - val_loss: 3.0266 - val_accuracy: 0.5465\n",
      "Epoch 114/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9884\n",
      "Epoch 114: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0174 - accuracy: 0.9884 - val_loss: 3.0400 - val_accuracy: 0.5523\n",
      "Epoch 115/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9826\n",
      "Epoch 115: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0180 - accuracy: 0.9826 - val_loss: 3.0372 - val_accuracy: 0.5640\n",
      "Epoch 116/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9869\n",
      "Epoch 116: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0175 - accuracy: 0.9869 - val_loss: 3.0556 - val_accuracy: 0.5581\n",
      "Epoch 117/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9884\n",
      "Epoch 117: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0173 - accuracy: 0.9884 - val_loss: 3.0950 - val_accuracy: 0.5465\n",
      "Epoch 118/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9884\n",
      "Epoch 118: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0175 - accuracy: 0.9884 - val_loss: 3.1174 - val_accuracy: 0.5581\n",
      "Epoch 119/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9884\n",
      "Epoch 119: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0172 - accuracy: 0.9884 - val_loss: 3.1145 - val_accuracy: 0.5581\n",
      "Epoch 120/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9855\n",
      "Epoch 120: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0175 - accuracy: 0.9855 - val_loss: 3.1226 - val_accuracy: 0.5581\n",
      "Epoch 121/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9884\n",
      "Epoch 121: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0172 - accuracy: 0.9884 - val_loss: 3.1288 - val_accuracy: 0.5523\n",
      "Epoch 122/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9884\n",
      "Epoch 122: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0178 - accuracy: 0.9884 - val_loss: 3.1265 - val_accuracy: 0.5581\n",
      "Epoch 123/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9884\n",
      "Epoch 123: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0171 - accuracy: 0.9884 - val_loss: 3.1562 - val_accuracy: 0.5581\n",
      "Epoch 124/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9884\n",
      "Epoch 124: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0174 - accuracy: 0.9884 - val_loss: 3.1275 - val_accuracy: 0.5581\n",
      "Epoch 125/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9855\n",
      "Epoch 125: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0171 - accuracy: 0.9855 - val_loss: 3.1576 - val_accuracy: 0.5581\n",
      "Epoch 126/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9884\n",
      "Epoch 126: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0164 - accuracy: 0.9884 - val_loss: 3.1388 - val_accuracy: 0.5814\n",
      "Epoch 127/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9898\n",
      "Epoch 127: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0165 - accuracy: 0.9898 - val_loss: 3.1595 - val_accuracy: 0.5930\n",
      "Epoch 128/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9913\n",
      "Epoch 128: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0172 - accuracy: 0.9913 - val_loss: 3.0348 - val_accuracy: 0.5756\n",
      "Epoch 129/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9724\n",
      "Epoch 129: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0583 - accuracy: 0.9724 - val_loss: 2.7681 - val_accuracy: 0.6047\n",
      "Epoch 130/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2445 - accuracy: 0.9157\n",
      "Epoch 130: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.2445 - accuracy: 0.9157 - val_loss: 1.3990 - val_accuracy: 0.5523\n",
      "Epoch 131/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1560 - accuracy: 0.9273\n",
      "Epoch 131: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.1560 - accuracy: 0.9273 - val_loss: 1.6518 - val_accuracy: 0.5116\n",
      "Epoch 132/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0918 - accuracy: 0.9637\n",
      "Epoch 132: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0918 - accuracy: 0.9637 - val_loss: 1.9482 - val_accuracy: 0.5523\n",
      "Epoch 133/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9666\n",
      "Epoch 133: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0828 - accuracy: 0.9666 - val_loss: 1.7965 - val_accuracy: 0.5814\n",
      "Epoch 134/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9826\n",
      "Epoch 134: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0429 - accuracy: 0.9826 - val_loss: 2.0147 - val_accuracy: 0.5581\n",
      "Epoch 135/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9811\n",
      "Epoch 135: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0423 - accuracy: 0.9811 - val_loss: 2.0829 - val_accuracy: 0.5756\n",
      "Epoch 136/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9753\n",
      "Epoch 136: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0487 - accuracy: 0.9753 - val_loss: 2.5175 - val_accuracy: 0.5814\n",
      "Epoch 137/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.9738\n",
      "Epoch 137: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0945 - accuracy: 0.9738 - val_loss: 2.1256 - val_accuracy: 0.5930\n",
      "Epoch 138/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2039 - accuracy: 0.9230\n",
      "Epoch 138: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.2039 - accuracy: 0.9230 - val_loss: 1.3395 - val_accuracy: 0.5581\n",
      "Epoch 139/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9738\n",
      "Epoch 139: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0795 - accuracy: 0.9738 - val_loss: 1.9553 - val_accuracy: 0.5465\n",
      "Epoch 140/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9797\n",
      "Epoch 140: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0505 - accuracy: 0.9797 - val_loss: 2.3374 - val_accuracy: 0.5698\n",
      "Epoch 141/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0757 - accuracy: 0.9608\n",
      "Epoch 141: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0757 - accuracy: 0.9608 - val_loss: 2.3113 - val_accuracy: 0.5523\n",
      "Epoch 142/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9622\n",
      "Epoch 142: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0656 - accuracy: 0.9622 - val_loss: 2.3282 - val_accuracy: 0.5523\n",
      "Epoch 143/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9782\n",
      "Epoch 143: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0362 - accuracy: 0.9782 - val_loss: 2.4510 - val_accuracy: 0.5349\n",
      "Epoch 144/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9753\n",
      "Epoch 144: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0514 - accuracy: 0.9753 - val_loss: 2.7083 - val_accuracy: 0.5233\n",
      "Epoch 145/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9695\n",
      "Epoch 145: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0646 - accuracy: 0.9695 - val_loss: 2.6439 - val_accuracy: 0.5000\n",
      "Epoch 146/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9724\n",
      "Epoch 146: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0651 - accuracy: 0.9724 - val_loss: 2.3354 - val_accuracy: 0.5465\n",
      "Epoch 147/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9840\n",
      "Epoch 147: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0399 - accuracy: 0.9840 - val_loss: 2.5742 - val_accuracy: 0.5407\n",
      "Epoch 148/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.9797\n",
      "Epoch 148: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0356 - accuracy: 0.9797 - val_loss: 2.9295 - val_accuracy: 0.5233\n",
      "Epoch 149/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9826\n",
      "Epoch 149: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0293 - accuracy: 0.9826 - val_loss: 2.9498 - val_accuracy: 0.5291\n",
      "Epoch 150/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9855\n",
      "Epoch 150: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0241 - accuracy: 0.9855 - val_loss: 3.0958 - val_accuracy: 0.5174\n",
      "Epoch 151/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9767\n",
      "Epoch 151: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0345 - accuracy: 0.9767 - val_loss: 3.3067 - val_accuracy: 0.5291\n",
      "Epoch 152/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0381 - accuracy: 0.9855\n",
      "Epoch 152: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0381 - accuracy: 0.9855 - val_loss: 2.9894 - val_accuracy: 0.5465\n",
      "Epoch 153/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.9622\n",
      "Epoch 153: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.1030 - accuracy: 0.9622 - val_loss: 2.3569 - val_accuracy: 0.5465\n",
      "Epoch 154/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.1350 - accuracy: 0.9375\n",
      "Epoch 154: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1350 - accuracy: 0.9375 - val_loss: 2.2192 - val_accuracy: 0.5058\n",
      "Epoch 155/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9520\n",
      "Epoch 155: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.1124 - accuracy: 0.9520 - val_loss: 1.6926 - val_accuracy: 0.5465\n",
      "Epoch 156/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1105 - accuracy: 0.9564\n",
      "Epoch 156: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.1105 - accuracy: 0.9564 - val_loss: 1.3684 - val_accuracy: 0.5581\n",
      "Epoch 157/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9709\n",
      "Epoch 157: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0655 - accuracy: 0.9709 - val_loss: 1.9432 - val_accuracy: 0.5465\n",
      "Epoch 158/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.9695\n",
      "Epoch 158: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0691 - accuracy: 0.9695 - val_loss: 1.8100 - val_accuracy: 0.5581\n",
      "Epoch 159/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9811\n",
      "Epoch 159: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0588 - accuracy: 0.9811 - val_loss: 2.0189 - val_accuracy: 0.5581\n",
      "Epoch 160/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9797\n",
      "Epoch 160: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0442 - accuracy: 0.9797 - val_loss: 2.2198 - val_accuracy: 0.5814\n",
      "Epoch 161/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9782\n",
      "Epoch 161: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0502 - accuracy: 0.9782 - val_loss: 2.1211 - val_accuracy: 0.5698\n",
      "Epoch 162/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9826\n",
      "Epoch 162: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0295 - accuracy: 0.9826 - val_loss: 2.4061 - val_accuracy: 0.5581\n",
      "Epoch 163/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9840\n",
      "Epoch 163: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0245 - accuracy: 0.9840 - val_loss: 2.5242 - val_accuracy: 0.5523\n",
      "Epoch 164/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.9826\n",
      "Epoch 164: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0217 - accuracy: 0.9826 - val_loss: 2.5271 - val_accuracy: 0.5407\n",
      "Epoch 165/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9884\n",
      "Epoch 165: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0204 - accuracy: 0.9884 - val_loss: 2.5807 - val_accuracy: 0.5465\n",
      "Epoch 166/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9855\n",
      "Epoch 166: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0216 - accuracy: 0.9855 - val_loss: 2.5713 - val_accuracy: 0.5407\n",
      "Epoch 167/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9869\n",
      "Epoch 167: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0226 - accuracy: 0.9869 - val_loss: 2.6983 - val_accuracy: 0.5698\n",
      "Epoch 168/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9797\n",
      "Epoch 168: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0460 - accuracy: 0.9797 - val_loss: 2.4668 - val_accuracy: 0.5465\n",
      "Epoch 169/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9826\n",
      "Epoch 169: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0285 - accuracy: 0.9826 - val_loss: 2.6113 - val_accuracy: 0.5581\n",
      "Epoch 170/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9840\n",
      "Epoch 170: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0255 - accuracy: 0.9840 - val_loss: 2.6520 - val_accuracy: 0.5465\n",
      "Epoch 171/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9797\n",
      "Epoch 171: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0238 - accuracy: 0.9797 - val_loss: 2.6422 - val_accuracy: 0.5523\n",
      "Epoch 172/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9869\n",
      "Epoch 172: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0206 - accuracy: 0.9869 - val_loss: 2.8029 - val_accuracy: 0.5291\n",
      "Epoch 173/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9884\n",
      "Epoch 173: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0189 - accuracy: 0.9884 - val_loss: 2.8195 - val_accuracy: 0.5291\n",
      "Epoch 174/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9884\n",
      "Epoch 174: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0176 - accuracy: 0.9884 - val_loss: 2.8381 - val_accuracy: 0.5349\n",
      "Epoch 175/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9884\n",
      "Epoch 175: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0203 - accuracy: 0.9884 - val_loss: 2.9258 - val_accuracy: 0.5291\n",
      "Epoch 176/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9898\n",
      "Epoch 176: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0193 - accuracy: 0.9898 - val_loss: 2.7175 - val_accuracy: 0.5523\n",
      "Epoch 177/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9840\n",
      "Epoch 177: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0248 - accuracy: 0.9840 - val_loss: 2.9125 - val_accuracy: 0.5407\n",
      "Epoch 178/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9840\n",
      "Epoch 178: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0194 - accuracy: 0.9840 - val_loss: 3.0124 - val_accuracy: 0.5407\n",
      "Epoch 179/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9884\n",
      "Epoch 179: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0178 - accuracy: 0.9884 - val_loss: 3.0200 - val_accuracy: 0.5233\n",
      "Epoch 180/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9869\n",
      "Epoch 180: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0178 - accuracy: 0.9869 - val_loss: 3.0271 - val_accuracy: 0.5291\n",
      "Epoch 181/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9840\n",
      "Epoch 181: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0180 - accuracy: 0.9840 - val_loss: 3.0333 - val_accuracy: 0.5291\n",
      "Epoch 182/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9898\n",
      "Epoch 182: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0168 - accuracy: 0.9898 - val_loss: 3.1340 - val_accuracy: 0.5349\n",
      "Epoch 183/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9869\n",
      "Epoch 183: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0174 - accuracy: 0.9869 - val_loss: 3.1419 - val_accuracy: 0.5349\n",
      "Epoch 184/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9869\n",
      "Epoch 184: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0190 - accuracy: 0.9869 - val_loss: 3.1787 - val_accuracy: 0.5291\n",
      "Epoch 185/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9884\n",
      "Epoch 185: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0185 - accuracy: 0.9884 - val_loss: 3.2615 - val_accuracy: 0.5233\n",
      "Epoch 186/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9898\n",
      "Epoch 186: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0165 - accuracy: 0.9898 - val_loss: 3.2880 - val_accuracy: 0.5291\n",
      "Epoch 187/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9913\n",
      "Epoch 187: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0156 - accuracy: 0.9913 - val_loss: 3.2976 - val_accuracy: 0.5291\n",
      "Epoch 188/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9869\n",
      "Epoch 188: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0161 - accuracy: 0.9869 - val_loss: 3.3323 - val_accuracy: 0.5116\n",
      "Epoch 189/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9898\n",
      "Epoch 189: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0172 - accuracy: 0.9898 - val_loss: 3.3450 - val_accuracy: 0.5116\n",
      "Epoch 190/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9855\n",
      "Epoch 190: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0178 - accuracy: 0.9855 - val_loss: 3.3492 - val_accuracy: 0.5233\n",
      "Epoch 191/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9884\n",
      "Epoch 191: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0175 - accuracy: 0.9884 - val_loss: 3.2881 - val_accuracy: 0.5349\n",
      "Epoch 192/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9855\n",
      "Epoch 192: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0172 - accuracy: 0.9855 - val_loss: 3.2986 - val_accuracy: 0.5407\n",
      "Epoch 193/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9884\n",
      "Epoch 193: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0157 - accuracy: 0.9884 - val_loss: 3.1422 - val_accuracy: 0.5523\n",
      "Epoch 194/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9913\n",
      "Epoch 194: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0274 - accuracy: 0.9913 - val_loss: 2.9709 - val_accuracy: 0.5581\n",
      "Epoch 195/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9855\n",
      "Epoch 195: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0236 - accuracy: 0.9855 - val_loss: 3.3796 - val_accuracy: 0.5233\n",
      "Epoch 196/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9797\n",
      "Epoch 196: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0401 - accuracy: 0.9797 - val_loss: 2.9941 - val_accuracy: 0.5116\n",
      "Epoch 197/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1252 - accuracy: 0.9578\n",
      "Epoch 197: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.1252 - accuracy: 0.9578 - val_loss: 1.9754 - val_accuracy: 0.5756\n",
      "Epoch 198/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1104 - accuracy: 0.9506\n",
      "Epoch 198: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.1104 - accuracy: 0.9506 - val_loss: 1.6509 - val_accuracy: 0.6047\n",
      "Epoch 199/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.9666\n",
      "Epoch 199: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0698 - accuracy: 0.9666 - val_loss: 1.8458 - val_accuracy: 0.5930\n",
      "Epoch 200/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.9709\n",
      "Epoch 200: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0731 - accuracy: 0.9709 - val_loss: 1.8742 - val_accuracy: 0.5698\n",
      "Epoch 201/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9782\n",
      "Epoch 201: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0330 - accuracy: 0.9782 - val_loss: 1.9433 - val_accuracy: 0.6105\n",
      "Epoch 202/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.9840\n",
      "Epoch 202: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0300 - accuracy: 0.9840 - val_loss: 2.0021 - val_accuracy: 0.5988\n",
      "Epoch 203/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 0.9855\n",
      "Epoch 203: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0306 - accuracy: 0.9855 - val_loss: 2.1833 - val_accuracy: 0.5756\n",
      "Epoch 204/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9826\n",
      "Epoch 204: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0312 - accuracy: 0.9826 - val_loss: 2.2739 - val_accuracy: 0.5814\n",
      "Epoch 205/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9767\n",
      "Epoch 205: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0451 - accuracy: 0.9767 - val_loss: 2.4646 - val_accuracy: 0.5523\n",
      "Epoch 206/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9811\n",
      "Epoch 206: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0506 - accuracy: 0.9811 - val_loss: 2.5508 - val_accuracy: 0.5756\n",
      "Epoch 207/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9826\n",
      "Epoch 207: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0338 - accuracy: 0.9826 - val_loss: 2.3730 - val_accuracy: 0.6047\n",
      "Epoch 208/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1089 - accuracy: 0.9608\n",
      "Epoch 208: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.1089 - accuracy: 0.9608 - val_loss: 2.0080 - val_accuracy: 0.5930\n",
      "Epoch 209/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.9651\n",
      "Epoch 209: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0844 - accuracy: 0.9651 - val_loss: 1.9476 - val_accuracy: 0.5581\n",
      "Epoch 210/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9695\n",
      "Epoch 210: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0635 - accuracy: 0.9695 - val_loss: 1.8283 - val_accuracy: 0.5407\n",
      "Epoch 211/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9797\n",
      "Epoch 211: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0432 - accuracy: 0.9797 - val_loss: 1.8975 - val_accuracy: 0.5814\n",
      "Epoch 212/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9855\n",
      "Epoch 212: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0246 - accuracy: 0.9855 - val_loss: 2.0359 - val_accuracy: 0.5930\n",
      "Epoch 213/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.9811\n",
      "Epoch 213: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0224 - accuracy: 0.9811 - val_loss: 2.1427 - val_accuracy: 0.5756\n",
      "Epoch 214/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9884\n",
      "Epoch 214: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0196 - accuracy: 0.9884 - val_loss: 2.2099 - val_accuracy: 0.5756\n",
      "Epoch 215/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9884\n",
      "Epoch 215: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0183 - accuracy: 0.9884 - val_loss: 2.3128 - val_accuracy: 0.5640\n",
      "Epoch 216/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9855\n",
      "Epoch 216: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0182 - accuracy: 0.9855 - val_loss: 2.3433 - val_accuracy: 0.5814\n",
      "Epoch 217/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9884\n",
      "Epoch 217: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 82ms/step - loss: 0.0177 - accuracy: 0.9884 - val_loss: 2.4168 - val_accuracy: 0.6047\n",
      "Epoch 218/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9869\n",
      "Epoch 218: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0180 - accuracy: 0.9869 - val_loss: 2.4552 - val_accuracy: 0.5930\n",
      "Epoch 219/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9869\n",
      "Epoch 219: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0165 - accuracy: 0.9869 - val_loss: 2.4812 - val_accuracy: 0.5872\n",
      "Epoch 220/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9913\n",
      "Epoch 220: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0159 - accuracy: 0.9913 - val_loss: 2.4897 - val_accuracy: 0.5930\n",
      "Epoch 221/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9927\n",
      "Epoch 221: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0146 - accuracy: 0.9927 - val_loss: 2.5229 - val_accuracy: 0.5988\n",
      "Epoch 222/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9898\n",
      "Epoch 222: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0150 - accuracy: 0.9898 - val_loss: 2.5557 - val_accuracy: 0.6047\n",
      "Epoch 223/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9898\n",
      "Epoch 223: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0203 - accuracy: 0.9898 - val_loss: 2.6105 - val_accuracy: 0.5698\n",
      "Epoch 224/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9869\n",
      "Epoch 224: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0194 - accuracy: 0.9869 - val_loss: 2.5811 - val_accuracy: 0.5872\n",
      "Epoch 225/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9898\n",
      "Epoch 225: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0171 - accuracy: 0.9898 - val_loss: 2.6173 - val_accuracy: 0.5814\n",
      "Epoch 226/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9913\n",
      "Epoch 226: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0159 - accuracy: 0.9913 - val_loss: 2.6349 - val_accuracy: 0.5756\n",
      "Epoch 227/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9898\n",
      "Epoch 227: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0155 - accuracy: 0.9898 - val_loss: 2.6594 - val_accuracy: 0.5930\n",
      "Epoch 228/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9898\n",
      "Epoch 228: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0141 - accuracy: 0.9898 - val_loss: 2.7108 - val_accuracy: 0.5988\n",
      "Epoch 229/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9913\n",
      "Epoch 229: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0236 - accuracy: 0.9913 - val_loss: 2.8113 - val_accuracy: 0.5523\n",
      "Epoch 230/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1654 - accuracy: 0.9390\n",
      "Epoch 230: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.1654 - accuracy: 0.9390 - val_loss: 1.9456 - val_accuracy: 0.5640\n",
      "Epoch 231/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1492 - accuracy: 0.9331\n",
      "Epoch 231: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.1492 - accuracy: 0.9331 - val_loss: 1.6746 - val_accuracy: 0.5523\n",
      "Epoch 232/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0829 - accuracy: 0.9695\n",
      "Epoch 232: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0829 - accuracy: 0.9695 - val_loss: 1.7069 - val_accuracy: 0.5581\n",
      "Epoch 233/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9767\n",
      "Epoch 233: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0553 - accuracy: 0.9767 - val_loss: 2.0033 - val_accuracy: 0.5581\n",
      "Epoch 234/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9826\n",
      "Epoch 234: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0369 - accuracy: 0.9826 - val_loss: 2.2616 - val_accuracy: 0.5756\n",
      "Epoch 235/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9855\n",
      "Epoch 235: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0250 - accuracy: 0.9855 - val_loss: 2.4396 - val_accuracy: 0.5872\n",
      "Epoch 236/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9840\n",
      "Epoch 236: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0338 - accuracy: 0.9840 - val_loss: 2.8077 - val_accuracy: 0.5581\n",
      "Epoch 237/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9797\n",
      "Epoch 237: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0359 - accuracy: 0.9797 - val_loss: 2.7943 - val_accuracy: 0.5581\n",
      "Epoch 238/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9869\n",
      "Epoch 238: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0291 - accuracy: 0.9869 - val_loss: 2.6031 - val_accuracy: 0.5756\n",
      "Epoch 239/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9826\n",
      "Epoch 239: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0316 - accuracy: 0.9826 - val_loss: 2.6361 - val_accuracy: 0.5581\n",
      "Epoch 240/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9811\n",
      "Epoch 240: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0502 - accuracy: 0.9811 - val_loss: 2.5747 - val_accuracy: 0.5523\n",
      "Epoch 241/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9782\n",
      "Epoch 241: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0357 - accuracy: 0.9782 - val_loss: 2.3420 - val_accuracy: 0.5814\n",
      "Epoch 242/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9869\n",
      "Epoch 242: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0314 - accuracy: 0.9869 - val_loss: 2.6258 - val_accuracy: 0.5930\n",
      "Epoch 243/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9767\n",
      "Epoch 243: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0437 - accuracy: 0.9767 - val_loss: 2.4589 - val_accuracy: 0.6105\n",
      "Epoch 244/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9840\n",
      "Epoch 244: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0266 - accuracy: 0.9840 - val_loss: 2.4513 - val_accuracy: 0.6105\n",
      "Epoch 245/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9913\n",
      "Epoch 245: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0177 - accuracy: 0.9913 - val_loss: 2.6547 - val_accuracy: 0.6047\n",
      "Epoch 246/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9927\n",
      "Epoch 246: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0161 - accuracy: 0.9927 - val_loss: 2.7462 - val_accuracy: 0.5872\n",
      "Epoch 247/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9913\n",
      "Epoch 247: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0151 - accuracy: 0.9913 - val_loss: 2.7306 - val_accuracy: 0.5988\n",
      "Epoch 248/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9913\n",
      "Epoch 248: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0144 - accuracy: 0.9913 - val_loss: 2.7506 - val_accuracy: 0.6105\n",
      "Epoch 249/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9927\n",
      "Epoch 249: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0149 - accuracy: 0.9927 - val_loss: 2.7539 - val_accuracy: 0.5930\n",
      "Epoch 250/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9913\n",
      "Epoch 250: val_accuracy did not improve from 0.66860\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0141 - accuracy: 0.9913 - val_loss: 2.7667 - val_accuracy: 0.5872\n",
      "=== Batch Size:  16\n"
     ]
    }
   ],
   "source": [
    "if ql3 == 1:\n",
    "    ## For Quanv Exp.\n",
    "    early_stop = EarlyStopping(monitor='val_loss', mode='min', \n",
    "                               verbose=1, patience=10, min_delta=0.0001)\n",
    "\n",
    "    checkpoint = ModelCheckpoint('checkpoints/best_quanv_demo23.hdf5', monitor='val_accuracy', \n",
    "                                 verbose=1, save_best_only=True, mode='max')\n",
    "    if net == 0:\n",
    "        modelq = dense_Model(x_train[0], labels)\n",
    "    elif net == 1:\n",
    "        modelq3 = attrnn_Model(q_train3[0], labels)\n",
    "\n",
    "    modelq3.summary()\n",
    "\n",
    "    q_history3 = modelq3.fit(\n",
    "        x=q_train3, \n",
    "        y=y_train,\n",
    "        epochs=eps, \n",
    "        callbacks=[checkpoint], \n",
    "        batch_size=bsize, \n",
    "        validation_data=(q_valid3,y_valid)\n",
    "    )\n",
    "\n",
    "    keras.models.save_model(modelq3, 'checkpoints/'+ data_ix + '_quanv_mode_demo23.hdf5') \n",
    "    modelq3.save('checkpoints/'+ data_ix + '_demo23.hdf5')\n",
    "\n",
    "    print(\"=== Batch Size: \", bsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9IM2jOJjvOWC",
   "metadata": {
    "id": "9IM2jOJjvOWC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_24 (InputLayer)          [(None, 30, 63, 2)]  0           []                               \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 30, 63, 2)   8           ['input_24[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " permute_11 (Permute)           (None, 63, 30, 2)    0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " ConvUp (Conv2D)                (None, 63, 30, 16)   176         ['permute_11[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 63, 30, 16)  64          ['ConvUp[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " ConvDown1 (Conv2D)             (None, 63, 30, 32)   2592        ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 63, 30, 32)  128         ['ConvDown1[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " ConvDown2 (Conv2D)             (None, 63, 30, 16)   2576        ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 63, 30, 16)  64          ['ConvDown2[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 63, 30, 32)   0           ['batch_normalization_56[0][0]', \n",
      "                                                                  'batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " ConvMerge (Conv2D)             (None, 63, 30, 1)    161         ['concatenate_11[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 63, 30, 1)   4           ['ConvMerge[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " squeeze_last_dim (Lambda)      (None, 63, 30)       0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " bidirectional_22 (Bidirectiona  (None, 63, 128)     48640       ['squeeze_last_dim[0][0]']       \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " bidirectional_23 (Bidirectiona  (None, 63, 128)     98816       ['bidirectional_22[0][0]']       \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " lambda_11 (Lambda)             (None, 128)          0           ['bidirectional_23[0][0]']       \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 128)          16512       ['lambda_11[0][0]']              \n",
      "                                                                                                  \n",
      " dot_22 (Dot)                   (None, 63)           0           ['dense_33[0][0]',               \n",
      "                                                                  'bidirectional_23[0][0]']       \n",
      "                                                                                                  \n",
      " attSoftmax (Softmax)           (None, 63)           0           ['dot_22[0][0]']                 \n",
      "                                                                                                  \n",
      " dot_23 (Dot)                   (None, 128)          0           ['attSoftmax[0][0]',             \n",
      "                                                                  'bidirectional_23[0][0]']       \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 64)           8256        ['dot_23[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 32)           2080        ['dense_34[0][0]']               \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 2)            66          ['dense_35[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 180,143\n",
      "Trainable params: 180,009\n",
      "Non-trainable params: 134\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.5465\n",
      "Epoch 1: val_accuracy improved from -inf to 0.51163, saving model to checkpoints\\best_quanv_demo24.hdf5\n",
      "43/43 [==============================] - 14s 140ms/step - loss: 0.6918 - accuracy: 0.5465 - val_loss: 0.7073 - val_accuracy: 0.5116\n",
      "Epoch 2/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6794 - accuracy: 0.5436\n",
      "Epoch 2: val_accuracy did not improve from 0.51163\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.6794 - accuracy: 0.5436 - val_loss: 0.6923 - val_accuracy: 0.5116\n",
      "Epoch 3/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6703 - accuracy: 0.5785\n",
      "Epoch 3: val_accuracy improved from 0.51163 to 0.55814, saving model to checkpoints\\best_quanv_demo24.hdf5\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.6703 - accuracy: 0.5785 - val_loss: 0.6891 - val_accuracy: 0.5581\n",
      "Epoch 4/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6597 - accuracy: 0.6017\n",
      "Epoch 4: val_accuracy did not improve from 0.55814\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.6597 - accuracy: 0.6017 - val_loss: 0.6933 - val_accuracy: 0.5407\n",
      "Epoch 5/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6673 - accuracy: 0.6003\n",
      "Epoch 5: val_accuracy did not improve from 0.55814\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.6673 - accuracy: 0.6003 - val_loss: 0.7141 - val_accuracy: 0.5233\n",
      "Epoch 6/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6809 - accuracy: 0.5320\n",
      "Epoch 6: val_accuracy did not improve from 0.55814\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.6809 - accuracy: 0.5320 - val_loss: 0.7054 - val_accuracy: 0.5174\n",
      "Epoch 7/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6619 - accuracy: 0.5887\n",
      "Epoch 7: val_accuracy did not improve from 0.55814\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.6619 - accuracy: 0.5887 - val_loss: 0.7180 - val_accuracy: 0.4709\n",
      "Epoch 8/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.6461 - accuracy: 0.6017\n",
      "Epoch 8: val_accuracy did not improve from 0.55814\n",
      "43/43 [==============================] - 3s 59ms/step - loss: 0.6461 - accuracy: 0.6017 - val_loss: 0.7599 - val_accuracy: 0.4942\n",
      "Epoch 9/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6379 - accuracy: 0.6235\n",
      "Epoch 9: val_accuracy did not improve from 0.55814\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 0.6379 - accuracy: 0.6235 - val_loss: 0.7559 - val_accuracy: 0.5058\n",
      "Epoch 10/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6287 - accuracy: 0.6294\n",
      "Epoch 10: val_accuracy did not improve from 0.55814\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 0.6287 - accuracy: 0.6294 - val_loss: 0.8753 - val_accuracy: 0.4884\n",
      "Epoch 11/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6151 - accuracy: 0.6366\n",
      "Epoch 11: val_accuracy did not improve from 0.55814\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.6151 - accuracy: 0.6366 - val_loss: 0.7687 - val_accuracy: 0.4942\n",
      "Epoch 12/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6148 - accuracy: 0.6555\n",
      "Epoch 12: val_accuracy did not improve from 0.55814\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 0.6148 - accuracy: 0.6555 - val_loss: 0.7436 - val_accuracy: 0.4884\n",
      "Epoch 13/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6076 - accuracy: 0.6672\n",
      "Epoch 13: val_accuracy did not improve from 0.55814\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.6076 - accuracy: 0.6672 - val_loss: 0.7348 - val_accuracy: 0.4884\n",
      "Epoch 14/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5770 - accuracy: 0.7006\n",
      "Epoch 14: val_accuracy did not improve from 0.55814\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.5770 - accuracy: 0.7006 - val_loss: 0.9301 - val_accuracy: 0.4884\n",
      "Epoch 15/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5700 - accuracy: 0.7020\n",
      "Epoch 15: val_accuracy did not improve from 0.55814\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.5700 - accuracy: 0.7020 - val_loss: 0.6961 - val_accuracy: 0.5349\n",
      "Epoch 16/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5654 - accuracy: 0.7137\n",
      "Epoch 16: val_accuracy did not improve from 0.55814\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.5654 - accuracy: 0.7137 - val_loss: 0.7853 - val_accuracy: 0.4826\n",
      "Epoch 17/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5477 - accuracy: 0.7209\n",
      "Epoch 17: val_accuracy did not improve from 0.55814\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.5477 - accuracy: 0.7209 - val_loss: 0.9402 - val_accuracy: 0.4884\n",
      "Epoch 18/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5241 - accuracy: 0.7224\n",
      "Epoch 18: val_accuracy did not improve from 0.55814\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.5241 - accuracy: 0.7224 - val_loss: 0.6824 - val_accuracy: 0.5116\n",
      "Epoch 19/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5266 - accuracy: 0.7224\n",
      "Epoch 19: val_accuracy did not improve from 0.55814\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.5266 - accuracy: 0.7224 - val_loss: 0.7521 - val_accuracy: 0.4942\n",
      "Epoch 20/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5187 - accuracy: 0.7544\n",
      "Epoch 20: val_accuracy did not improve from 0.55814\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.5187 - accuracy: 0.7544 - val_loss: 0.8881 - val_accuracy: 0.4884\n",
      "Epoch 21/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5415 - accuracy: 0.7006\n",
      "Epoch 21: val_accuracy did not improve from 0.55814\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.5415 - accuracy: 0.7006 - val_loss: 0.7265 - val_accuracy: 0.5000\n",
      "Epoch 22/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4987 - accuracy: 0.7544\n",
      "Epoch 22: val_accuracy did not improve from 0.55814\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.4987 - accuracy: 0.7544 - val_loss: 0.6914 - val_accuracy: 0.5058\n",
      "Epoch 23/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4887 - accuracy: 0.7398\n",
      "Epoch 23: val_accuracy did not improve from 0.55814\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.4887 - accuracy: 0.7398 - val_loss: 0.8489 - val_accuracy: 0.4884\n",
      "Epoch 24/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4798 - accuracy: 0.7645\n",
      "Epoch 24: val_accuracy improved from 0.55814 to 0.56977, saving model to checkpoints\\best_quanv_demo24.hdf5\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.4798 - accuracy: 0.7645 - val_loss: 0.6962 - val_accuracy: 0.5698\n",
      "Epoch 25/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4744 - accuracy: 0.7791\n",
      "Epoch 25: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.4744 - accuracy: 0.7791 - val_loss: 0.7664 - val_accuracy: 0.4942\n",
      "Epoch 26/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4612 - accuracy: 0.7660\n",
      "Epoch 26: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.4612 - accuracy: 0.7660 - val_loss: 0.8158 - val_accuracy: 0.4826\n",
      "Epoch 27/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4342 - accuracy: 0.7936\n",
      "Epoch 27: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.4342 - accuracy: 0.7936 - val_loss: 0.8107 - val_accuracy: 0.4884\n",
      "Epoch 28/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4302 - accuracy: 0.7878\n",
      "Epoch 28: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.4302 - accuracy: 0.7878 - val_loss: 0.9309 - val_accuracy: 0.4884\n",
      "Epoch 29/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3998 - accuracy: 0.8067\n",
      "Epoch 29: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.3998 - accuracy: 0.8067 - val_loss: 1.1634 - val_accuracy: 0.4884\n",
      "Epoch 30/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.8314\n",
      "Epoch 30: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.3786 - accuracy: 0.8314 - val_loss: 0.9099 - val_accuracy: 0.4826\n",
      "Epoch 31/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3753 - accuracy: 0.8299\n",
      "Epoch 31: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.3753 - accuracy: 0.8299 - val_loss: 0.7418 - val_accuracy: 0.5523\n",
      "Epoch 32/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3541 - accuracy: 0.8474\n",
      "Epoch 32: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.3541 - accuracy: 0.8474 - val_loss: 0.7585 - val_accuracy: 0.4419\n",
      "Epoch 33/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4422 - accuracy: 0.7747\n",
      "Epoch 33: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.4422 - accuracy: 0.7747 - val_loss: 0.7815 - val_accuracy: 0.4942\n",
      "Epoch 34/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3901 - accuracy: 0.8343\n",
      "Epoch 34: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.3901 - accuracy: 0.8343 - val_loss: 0.7576 - val_accuracy: 0.5465\n",
      "Epoch 35/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3954 - accuracy: 0.8154\n",
      "Epoch 35: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.3954 - accuracy: 0.8154 - val_loss: 0.8474 - val_accuracy: 0.5407\n",
      "Epoch 36/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3501 - accuracy: 0.8634\n",
      "Epoch 36: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.3501 - accuracy: 0.8634 - val_loss: 0.8655 - val_accuracy: 0.5291\n",
      "Epoch 37/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.4107 - accuracy: 0.8198\n",
      "Epoch 37: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.4107 - accuracy: 0.8198 - val_loss: 1.0558 - val_accuracy: 0.4884\n",
      "Epoch 38/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3982 - accuracy: 0.8241\n",
      "Epoch 38: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.3982 - accuracy: 0.8241 - val_loss: 1.1147 - val_accuracy: 0.4709\n",
      "Epoch 39/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3430 - accuracy: 0.8401\n",
      "Epoch 39: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.3430 - accuracy: 0.8401 - val_loss: 1.2906 - val_accuracy: 0.4884\n",
      "Epoch 40/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3182 - accuracy: 0.8430\n",
      "Epoch 40: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.3182 - accuracy: 0.8430 - val_loss: 0.9396 - val_accuracy: 0.4709\n",
      "Epoch 41/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3476 - accuracy: 0.8503\n",
      "Epoch 41: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.3476 - accuracy: 0.8503 - val_loss: 1.3867 - val_accuracy: 0.4709\n",
      "Epoch 42/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2840 - accuracy: 0.8765\n",
      "Epoch 42: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.2840 - accuracy: 0.8765 - val_loss: 0.9386 - val_accuracy: 0.5291\n",
      "Epoch 43/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2941 - accuracy: 0.8605\n",
      "Epoch 43: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.2941 - accuracy: 0.8605 - val_loss: 0.9925 - val_accuracy: 0.4826\n",
      "Epoch 44/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3296 - accuracy: 0.8488\n",
      "Epoch 44: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.3296 - accuracy: 0.8488 - val_loss: 1.0149 - val_accuracy: 0.4884\n",
      "Epoch 45/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2981 - accuracy: 0.8677\n",
      "Epoch 45: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.2981 - accuracy: 0.8677 - val_loss: 1.1182 - val_accuracy: 0.5000\n",
      "Epoch 46/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3332 - accuracy: 0.8532\n",
      "Epoch 46: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.3332 - accuracy: 0.8532 - val_loss: 0.9311 - val_accuracy: 0.5116\n",
      "Epoch 47/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2416 - accuracy: 0.8895\n",
      "Epoch 47: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.2416 - accuracy: 0.8895 - val_loss: 0.8832 - val_accuracy: 0.5233\n",
      "Epoch 48/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3005 - accuracy: 0.8794\n",
      "Epoch 48: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.3005 - accuracy: 0.8794 - val_loss: 0.8049 - val_accuracy: 0.4826\n",
      "Epoch 49/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2667 - accuracy: 0.8924\n",
      "Epoch 49: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.2667 - accuracy: 0.8924 - val_loss: 0.9433 - val_accuracy: 0.5116\n",
      "Epoch 50/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3460 - accuracy: 0.8387\n",
      "Epoch 50: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.3460 - accuracy: 0.8387 - val_loss: 0.8760 - val_accuracy: 0.4360\n",
      "Epoch 51/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.8852\n",
      "Epoch 51: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.2731 - accuracy: 0.8852 - val_loss: 0.8715 - val_accuracy: 0.4535\n",
      "Epoch 52/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2521 - accuracy: 0.8939\n",
      "Epoch 52: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.2521 - accuracy: 0.8939 - val_loss: 1.4852 - val_accuracy: 0.4942\n",
      "Epoch 53/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2010 - accuracy: 0.9113\n",
      "Epoch 53: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.2010 - accuracy: 0.9113 - val_loss: 1.4433 - val_accuracy: 0.4942\n",
      "Epoch 54/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2264 - accuracy: 0.9041\n",
      "Epoch 54: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.2264 - accuracy: 0.9041 - val_loss: 1.2692 - val_accuracy: 0.4884\n",
      "Epoch 55/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 0.9186\n",
      "Epoch 55: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.2064 - accuracy: 0.9186 - val_loss: 0.8843 - val_accuracy: 0.4651\n",
      "Epoch 56/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1846 - accuracy: 0.9360\n",
      "Epoch 56: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1846 - accuracy: 0.9360 - val_loss: 1.1739 - val_accuracy: 0.5116\n",
      "Epoch 57/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1697 - accuracy: 0.9331\n",
      "Epoch 57: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1697 - accuracy: 0.9331 - val_loss: 1.0187 - val_accuracy: 0.4826\n",
      "Epoch 58/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1477 - accuracy: 0.9462\n",
      "Epoch 58: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1477 - accuracy: 0.9462 - val_loss: 1.1023 - val_accuracy: 0.5116\n",
      "Epoch 59/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1572 - accuracy: 0.9375\n",
      "Epoch 59: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1572 - accuracy: 0.9375 - val_loss: 1.0354 - val_accuracy: 0.5000\n",
      "Epoch 60/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2755 - accuracy: 0.8881\n",
      "Epoch 60: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.2755 - accuracy: 0.8881 - val_loss: 1.0219 - val_accuracy: 0.5000\n",
      "Epoch 61/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2036 - accuracy: 0.9273\n",
      "Epoch 61: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.2036 - accuracy: 0.9273 - val_loss: 1.1233 - val_accuracy: 0.4767\n",
      "Epoch 62/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2078 - accuracy: 0.9259\n",
      "Epoch 62: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.2078 - accuracy: 0.9259 - val_loss: 1.0208 - val_accuracy: 0.4884\n",
      "Epoch 63/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2110 - accuracy: 0.9157\n",
      "Epoch 63: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.2110 - accuracy: 0.9157 - val_loss: 1.0466 - val_accuracy: 0.4942\n",
      "Epoch 64/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1495 - accuracy: 0.9491\n",
      "Epoch 64: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.1495 - accuracy: 0.9491 - val_loss: 1.6770 - val_accuracy: 0.5116\n",
      "Epoch 65/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1836 - accuracy: 0.9317\n",
      "Epoch 65: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.1836 - accuracy: 0.9317 - val_loss: 0.8750 - val_accuracy: 0.4826\n",
      "Epoch 66/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2234 - accuracy: 0.9142\n",
      "Epoch 66: val_accuracy did not improve from 0.56977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 4s 96ms/step - loss: 0.2234 - accuracy: 0.9142 - val_loss: 1.0602 - val_accuracy: 0.4651\n",
      "Epoch 67/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1300 - accuracy: 0.9506\n",
      "Epoch 67: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.1300 - accuracy: 0.9506 - val_loss: 1.0756 - val_accuracy: 0.4884\n",
      "Epoch 68/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.9419\n",
      "Epoch 68: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.1329 - accuracy: 0.9419 - val_loss: 1.3175 - val_accuracy: 0.4826\n",
      "Epoch 69/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1846 - accuracy: 0.9201\n",
      "Epoch 69: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1846 - accuracy: 0.9201 - val_loss: 1.0500 - val_accuracy: 0.5174\n",
      "Epoch 70/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1353 - accuracy: 0.9462\n",
      "Epoch 70: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.1353 - accuracy: 0.9462 - val_loss: 1.0642 - val_accuracy: 0.5174\n",
      "Epoch 71/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.9608\n",
      "Epoch 71: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0910 - accuracy: 0.9608 - val_loss: 1.2966 - val_accuracy: 0.5291\n",
      "Epoch 72/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1830 - accuracy: 0.9331\n",
      "Epoch 72: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.1830 - accuracy: 0.9331 - val_loss: 0.9168 - val_accuracy: 0.5174\n",
      "Epoch 73/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1263 - accuracy: 0.9564\n",
      "Epoch 73: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1263 - accuracy: 0.9564 - val_loss: 1.2551 - val_accuracy: 0.5174\n",
      "Epoch 74/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9608\n",
      "Epoch 74: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.1133 - accuracy: 0.9608 - val_loss: 1.1688 - val_accuracy: 0.4709\n",
      "Epoch 75/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9695\n",
      "Epoch 75: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0796 - accuracy: 0.9695 - val_loss: 1.4157 - val_accuracy: 0.4884\n",
      "Epoch 76/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1130 - accuracy: 0.9520\n",
      "Epoch 76: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.1130 - accuracy: 0.9520 - val_loss: 1.0733 - val_accuracy: 0.4884\n",
      "Epoch 77/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9593\n",
      "Epoch 77: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0839 - accuracy: 0.9593 - val_loss: 1.1791 - val_accuracy: 0.5233\n",
      "Epoch 78/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1056 - accuracy: 0.9564\n",
      "Epoch 78: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.1056 - accuracy: 0.9564 - val_loss: 1.6038 - val_accuracy: 0.4302\n",
      "Epoch 79/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0885 - accuracy: 0.9608\n",
      "Epoch 79: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0885 - accuracy: 0.9608 - val_loss: 1.3971 - val_accuracy: 0.4767\n",
      "Epoch 80/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.9651\n",
      "Epoch 80: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0945 - accuracy: 0.9651 - val_loss: 1.7241 - val_accuracy: 0.4709\n",
      "Epoch 81/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9695\n",
      "Epoch 81: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0958 - accuracy: 0.9695 - val_loss: 1.3364 - val_accuracy: 0.5291\n",
      "Epoch 82/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0899 - accuracy: 0.9651\n",
      "Epoch 82: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0899 - accuracy: 0.9651 - val_loss: 1.5645 - val_accuracy: 0.4942\n",
      "Epoch 83/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1380 - accuracy: 0.9535\n",
      "Epoch 83: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.1380 - accuracy: 0.9535 - val_loss: 1.1900 - val_accuracy: 0.5116\n",
      "Epoch 84/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1573 - accuracy: 0.9433\n",
      "Epoch 84: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.1573 - accuracy: 0.9433 - val_loss: 1.3452 - val_accuracy: 0.4302\n",
      "Epoch 85/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.9811\n",
      "Epoch 85: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0615 - accuracy: 0.9811 - val_loss: 1.7342 - val_accuracy: 0.4767\n",
      "Epoch 86/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.9709\n",
      "Epoch 86: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0909 - accuracy: 0.9709 - val_loss: 1.9341 - val_accuracy: 0.4709\n",
      "Epoch 87/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9826\n",
      "Epoch 87: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0523 - accuracy: 0.9826 - val_loss: 1.9154 - val_accuracy: 0.4826\n",
      "Epoch 88/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9913\n",
      "Epoch 88: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 2.7417 - val_accuracy: 0.5233\n",
      "Epoch 89/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9927\n",
      "Epoch 89: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0267 - accuracy: 0.9927 - val_loss: 3.3726 - val_accuracy: 0.5058\n",
      "Epoch 90/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1304 - accuracy: 0.9549\n",
      "Epoch 90: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1304 - accuracy: 0.9549 - val_loss: 1.6196 - val_accuracy: 0.5233\n",
      "Epoch 91/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1477 - accuracy: 0.9506\n",
      "Epoch 91: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.1477 - accuracy: 0.9506 - val_loss: 1.3359 - val_accuracy: 0.4884\n",
      "Epoch 92/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 0.9869\n",
      "Epoch 92: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0405 - accuracy: 0.9869 - val_loss: 1.1572 - val_accuracy: 0.4709\n",
      "Epoch 93/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9956\n",
      "Epoch 93: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 1.3399 - val_accuracy: 0.4651\n",
      "Epoch 94/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9913\n",
      "Epoch 94: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0363 - accuracy: 0.9913 - val_loss: 1.6872 - val_accuracy: 0.4535\n",
      "Epoch 95/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1010 - accuracy: 0.9753\n",
      "Epoch 95: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.1010 - accuracy: 0.9753 - val_loss: 1.3251 - val_accuracy: 0.4535\n",
      "Epoch 96/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9826\n",
      "Epoch 96: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0561 - accuracy: 0.9826 - val_loss: 1.4118 - val_accuracy: 0.4477\n",
      "Epoch 97/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9797\n",
      "Epoch 97: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0459 - accuracy: 0.9797 - val_loss: 1.5589 - val_accuracy: 0.5058\n",
      "Epoch 98/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.9651\n",
      "Epoch 98: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0857 - accuracy: 0.9651 - val_loss: 2.0827 - val_accuracy: 0.4651\n",
      "Epoch 99/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9855\n",
      "Epoch 99: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0515 - accuracy: 0.9855 - val_loss: 1.9005 - val_accuracy: 0.4651\n",
      "Epoch 100/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9884\n",
      "Epoch 100: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0294 - accuracy: 0.9884 - val_loss: 2.0062 - val_accuracy: 0.4942\n",
      "Epoch 101/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1004 - accuracy: 0.9709\n",
      "Epoch 101: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1004 - accuracy: 0.9709 - val_loss: 1.3560 - val_accuracy: 0.5291\n",
      "Epoch 102/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 0.9782\n",
      "Epoch 102: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0519 - accuracy: 0.9782 - val_loss: 1.3336 - val_accuracy: 0.5174\n",
      "Epoch 103/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9811\n",
      "Epoch 103: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0655 - accuracy: 0.9811 - val_loss: 1.5049 - val_accuracy: 0.4884\n",
      "Epoch 104/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9826\n",
      "Epoch 104: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0545 - accuracy: 0.9826 - val_loss: 1.1945 - val_accuracy: 0.4709\n",
      "Epoch 105/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9811\n",
      "Epoch 105: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0508 - accuracy: 0.9811 - val_loss: 1.6460 - val_accuracy: 0.4884\n",
      "Epoch 106/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9797\n",
      "Epoch 106: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0707 - accuracy: 0.9797 - val_loss: 1.3673 - val_accuracy: 0.4709\n",
      "Epoch 107/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0685 - accuracy: 0.9826\n",
      "Epoch 107: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0685 - accuracy: 0.9826 - val_loss: 1.2791 - val_accuracy: 0.5116\n",
      "Epoch 108/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9753\n",
      "Epoch 108: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0553 - accuracy: 0.9753 - val_loss: 2.1576 - val_accuracy: 0.5174\n",
      "Epoch 109/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.9709\n",
      "Epoch 109: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0872 - accuracy: 0.9709 - val_loss: 2.1020 - val_accuracy: 0.4884\n",
      "Epoch 110/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.9811\n",
      "Epoch 110: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0792 - accuracy: 0.9811 - val_loss: 1.6835 - val_accuracy: 0.4535\n",
      "Epoch 111/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9811\n",
      "Epoch 111: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0496 - accuracy: 0.9811 - val_loss: 1.9734 - val_accuracy: 0.4826\n",
      "Epoch 112/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9985\n",
      "Epoch 112: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0139 - accuracy: 0.9985 - val_loss: 2.1853 - val_accuracy: 0.4709\n",
      "Epoch 113/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9985\n",
      "Epoch 113: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0119 - accuracy: 0.9985 - val_loss: 2.9667 - val_accuracy: 0.5116\n",
      "Epoch 114/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9942\n",
      "Epoch 114: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0449 - accuracy: 0.9942 - val_loss: 2.9049 - val_accuracy: 0.4826\n",
      "Epoch 115/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9709\n",
      "Epoch 115: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0601 - accuracy: 0.9709 - val_loss: 2.8864 - val_accuracy: 0.4767\n",
      "Epoch 116/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.9811\n",
      "Epoch 116: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0653 - accuracy: 0.9811 - val_loss: 2.3994 - val_accuracy: 0.4767\n",
      "Epoch 117/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9884\n",
      "Epoch 117: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0321 - accuracy: 0.9884 - val_loss: 2.4624 - val_accuracy: 0.5058\n",
      "Epoch 118/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9913\n",
      "Epoch 118: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0369 - accuracy: 0.9913 - val_loss: 2.2773 - val_accuracy: 0.5174\n",
      "Epoch 119/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.9797\n",
      "Epoch 119: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0665 - accuracy: 0.9797 - val_loss: 2.9735 - val_accuracy: 0.4884\n",
      "Epoch 120/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9898\n",
      "Epoch 120: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0274 - accuracy: 0.9898 - val_loss: 2.7477 - val_accuracy: 0.4826\n",
      "Epoch 121/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9826\n",
      "Epoch 121: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0469 - accuracy: 0.9826 - val_loss: 2.8481 - val_accuracy: 0.5058\n",
      "Epoch 122/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9884\n",
      "Epoch 122: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0333 - accuracy: 0.9884 - val_loss: 2.4543 - val_accuracy: 0.5058\n",
      "Epoch 123/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9840\n",
      "Epoch 123: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0387 - accuracy: 0.9840 - val_loss: 2.3701 - val_accuracy: 0.4942\n",
      "Epoch 124/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9942\n",
      "Epoch 124: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 2.8822 - val_accuracy: 0.5116\n",
      "Epoch 125/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9913\n",
      "Epoch 125: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0207 - accuracy: 0.9913 - val_loss: 2.0317 - val_accuracy: 0.5291\n",
      "Epoch 126/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9971\n",
      "Epoch 126: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0160 - accuracy: 0.9971 - val_loss: 2.1679 - val_accuracy: 0.5349\n",
      "Epoch 127/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9869\n",
      "Epoch 127: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0318 - accuracy: 0.9869 - val_loss: 2.2960 - val_accuracy: 0.5058\n",
      "Epoch 128/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9971\n",
      "Epoch 128: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0107 - accuracy: 0.9971 - val_loss: 3.1513 - val_accuracy: 0.4942\n",
      "Epoch 129/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 129: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.9070 - val_accuracy: 0.5000\n",
      "Epoch 130/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000    \n",
      "Epoch 130: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.3202 - val_accuracy: 0.4942\n",
      "Epoch 131/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9927\n",
      "Epoch 131: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0233 - accuracy: 0.9927 - val_loss: 3.0787 - val_accuracy: 0.4884\n",
      "Epoch 132/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9826\n",
      "Epoch 132: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0613 - accuracy: 0.9826 - val_loss: 1.8991 - val_accuracy: 0.5291\n",
      "Epoch 133/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9826\n",
      "Epoch 133: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0530 - accuracy: 0.9826 - val_loss: 2.1897 - val_accuracy: 0.4884\n",
      "Epoch 134/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9942\n",
      "Epoch 134: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0298 - accuracy: 0.9942 - val_loss: 1.9704 - val_accuracy: 0.5058\n",
      "Epoch 135/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9942\n",
      "Epoch 135: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 2.4130 - val_accuracy: 0.4709\n",
      "Epoch 136/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9898\n",
      "Epoch 136: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0373 - accuracy: 0.9898 - val_loss: 2.6405 - val_accuracy: 0.5000\n",
      "Epoch 137/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9927\n",
      "Epoch 137: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0275 - accuracy: 0.9927 - val_loss: 1.9533 - val_accuracy: 0.5233\n",
      "Epoch 138/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.9797\n",
      "Epoch 138: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0627 - accuracy: 0.9797 - val_loss: 2.2859 - val_accuracy: 0.4709\n",
      "Epoch 139/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0431 - accuracy: 0.9826\n",
      "Epoch 139: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0431 - accuracy: 0.9826 - val_loss: 2.6180 - val_accuracy: 0.4709\n",
      "Epoch 140/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9927\n",
      "Epoch 140: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0274 - accuracy: 0.9927 - val_loss: 3.2992 - val_accuracy: 0.4767\n",
      "Epoch 141/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9913\n",
      "Epoch 141: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0177 - accuracy: 0.9913 - val_loss: 2.4708 - val_accuracy: 0.5233\n",
      "Epoch 142/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9971\n",
      "Epoch 142: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0175 - accuracy: 0.9971 - val_loss: 2.2297 - val_accuracy: 0.4942\n",
      "Epoch 143/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9971\n",
      "Epoch 143: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 2.6711 - val_accuracy: 0.5116\n",
      "Epoch 144/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9738\n",
      "Epoch 144: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0784 - accuracy: 0.9738 - val_loss: 1.7965 - val_accuracy: 0.5174\n",
      "Epoch 145/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.9826\n",
      "Epoch 145: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0627 - accuracy: 0.9826 - val_loss: 1.8102 - val_accuracy: 0.5174\n",
      "Epoch 146/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9985\n",
      "Epoch 146: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 2.2015 - val_accuracy: 0.4767\n",
      "Epoch 147/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 147: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.2149 - val_accuracy: 0.5058\n",
      "Epoch 148/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9927\n",
      "Epoch 148: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0256 - accuracy: 0.9927 - val_loss: 2.4208 - val_accuracy: 0.5174\n",
      "Epoch 149/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.9680\n",
      "Epoch 149: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0986 - accuracy: 0.9680 - val_loss: 2.6665 - val_accuracy: 0.5523\n",
      "Epoch 150/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.9753\n",
      "Epoch 150: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0608 - accuracy: 0.9753 - val_loss: 2.0532 - val_accuracy: 0.4942\n",
      "Epoch 151/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9898\n",
      "Epoch 151: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0389 - accuracy: 0.9898 - val_loss: 1.9931 - val_accuracy: 0.5233\n",
      "Epoch 152/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 0.9767\n",
      "Epoch 152: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0576 - accuracy: 0.9767 - val_loss: 1.9465 - val_accuracy: 0.5058\n",
      "Epoch 153/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.9898\n",
      "Epoch 153: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0395 - accuracy: 0.9898 - val_loss: 1.7393 - val_accuracy: 0.5174\n",
      "Epoch 154/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9738\n",
      "Epoch 154: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0667 - accuracy: 0.9738 - val_loss: 2.6710 - val_accuracy: 0.4942\n",
      "Epoch 155/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.9840\n",
      "Epoch 155: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0575 - accuracy: 0.9840 - val_loss: 2.7822 - val_accuracy: 0.4884\n",
      "Epoch 156/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9913\n",
      "Epoch 156: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0258 - accuracy: 0.9913 - val_loss: 2.5862 - val_accuracy: 0.4884\n",
      "Epoch 157/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9767\n",
      "Epoch 157: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0577 - accuracy: 0.9767 - val_loss: 2.9550 - val_accuracy: 0.4942\n",
      "Epoch 158/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9913\n",
      "Epoch 158: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0266 - accuracy: 0.9913 - val_loss: 2.8331 - val_accuracy: 0.5058\n",
      "Epoch 159/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9840\n",
      "Epoch 159: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0616 - accuracy: 0.9840 - val_loss: 2.9668 - val_accuracy: 0.5233\n",
      "Epoch 160/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.9898\n",
      "Epoch 160: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 98ms/step - loss: 0.0403 - accuracy: 0.9898 - val_loss: 2.1442 - val_accuracy: 0.4884\n",
      "Epoch 161/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9840\n",
      "Epoch 161: val_accuracy did not improve from 0.56977\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.0442 - accuracy: 0.9840 - val_loss: 2.2231 - val_accuracy: 0.5116\n",
      "Epoch 162/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 0.9884\n",
      "Epoch 162: val_accuracy improved from 0.56977 to 0.59302, saving model to checkpoints\\best_quanv_demo24.hdf5\n",
      "43/43 [==============================] - 4s 97ms/step - loss: 0.0424 - accuracy: 0.9884 - val_loss: 1.4808 - val_accuracy: 0.5930\n",
      "Epoch 163/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9956\n",
      "Epoch 163: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 97ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 1.8096 - val_accuracy: 0.5581\n",
      "Epoch 164/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9985\n",
      "Epoch 164: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 2.4241 - val_accuracy: 0.5407\n",
      "Epoch 165/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 165: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.5455 - val_accuracy: 0.5233\n",
      "Epoch 166/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9985\n",
      "Epoch 166: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 2.5456 - val_accuracy: 0.5465\n",
      "Epoch 167/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 9.4977e-04 - accuracy: 1.0000\n",
      "Epoch 167: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 9.4977e-04 - accuracy: 1.0000 - val_loss: 2.5170 - val_accuracy: 0.5407\n",
      "Epoch 168/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 4.7281e-04 - accuracy: 1.0000\n",
      "Epoch 168: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 4.7281e-04 - accuracy: 1.0000 - val_loss: 2.5374 - val_accuracy: 0.5465\n",
      "Epoch 169/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9971\n",
      "Epoch 169: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 2.6713 - val_accuracy: 0.5116\n",
      "Epoch 170/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 9.2115e-04 - accuracy: 1.0000\n",
      "Epoch 170: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 9.2115e-04 - accuracy: 1.0000 - val_loss: 2.6715 - val_accuracy: 0.5116\n",
      "Epoch 171/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 171: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6989 - val_accuracy: 0.5174\n",
      "Epoch 172/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.4917e-04 - accuracy: 1.0000\n",
      "Epoch 172: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 3.4917e-04 - accuracy: 1.0000 - val_loss: 2.6994 - val_accuracy: 0.5233\n",
      "Epoch 173/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.7908e-04 - accuracy: 1.0000\n",
      "Epoch 173: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 2.7908e-04 - accuracy: 1.0000 - val_loss: 2.7108 - val_accuracy: 0.5233\n",
      "Epoch 174/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.3761e-04 - accuracy: 1.0000\n",
      "Epoch 174: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 2.3761e-04 - accuracy: 1.0000 - val_loss: 2.7331 - val_accuracy: 0.5174\n",
      "Epoch 175/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.0615e-04 - accuracy: 1.0000\n",
      "Epoch 175: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 3.0615e-04 - accuracy: 1.0000 - val_loss: 2.7640 - val_accuracy: 0.5174\n",
      "Epoch 176/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.9371e-04 - accuracy: 1.0000\n",
      "Epoch 176: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 1.9371e-04 - accuracy: 1.0000 - val_loss: 2.7868 - val_accuracy: 0.5174\n",
      "Epoch 177/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.7374e-04 - accuracy: 1.0000\n",
      "Epoch 177: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 1.7374e-04 - accuracy: 1.0000 - val_loss: 2.8073 - val_accuracy: 0.5174\n",
      "Epoch 178/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9985\n",
      "Epoch 178: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0030 - accuracy: 0.9985 - val_loss: 2.8614 - val_accuracy: 0.5058\n",
      "Epoch 179/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9927\n",
      "Epoch 179: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0330 - accuracy: 0.9927 - val_loss: 2.8365 - val_accuracy: 0.5233\n",
      "Epoch 180/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9811\n",
      "Epoch 180: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0587 - accuracy: 0.9811 - val_loss: 2.0249 - val_accuracy: 0.5756\n",
      "Epoch 181/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9942\n",
      "Epoch 181: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0248 - accuracy: 0.9942 - val_loss: 1.9900 - val_accuracy: 0.5233\n",
      "Epoch 182/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9927\n",
      "Epoch 182: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0332 - accuracy: 0.9927 - val_loss: 3.1883 - val_accuracy: 0.5407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9898\n",
      "Epoch 183: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0291 - accuracy: 0.9898 - val_loss: 1.9166 - val_accuracy: 0.5698\n",
      "Epoch 184/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9927\n",
      "Epoch 184: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0212 - accuracy: 0.9927 - val_loss: 2.0245 - val_accuracy: 0.5291\n",
      "Epoch 185/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9971\n",
      "Epoch 185: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0119 - accuracy: 0.9971 - val_loss: 2.0331 - val_accuracy: 0.5349\n",
      "Epoch 186/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9840\n",
      "Epoch 186: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0607 - accuracy: 0.9840 - val_loss: 1.7376 - val_accuracy: 0.5291\n",
      "Epoch 187/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9840\n",
      "Epoch 187: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0561 - accuracy: 0.9840 - val_loss: 2.3174 - val_accuracy: 0.5116\n",
      "Epoch 188/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9956\n",
      "Epoch 188: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0088 - accuracy: 0.9956 - val_loss: 2.4917 - val_accuracy: 0.5233\n",
      "Epoch 189/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9971\n",
      "Epoch 189: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 2.8849 - val_accuracy: 0.5174\n",
      "Epoch 190/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 190: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.9685 - val_accuracy: 0.5349\n",
      "Epoch 191/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 191: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1461 - val_accuracy: 0.5349\n",
      "Epoch 192/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 7.8405e-04 - accuracy: 1.0000\n",
      "Epoch 192: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 7.8405e-04 - accuracy: 1.0000 - val_loss: 3.2330 - val_accuracy: 0.5349\n",
      "Epoch 193/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 6.9661e-04 - accuracy: 1.0000\n",
      "Epoch 193: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 6.9661e-04 - accuracy: 1.0000 - val_loss: 3.2347 - val_accuracy: 0.5407\n",
      "Epoch 194/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 8.3648e-04 - accuracy: 1.0000\n",
      "Epoch 194: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 8.3648e-04 - accuracy: 1.0000 - val_loss: 3.4742 - val_accuracy: 0.5349\n",
      "Epoch 195/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.0190e-04 - accuracy: 1.0000\n",
      "Epoch 195: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 3.0190e-04 - accuracy: 1.0000 - val_loss: 3.4693 - val_accuracy: 0.5291\n",
      "Epoch 196/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.2921e-04 - accuracy: 1.0000\n",
      "Epoch 196: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 5.2921e-04 - accuracy: 1.0000 - val_loss: 3.3369 - val_accuracy: 0.5233\n",
      "Epoch 197/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.6960e-04 - accuracy: 1.0000\n",
      "Epoch 197: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 2.6960e-04 - accuracy: 1.0000 - val_loss: 3.3477 - val_accuracy: 0.5174\n",
      "Epoch 198/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 9.4039e-04 - accuracy: 1.0000\n",
      "Epoch 198: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 9.4039e-04 - accuracy: 1.0000 - val_loss: 3.2863 - val_accuracy: 0.5116\n",
      "Epoch 199/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 4.0443e-04 - accuracy: 1.0000\n",
      "Epoch 199: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 4.0443e-04 - accuracy: 1.0000 - val_loss: 3.3883 - val_accuracy: 0.5174\n",
      "Epoch 200/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 4.3345e-04 - accuracy: 1.0000\n",
      "Epoch 200: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 4.3345e-04 - accuracy: 1.0000 - val_loss: 3.4204 - val_accuracy: 0.5174\n",
      "Epoch 201/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.8007e-04 - accuracy: 1.0000\n",
      "Epoch 201: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 5.8007e-04 - accuracy: 1.0000 - val_loss: 3.3659 - val_accuracy: 0.5291\n",
      "Epoch 202/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.7793e-04 - accuracy: 1.0000\n",
      "Epoch 202: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 2.7793e-04 - accuracy: 1.0000 - val_loss: 3.4671 - val_accuracy: 0.5407\n",
      "Epoch 203/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9884\n",
      "Epoch 203: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0249 - accuracy: 0.9884 - val_loss: 4.0485 - val_accuracy: 0.5116\n",
      "Epoch 204/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.9767\n",
      "Epoch 204: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0638 - accuracy: 0.9767 - val_loss: 3.4492 - val_accuracy: 0.4942\n",
      "Epoch 205/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1154 - accuracy: 0.9637\n",
      "Epoch 205: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.1154 - accuracy: 0.9637 - val_loss: 3.3331 - val_accuracy: 0.4826\n",
      "Epoch 206/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9709\n",
      "Epoch 206: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0651 - accuracy: 0.9709 - val_loss: 1.7683 - val_accuracy: 0.5116\n",
      "Epoch 207/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9971\n",
      "Epoch 207: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0137 - accuracy: 0.9971 - val_loss: 2.2687 - val_accuracy: 0.5000\n",
      "Epoch 208/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9971\n",
      "Epoch 208: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 2.6889 - val_accuracy: 0.4884\n",
      "Epoch 209/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9956\n",
      "Epoch 209: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 1.8039 - val_accuracy: 0.4942\n",
      "Epoch 210/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9927\n",
      "Epoch 210: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 1.8286 - val_accuracy: 0.5349\n",
      "Epoch 211/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9869\n",
      "Epoch 211: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0327 - accuracy: 0.9869 - val_loss: 2.3036 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9869\n",
      "Epoch 212: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0456 - accuracy: 0.9869 - val_loss: 2.0867 - val_accuracy: 0.5116\n",
      "Epoch 213/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9913\n",
      "Epoch 213: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 1.8210 - val_accuracy: 0.5174\n",
      "Epoch 214/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9898\n",
      "Epoch 214: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0245 - accuracy: 0.9898 - val_loss: 2.3513 - val_accuracy: 0.5174\n",
      "Epoch 215/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9942\n",
      "Epoch 215: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 2.2865 - val_accuracy: 0.4651\n",
      "Epoch 216/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.9840\n",
      "Epoch 216: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0516 - accuracy: 0.9840 - val_loss: 2.9066 - val_accuracy: 0.5000\n",
      "Epoch 217/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9956\n",
      "Epoch 217: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 3.4266 - val_accuracy: 0.4884\n",
      "Epoch 218/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 218: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.6349 - val_accuracy: 0.4884\n",
      "Epoch 219/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9985\n",
      "Epoch 219: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 3.8911 - val_accuracy: 0.4884\n",
      "Epoch 220/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9927\n",
      "Epoch 220: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0499 - accuracy: 0.9927 - val_loss: 3.2502 - val_accuracy: 0.4884\n",
      "Epoch 221/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9985\n",
      "Epoch 221: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 3.0622 - val_accuracy: 0.5058\n",
      "Epoch 222/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 222: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.8499 - val_accuracy: 0.4884\n",
      "Epoch 223/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9985\n",
      "Epoch 223: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0025 - accuracy: 0.9985 - val_loss: 2.7638 - val_accuracy: 0.4651\n",
      "Epoch 224/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 224: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.8805 - val_accuracy: 0.4826\n",
      "Epoch 225/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 225: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.8550 - val_accuracy: 0.4826\n",
      "Epoch 226/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9985\n",
      "Epoch 226: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0036 - accuracy: 0.9985 - val_loss: 2.9459 - val_accuracy: 0.4651\n",
      "Epoch 227/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9942\n",
      "Epoch 227: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0238 - accuracy: 0.9942 - val_loss: 3.0947 - val_accuracy: 0.4884\n",
      "Epoch 228/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9971\n",
      "Epoch 228: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0044 - accuracy: 0.9971 - val_loss: 3.4965 - val_accuracy: 0.4767\n",
      "Epoch 229/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 229: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.1380 - val_accuracy: 0.5000\n",
      "Epoch 230/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 5.8372e-04 - accuracy: 1.0000\n",
      "Epoch 230: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 5.8372e-04 - accuracy: 1.0000 - val_loss: 3.0949 - val_accuracy: 0.5058\n",
      "Epoch 231/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.4442e-04 - accuracy: 1.0000\n",
      "Epoch 231: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 3.4442e-04 - accuracy: 1.0000 - val_loss: 3.1770 - val_accuracy: 0.5058\n",
      "Epoch 232/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 6.5867e-04 - accuracy: 1.0000\n",
      "Epoch 232: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 6.5867e-04 - accuracy: 1.0000 - val_loss: 3.2051 - val_accuracy: 0.5058\n",
      "Epoch 233/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.0171e-04 - accuracy: 1.0000\n",
      "Epoch 233: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 2.0171e-04 - accuracy: 1.0000 - val_loss: 3.2662 - val_accuracy: 0.5058\n",
      "Epoch 234/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.3902e-04 - accuracy: 1.0000\n",
      "Epoch 234: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 2.3902e-04 - accuracy: 1.0000 - val_loss: 3.3329 - val_accuracy: 0.5000\n",
      "Epoch 235/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.6455e-04 - accuracy: 1.0000\n",
      "Epoch 235: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 1.6455e-04 - accuracy: 1.0000 - val_loss: 3.3676 - val_accuracy: 0.5000\n",
      "Epoch 236/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.3816e-04 - accuracy: 1.0000\n",
      "Epoch 236: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 1.3816e-04 - accuracy: 1.0000 - val_loss: 3.3910 - val_accuracy: 0.4942\n",
      "Epoch 237/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 9.8925e-04 - accuracy: 1.0000\n",
      "Epoch 237: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 9.8925e-04 - accuracy: 1.0000 - val_loss: 3.4030 - val_accuracy: 0.4942\n",
      "Epoch 238/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9884\n",
      "Epoch 238: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0221 - accuracy: 0.9884 - val_loss: 3.5803 - val_accuracy: 0.5058\n",
      "Epoch 239/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.9753\n",
      "Epoch 239: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0671 - accuracy: 0.9753 - val_loss: 2.5102 - val_accuracy: 0.5407\n",
      "Epoch 240/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9898\n",
      "Epoch 240: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0212 - accuracy: 0.9898 - val_loss: 2.1406 - val_accuracy: 0.5058\n",
      "Epoch 241/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9956\n",
      "Epoch 241: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0103 - accuracy: 0.9956 - val_loss: 2.4272 - val_accuracy: 0.5116\n",
      "Epoch 242/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9971\n",
      "Epoch 242: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 2.8939 - val_accuracy: 0.5116\n",
      "Epoch 243/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 243: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.1053 - val_accuracy: 0.5058\n",
      "Epoch 244/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 244: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.2773 - val_accuracy: 0.5000\n",
      "Epoch 245/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000    \n",
      "Epoch 245: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.4465 - val_accuracy: 0.5116\n",
      "Epoch 246/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9985\n",
      "Epoch 246: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0039 - accuracy: 0.9985 - val_loss: 3.3774 - val_accuracy: 0.5349\n",
      "Epoch 247/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9985\n",
      "Epoch 247: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0027 - accuracy: 0.9985 - val_loss: 3.1755 - val_accuracy: 0.5233\n",
      "Epoch 248/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 248: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.0768 - val_accuracy: 0.5174\n",
      "Epoch 249/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 7.1767e-04 - accuracy: 1.0000\n",
      "Epoch 249: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 7.1767e-04 - accuracy: 1.0000 - val_loss: 3.3244 - val_accuracy: 0.5174\n",
      "Epoch 250/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.7387e-04 - accuracy: 1.0000\n",
      "Epoch 250: val_accuracy did not improve from 0.59302\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 2.7387e-04 - accuracy: 1.0000 - val_loss: 3.2896 - val_accuracy: 0.5116\n",
      "=== Batch Size:  16\n"
     ]
    }
   ],
   "source": [
    "if ql4 == 1:\n",
    "    ## For Quanv Exp.\n",
    "    early_stop = EarlyStopping(monitor='val_loss', mode='min', \n",
    "                               verbose=1, patience=10, min_delta=0.0001)\n",
    "\n",
    "    checkpoint = ModelCheckpoint('checkpoints/best_quanv_demo24.hdf5', monitor='val_accuracy', \n",
    "                                 verbose=1, save_best_only=True, mode='max')\n",
    "    if net == 0:\n",
    "        modelq = dense_Model(x_train[0], labels)\n",
    "    elif net == 1:\n",
    "        modelq4 = attrnn_Model(q_train4[0], labels)\n",
    "    modelq4.summary()\n",
    "\n",
    "    q_history4 = modelq4.fit(\n",
    "        x=q_train4, \n",
    "        y=y_train,\n",
    "        epochs=eps, \n",
    "        callbacks=[checkpoint], \n",
    "        batch_size=bsize, \n",
    "        validation_data=(q_valid4,y_valid)\n",
    "    )\n",
    "\n",
    "    keras.models.save_model(modelq4, 'checkpoints/'+ data_ix + '_quanv_model_demo24.hdf5') \n",
    "    modelq4.save('checkpoints/'+ data_ix + '_demo24.hdf5')\n",
    "\n",
    "    print(\"=== Batch Size: \", bsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "87156df1",
   "metadata": {
    "id": "87156df1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 27ms/step\n",
      "22/22 [==============================] - 1s 35ms/step\n",
      "\n",
      "Quanv Train Accuracy: 1.00\n",
      "\n",
      "\n",
      "Quanv Valid Accuracy: 0.58\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 31ms/step\n",
      "22/22 [==============================] - 1s 36ms/step\n",
      "\n",
      "Quanv Train Accuracy: 0.98\n",
      "\n",
      "\n",
      "Quanv Valid Accuracy: 0.65\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if ql0 == 1:\n",
    "    modelq=modelq0 \n",
    "    y_pred=modelq.predict(q_valid0)\n",
    "    y_pred1 = (y_pred > 0.5) \n",
    "    y_pred=modelq.predict(q_train0)\n",
    "    y_pred2 = (y_pred > 0.5) \n",
    "\n",
    "    y_pred=np.argmax(y_pred1, axis=1)\n",
    "    print('\\nQuanv Train Accuracy: {:.2f}\\n'.format(accuracy_score(y_train, y_pred2)))\n",
    "    print('\\nQuanv Valid Accuracy: {:.2f}\\n'.format(accuracy_score(y_valid, y_pred1)))\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "    plot_confusion_matrix(cm , \n",
    "                          normalize    = False,\n",
    "                          target_names = labels,\n",
    "                          title        = \"Quanv 2 qubits Depolarizing Circuit with p=0 Confusion Matrix\")\n",
    "    \n",
    "    modelq=keras.models.load_model('checkpoints/best_quanv_demo20.hdf5') \n",
    "    y_pred=modelq.predict(q_valid0)\n",
    "    y_pred1 = (y_pred > 0.5) \n",
    "    y_pred=modelq.predict(q_train0)\n",
    "    y_pred2 = (y_pred > 0.5) \n",
    "\n",
    "    y_pred=np.argmax(y_pred1, axis=1)\n",
    "    print('\\nQuanv Train Accuracy: {:.2f}\\n'.format(accuracy_score(y_train, y_pred2)))\n",
    "    print('\\nQuanv Valid Accuracy: {:.2f}\\n'.format(accuracy_score(y_valid, y_pred1)))\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "    plot_confusion_matrix(cm , \n",
    "                          normalize    = False,\n",
    "                          target_names = labels,\n",
    "                          title        = \"Best Quanv 2 qubits Depolarizing Circuit with p=0 Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "29126df5-a560-4278-afef-5f1cc8d2d57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 31ms/step\n",
      "22/22 [==============================] - 1s 32ms/step\n",
      "\n",
      "Quanv Train Accuracy: 1.00\n",
      "\n",
      "\n",
      "Quanv Valid Accuracy: 0.56\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 31ms/step\n",
      "22/22 [==============================] - 1s 33ms/step\n",
      "\n",
      "Quanv Train Accuracy: 0.63\n",
      "\n",
      "\n",
      "Quanv Valid Accuracy: 0.65\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if ql1 == 1:\n",
    "    modelq=modelq1 \n",
    "    y_pred=modelq.predict(q_valid1)\n",
    "    y_pred1 = (y_pred > 0.5) \n",
    "    y_pred=modelq.predict(q_train1)\n",
    "    y_pred2 = (y_pred > 0.5) \n",
    "\n",
    "    y_pred=np.argmax(y_pred1, axis=1)\n",
    "    print('\\nQuanv Train Accuracy: {:.2f}\\n'.format(accuracy_score(y_train, y_pred2)))\n",
    "    print('\\nQuanv Valid Accuracy: {:.2f}\\n'.format(accuracy_score(y_valid, y_pred1)))\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "    plot_confusion_matrix(cm , \n",
    "                          normalize    = False,\n",
    "                          target_names = labels,\n",
    "                          title        = \"Quanv 2 qubits Depolarizing Circuit with p=0.001 Confusion Matrix\")\n",
    "    \n",
    "    modelq=keras.models.load_model('checkpoints/best_quanv_demo21.hdf5') \n",
    "    y_pred=modelq.predict(q_valid1)\n",
    "    y_pred1 = (y_pred > 0.5) \n",
    "    y_pred=modelq.predict(q_train1)\n",
    "    y_pred2 = (y_pred > 0.5) \n",
    "\n",
    "    y_pred=np.argmax(y_pred1, axis=1)\n",
    "    print('\\nQuanv Train Accuracy: {:.2f}\\n'.format(accuracy_score(y_train, y_pred2)))\n",
    "    print('\\nQuanv Valid Accuracy: {:.2f}\\n'.format(accuracy_score(y_valid, y_pred1)))\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "    plot_confusion_matrix(cm , \n",
    "                          normalize    = False,\n",
    "                          target_names = labels,\n",
    "                          title        = \"Best Quanv 2 qubits Depolarizing Circuit with p=0.001 Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6d6e521d",
   "metadata": {
    "id": "6d6e521d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 34ms/step\n",
      "22/22 [==============================] - 1s 33ms/step\n",
      "\n",
      "Quanv Train Accuracy: 1.00\n",
      "\n",
      "\n",
      "Quanv Valid Accuracy: 0.56\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 30ms/step\n",
      "22/22 [==============================] - 1s 33ms/step\n",
      "\n",
      "Quanv Train Accuracy: 1.00\n",
      "\n",
      "\n",
      "Quanv Valid Accuracy: 0.67\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if ql2 == 1:\n",
    "    modelq=modelq2 \n",
    "    y_pred=modelq.predict(q_valid2)\n",
    "    y_pred1 = (y_pred > 0.5) \n",
    "    y_pred=modelq.predict(q_train2)\n",
    "    y_pred2 = (y_pred > 0.5) \n",
    "\n",
    "    y_pred=np.argmax(y_pred1, axis=1)\n",
    "    print('\\nQuanv Train Accuracy: {:.2f}\\n'.format(accuracy_score(y_train, y_pred2)))\n",
    "    print('\\nQuanv Valid Accuracy: {:.2f}\\n'.format(accuracy_score(y_valid, y_pred1)))\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "    plot_confusion_matrix(cm , \n",
    "                          normalize    = False,\n",
    "                          target_names = labels,\n",
    "                          title        = \"Quanv 2 qubits Depolarizing Circuit with p=0.001 Confusion Matrix\")\n",
    "    \n",
    "    modelq=keras.models.load_model('checkpoints/best_quanv_demo22.hdf5') \n",
    "    y_pred=modelq.predict(q_valid2)\n",
    "    y_pred1 = (y_pred > 0.5) \n",
    "    y_pred=modelq.predict(q_train2)\n",
    "    y_pred2 = (y_pred > 0.5) \n",
    "\n",
    "    y_pred=np.argmax(y_pred1, axis=1)\n",
    "    print('\\nQuanv Train Accuracy: {:.2f}\\n'.format(accuracy_score(y_train, y_pred2)))\n",
    "    print('\\nQuanv Valid Accuracy: {:.2f}\\n'.format(accuracy_score(y_valid, y_pred1)))\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "    plot_confusion_matrix(cm , \n",
    "                          normalize    = False,\n",
    "                          target_names = labels,\n",
    "                          title        = \"Best Quanv 2 qubits Depolarizing Circuit with p=0.01 Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "w0AUf24QwMM2",
   "metadata": {
    "id": "w0AUf24QwMM2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 30ms/step\n",
      "22/22 [==============================] - 1s 34ms/step\n",
      "\n",
      "Quanv Train Accuracy: 0.99\n",
      "\n",
      "\n",
      "Quanv Valid Accuracy: 0.59\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAHWCAYAAAAo8M7SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABj4ElEQVR4nO3dd9xbZf3/8de7LW0pUEYrUDaIgDK+IkNBvwgiiqAiDoYiQwQHiOurKLIVEVBBAUVQLPyQJYgsEVlV9laWlFEKlLJKF93r8/vjukLTNPd9J2lycufu+9lHHndzzpVzPjk5ST651lFEYGZmZma9U792B2BmZmZmXXOyZmZmZtaLOVkzMzMz68WcrJmZmZn1Yk7WzMzMzHoxJ2tmZmZmvZiTtT5AUkgaWWPZA3P5HVsaVB8gaaSkls1tI2mspFENPK4jX0NJO+a4D2xzHKMkjW3j/tfLx+H4VpS3pYukfpKOlzRG0rze+Jm1tMmvR0har1nbrDlZkzRU0jGSHpL0pqQZkp6QdKqkVZsVUG8jabCkQyRdnU/UmflNcYmkd7Y7vmaQ9O58cq3X5O2WvmRKtwWSpkgaLelSSZ+TNKCZ+7TiSdo6J7Zj8vtjuqTHJJ0haZN2x1eLnAB/q437Xym/B3dsVwzNJGmQpBMlPSdptqRnJR0taZlWbUPS/pIezufgq5J+L+ltVcrtIukcSfdLmrUkP3x6ybl/AHAccBtwMPDFgvbbFqUf0fm2dRdlvl1W5sAG99O73pMR0eMN2Ah4DlgAXAEcBhwKnA/MAV4H3lvLtjrtBmwCBHA7cAzpzXASMBGYDezUC2IMYGSNZfsDg4F+ZcsOzNvYsclxrZe3+w9gv3z7KnAq8ERe9yCwTruPYRfxj0xvkZZtfxAwsIHHLfYatvEYHZc/F14DzsifC18FzgReBuYBK+Sy/XLc/dsc80BgUMWyUcDYgvavfBwGlC0rvVeOr1K+y3W99Qb8Ncf8B+DL+W/Nn1P1bgP4dl43Kp+DJwLTgMeB5SrKjszfWw8BDzf62VfPud/iY30xMBlQAftq6DOryTGMzK/ZTODsLso8ktcHcGCD+2n4fQcMyO/xpr0mtex0CDA6n9y7V1m/dT5RXgVWbeeL2KITYxjw7irL30VK1h7oBTHW9SFY5fEHNvqB1cN2Syf7WV2s/1Ze/2j5F1dvudGCZA1YBhjc7ufWpOfypfz63QqsWGX9ssDPgKF1blfA8gU/l1EUlKx1sf8uvxiW5EujTc9ltxzvLyqW/yIv376Z2wCGA9OB+yj7IQB8Ipc9qmIba5KTdeD/Gvnsa9W53+DxvrWd524bzq+R+dhfTKo0qfzhtU1e/ycKTtZoYXJey86/kQM+tZsyX89lTitb1mUCUO2DEfgIcBkwhpQRTybVyHywq8cDawCXAJOAGcCNwEZl5T6WYziii7jvJtUKLtPgi/kgMKuO8nuQfsnNAl4EfgzsUnlCAcfnZetV2cZYYFTFssgn8IeBe/KxeAX4FRVfepWvS9m+Km8j8/rBuczovN3JpOTqtBqeb+lkr5qs5TIX5TL7VSwfBBxF+mU8K+/3WmDLinI7lo5fPlefyuWfAr7RxT53AG4CpuRz7SHg4CrlRlKRrJFqWn+T43ozH5MHgS9XeXzp2G4K/BIYB8wvO/aLvJbdvBal23pdvbfKln2I9AX0LOnHxFPAAVVi60+qKX4+H69HgL3p5tyrePxAUu3Bm8Dbajz/33qtunj9DiPVuM6m7AMS+AzpPT85H+/RwK/Jv/CrHY8ePmsWWZZfh2rHe7HtlT3mtirb3Tc/7j8Vy7+Wl7+34n1xfMUxqLyNrSwPfBy4P79mLwOnUeMPHer4nFiSGwvf02tXLF87L/9NM7dBqnUL4ItVtvMs8EQ3+6k7WWvk3M+PGw6cTfrsn5P/ng0MqyhXOp+7fS93c96MLDuvR1WJo/S48vdhTZ/z3WzzU8CdpKR5Wv7/HlXKjSW9/zYBrs/HcAqpxW71Go/jyBx/6btz74r1vyHVdpbej+XPsx/wI+Bf+dyfA7wA/Lb8dejm2FZ7T+5N+g6YWXbsj2fRz+wVgGfyebNqRbw/zWW/1N3zrqW/0Gfz33O7KTOSVA38GeB7NWyzmgOBVYALSV9qa5LehLdI2ikibq8ovxzpgN9D+lJfH/gmcLWkzSJiPinZewXYn/Th/hZJ7wDeB/w6IubWG6ykfsAIUo1iLeX3BK4knawnkqrIDwJ2r3ffXXgP6bU6j3QMdwKOADaTtEtELOjicX8hPY9DSSfNf/PyZ/Pfs0m/Ii8kJRwDgHeQPkia4ffAF0jH4SKA3Cfl78D2wP8DzgJWBA4B7pS0Q0Q8ULGdbwCrA78jfQDsC/xa0ioRcUKpkKRPAFeRzotf5LL7AL+XtEFE/KiHeHckJXvXkboGLAd8DjhP0tsi4uQqj/kT6Y1cqhV4uYtt/4X0hi43OD9uQI61Jz8l/ar/HekD/mvASEnPRMSdZeXOIjXZ3Ab8HHgb6UPuuRr2AfB+0vH+fxHxeo2P6c63SLXY55FemxcBJJ1Een8/AZxOOnZvJ33WHEv6sG3Gvk8mfZl+u2z5f6uWTm4FTpT09ogovVd2JjWLbS5peERMyMs/BEwFKs/Z8v18m/T8riKdB5C+9MrtRvphfA6pC8oepC/zSaTXvRY1fU7k9+CKNW6TsucKqWbjpYh4saLMi5LG5/U9qWcbpf/fXWU79wD7Slo+IiqPZ6PqPvclrQjcBWxIeu0eArYkvT8/JGnbiKh8f/f0Xv4vqX/aj1j03H2W+jX8OS/p6/nxT5K+2yB9n/9V0lciojJ3WJOUsF1Fyhf+B/gKMJRUaVOrh4F/57gvy7EMJn32/xGo9r0+MO/zSuBqUnK5Dal70wckbRURc6j9Pfkp0vvnt6T35dRqgUbEm5L2ISWxF0jaLSJC0s7AkcClEXF+t8+2hiz2DWBqDeUeIX0RLV/x62CxXyxU/7W7XJVyqwETgL9VeXwA369Y/r28/KNly07Ly95VUfbHefl7asnmq8RWqk08sYay/UnZ+wRgeNnyFUk1G5XZ//HUX7MWwKcqlv8qL9+nbNlir0sPr9XEyuNfxzFaj55r1lbJZR4sW1bqf/LRirJD83EcVbZsx1z2TWCtsuUDSc0ic0vL8+vwPOlX4xoVZe8k1Xq9o2z5SBavWat2nvbL5+QUymppy17HUVSp/aj2WlasF3ApKQHYs8bX8GHK+pSQPhhnA5eULds0l/07i/Zd3Dwfg6rnXkVspRr379RxPpReqwOrLJvI4r84t2VhU9PginUi9wfp4fwdRQ81a10t6+G5vD/v85CyZWNIPy4C2KsszteBa6u8L47vblmVddPLX5e87ceAl2uMuZ7PiR3Lyvd4q9jem8C9XcRwHzC+hlhr3gapxj2AZauUPTWv26iLbTVSs9bIuX9SfszXK5Yflpf/uGxZ6Xzu8b3c3blLfTVrNX3OV24TWJmUwDxDWZMv6bP62fw6rlTx+LfeH2XLz87LN64hhpG57PD8Wsxn4Wf85/O6zUg/Siqfp7o4Tw6ujIva3pNzgXdWWX88VT5Hge/k5f8HrEr68TmGGprLaxkNOpT0JdSTUka5Qg1lFxMR00v/l7S8pGGkF+Fe4L1VHrKAitoy0oc6pF8EJRfkv/uXbV+kzu6PRcRD9cYqaXvSr4//UNsv2q1I1fd/jLJfoBExhZSNN8PoiPhrxbKf5b97LsF2pwCbStpsCbbRndJ5M7Rs2X6kX2kPShpeupGSqptIv4CWrdjOnyJiXOlOpF9Hp5N+IX4iL94KWAc4PyLGV5Q9lZR07dFdsBXn6eB8nq5CqsUdSqrer3RGRMzrbrtd+DGpiv0HEXFVjY/5TX4+pXhfIjWflL8nPp7//irKalwj4lFSV4JalF6vqr8kG3BhRLxWsewL+e8PI2JW+YrImrTvRtxH+pL6EICkdUm1+5eQEqidc7nNSV8qt1bZRr3+GhFjS3fy878NWF3S8jVuo9bPif+QmplqvZUbQkoqqpmV1/eknm2U/l+t/KyKMs3QyLm/Jylpr6xl+l1eXu0zupb3crM0+jm/C6l14dcR8dbxyP//NbA8qdm93PiIuLxiWbXv7lr8iZQwHZDvHwTcHxGPVSucPzZmAkjqn0d8lr8/q+Ua3bk+Irqrga90OvA3Ut5wHak1YZ/yY9eVWppBp7LoF2lXhpISqAk9FaxG0ttJvz4+CqxUsbrah/L4yg9wUi0gpAOQHhjxmKSHgC9IOip/Oe1Ayoy/30CcW5Ha2seTBlxUxlDNBvnvk1XWPVFvDF1Y7ISJiJclTS7bfyO+RaoteFTSGNKXw7WkmoKumlbrUe2D752k6v/umhiGk5vKsmpvmNKxLT3/9fPfx6uUfbyibFX5S/F4YC9SAl5p5SrLnupum13s5wBS88YfIuLUOh46psqyN4B1y+6XjsPoKmVHk/p69mSJfpxVUe0YvYPcB6xJ+2iaiJgr6Q5SMyKk5GweqWvGraQmS1jYjNSMZK2r1xbSZ14tzXw1fU5ExCTg5gZihNTnaVAX6wbn9c3cRun/g0jdDSrLlpdphkbO/fVJg9EW+dEWEfMkPUVqnq5Uy3u5Wb5FY5/zjXym9nQe1ywiJkq6BjhQ0kWk99vh3T1G0l7Ad0nN0JXTwFT7/O5OXZ/tERH5s/1pUvPrjyLivloeW0uy9hiwg6QNI6KyPw0AkoaQahSej4X9v7r71bvIfvMX4L9IGfoZpI6Nb5KSvx9Svd18fjfbV8X9C/N2P0T6ANo/P/6ibrax+Eal97CwY/pO+ZdOK9R87FotIq5Wmn9tN+CDpF9JBwO3S/pw+S+/Bm2R/5YnDiKdA9/p5nHN6CfViItJNVPnks7ZN0jn0m6k5ttqtdV1fVHkeX3OI33Bf63O+Lp6X1S+J5ZU6Zfrlk3aXlfHqNTU1p12vV9uBXaVtCnps+X+iJgm6VbgCEnr5OUTSN1EllQ9n3lLRNJAUo1xTSLilbK740lNdtWsCdTyuVnPNsaXLa/8jlqTdH6Mp3mafe53ZUnfy129LxZ7TxTwOV+u2efx+cANpM/MOaTa7eoblz5N6t92H6mP+4uk2tf+5G4hde67kR8BO7CwQurdtT6olsCuyH+/3E2Z/UkZannyMzH/rfaGX7/i/s6kkZ3fjojjI+LKiPhHRNxMSuCW1MWkqtL9c/PZZ4GbIqKrjt6LyYnazaQkcqeIeL6O/Zd+SVRrIntXlWVVj13uPDmii30sNkGvpBGkk6LaL5ly3X4ZRsTEiLgoIg4h/Uo6FfhfemgyrFHpvLq+bNnTpA7vt0bEzV3cKms0q01QXDq2Yyr+blpD2cVIWomUqP2/iPhqRFwcETfm87QpH2aSNiZ1Zh0DfDYaGPxSg7H578ZV1lVbVs2dpIEAn8pNwa3wFOkz6n96KFfPZ01XGmlSLdWW7UxKym7J90eRvpA+QvpgHlVDk21RTbq1fk5sT+pPU+ut3P3AmpIWqXnO99eg64EWjW7j/vx3uyrbeR+p6bdZgwugsXN/DLCxKiYBz/c3oufP6EZMpPp7omrrQYOf80v0mdok/yANStwF+EtETO6m7BdJydlOEfHbiLguf35X+z5v+nsy/4D7PSnh/yXwOUmH1PLYWpK1P5A+NL8jadcqO38PaSTVy6ROgiWl6sEPV5Tfl/RmK1fKtFVR9iPU34a8mEgjdm4APk3qBzOUhX3ZeiRpS1KN2jTSi/xcnSE8SDqZDsrt46XtDiWNyKtU9djRdc0NpA+CT1UsOzL//WsP8ZU+yCqTw/45QXlL/tJ5uFr5ekn6Jun1eIQ8mie7kDTaqmrNmqTVqiz+gqS1ysoMJB2v+aS+AZBGYL1Aeh1WLyu7DAsHp1zdTchdnacj6P7HTE3yB//1pBrl3XNTVCtcm/9+M49qLu1/c1I3hB7lX9o/IjUFXSZpsSah3Kfvp/k8b8TF+e9P8+tZuf3S61DPZ01XpgErl22zFg+TRmJ+lfQj6lZ4qy/qQ6Tzb0VqawKt+h5sgVo/J5akz1qpZuNbFctL9/9UvlDSJrkbTKPbuJrU/Hm4pP5l2/0EKelYZH9LqsFz/6+kH6CVnxOH5OW19kmtx1PAJpLeqqGUNIg0qKE81iX5nL+JNPDlG+XHIf//G6Tz+qYleA49ys20hwEnAKf0ULw0gKr8c0/A0VXKNvU9mc/Ni0lN83uT3nd3A2eohqsh9dhEEBEzJH2SVEV4vaQrSb8c55FGa32R9IH1yYh4texxoyXdDHwlH4x/k6r89iRVVZe3Fd9BnkohV8WOy2W/SGoO27ynOGtwAfBJ0jQIU+g5gQHe6jh8E6kt+9fA9nmAQbmryjueV4qI+ZK+DVwO3CfpPNLx+xKpGW2diofcTGoWPDF/gT8HfID0K7GrPoGPAhflbT9N6kvzWeCfLJoIVXM/KUH4kaSVSW++53IML+c+AQ+T5q5Zn9Q0N4mFX/o92UjSfvn/Q0hTL3yc9MvrQdLotPK+HL8ifQGcJulDpC+7qaTjtDP5l1HFPp4C7pV0Dqn28/OkPgE/jjz8P78Oh5M+GO+XdG4uuzfp2P40Ip7u6klEGn79D2A/STPzcVuXNOz8Oersb1HFb0jH5hxgO0mVNQXdnme1iojH83M/FLhZ0lWkL4zDSK/zVtTwqzIizs81HccBz0i6mNRPsB+pBudzpBFP1aYzqSXO+ySdQvpQe0jSZaTPifVJ5/a2wOQ6P2u6cg/pnDxL0l2kD/Vbqwx6KI9vgaR/kobvzyJNzVByKwuToB6TtYh4Q9IzwD6SniVNCTQ9Imp9j9Wqps+JJemzFhHXS7qO9AN/RdIX0nakZrWLIuKOiof8l1SzsV4j24iI1yUdQ5qC5mZJl5CaP79L6id8RvnOJG1B+i6ANKoX4IuSPpD/f2ZOuLt7jvWe+6fmZWfnCo6HSc2oB5M+Z+vpl1qrs0jTEt2cPxcHkr5TK5vuVqDBz/mImCzp+6SKmnu18BrVB5KmKflKT8eyGSLiGuCaGopeQZr251ZJF5I+Gz5FlQEoLXhPHk863w6NiCcAJH2e9Hl1qdL0LV0NqqGmYcexcCjuMaQXcxoL+5I8RtnQ3IrHrA78mfRFO41Uu/VOqg+d34KUEE4ifYGOIlXBjmTxoeGLPT56Hmo7kJQYBXBeHc97x7Ln2tVtvRq39en8wsymm0lxc9mN8vEoTVB4OekDaCzdT4p7L+lX5quky56sUFH2QKoMVSeNpnmC1JxX2t5A0ofNffnYzc77P5+yKS66eb6l16N0W5DPhadIU1J8ji4m9CT9kDiClBBNz7enSb+SP1Ll9Tkwl386x/k08M0utv1BUgI+lfQl+zC1T4o7nFSNPT4/9lHSr+PFjis9TDBb+VqycEqabs+zLvZV9XXt6v1C6qNxHKmmcTapdnMv0hdeUMfVSEhXMbmAlLDOIp2zj5Kq+cunQnnrtepuWZXt70tqenoznwelL+DyaQ3q+ayptmwIqRXhVRb++l7sWFaJrTSNwy0Vy0vv63G1fk6Rks/SxKJBlQk4q2yr23Os0c+JJb2Rag9+QjrHZ5Oawo6hygTk5c+10W2UvQf+k8/B10ifU4udxyx8ryzR53k9534uW5rLcBypW844UpIzvIv4an0vL7asbN0BLLwC0XOkQXUfouw9Rx2f83Q9HciepB8rpc/qu6iYIqaHx+9ID58DZWVH5rLDeyi32NQdefkhpO+60sTS57JwCqmRS/qerPa+zM9vPnBZlbJ75bJndvd8SvMU1S23tf+ZlJV+JyJOb2hDSzmlzuS3AQdFxMi2BtOBfPyaS9K1pA/zoZEmlrY+QlIAF0TEge2OxczqU+/Ih7dEarbamzRnyC8l1TtqzczaRIvPU1dqHvoYqfnPiZqZWS+xRMPaI3W0bNblksysOAdI2p80oOF10kjlQ0nNJce2MzAzM1tUoXN2mVmv8RCpn8kRpP4ab5I6wp8QEQ+3MzAzM1tUw33WzMzMzKz1Gu6zZmZmZmat52ZQ6zMGr7ByLPe2WudAtb5s2JBaplazpcGrL73IlElvNPtya/Qfum7EvMpLkXYvZr5+Y0QsNrm8WU+crFmfsdzb1mD3H1/cc0Hr8/bb0km7JYfvVXmBheaIebMYtMk+dT1m1sNnDu+5lNninKyZmZnVS0BdVycza5yTNTMzs0bI3b6tGE7WzMzMGuGaNSuIfxaYmZnVTalmrZ5bT1uUDpQUVW5fLSsztsr6V1r6VK3tXLNmZmbWiNbVrH0IKB9qOqZi/cXAmWX357QqEOsdnKyZmZnVS7Syz9r9ETGtm/UvR8Q9rdq59T5O1szMzOom91mzwrjPmpmZWSOa3GetzLOS5kkaLekrVdYfLGmOpCmSrpC0bpOekfVSrlkzMzNrRPNr1l4GjgHuA/oD+wDnSBoSEafnMlcD9wDjgHcCxwG3S9o8IqY0OyDrHZysmZmZ1U2N9FkbLumBsvvnRsS5pTsRcSNwY9n6GyQNBo6W9KuIWBAR3yxbf7uku4B/AwcBZ9QbkHUGJ2tmZmb1auwKBhMiYus6H3MFsBewHouPCiUiHpM0GnhPvcFY53CyZmZm1ohirmAQFX+7KtPdeutwHmBgZmZWt+ZPituFzwITgOerRiFtBmwCPNjoDqz3c82amZlZI/o1d4CBpCtJgwseIQ0w2DvfjoiIBZJ2B/YDrgPGk5K0o4EXgJFNDcZ6FSdrZmZm9WrNpLijgS8Ba+c9PAHsHxH/L69/EViVNJBgJeAN4O/AURExtdnBWO/hZM3MzKwRTZ66IyKOAo7qZv0jwM5N3al1BCdrZmZmdWto6g6zhjhZMzMza4QvN2UFcbJmZmbWCNesWUGcrJmZmdVLvpC7FcfJmpmZWSNcs2YFcbJmZmbWCNesWUGcrJmZmdXNo0GtOE7WzMzMGuGaNSuIkzUzM7N6teYKBmZVOVkzMzOrm5tBrThO1szMzBrhZlAriH8WmJmZmfVirlkzMzNrhJtBrSBO1szMzBrhZlAriJM1MzOzeskDDKw4TtbMzMwa4Zo1K4iTNTMzswbIyZoVxMmamZlZnYSTNSuOkzUzM7N6Kd/MCuBkzczMrG5yzZoVxsmamZlZA5ysWVGcrJmZmTXAyZoVxcmamZlZA5ysWVGcrJmZmdXLAwysQE7WzMzM6iQPMLACOVkzMzNrgJM1K4qTNTMzswY4WbOiOFkzMzNrgJM1K4qTNTMzs3p5gIEVyMmamZlZA1yzZkVxsmZmZlYnjwa1IjlZMzMza4CTNSuKkzUzM7NGOFezgjhZMzMzq5dcs2bFcbJmZmbWACdrVhQna2ZmZg1wsmZFcbJm1sFWXnYAp3xiEwYv059DLnuU2fMWAPCLPd7J25YfuEjZyTPncsRfnmhHmNYCq60wkHWHDWHIwP707ydmzZ3P+CmzGTthBpHLDOgnNl5tOVYdOghJTJ4xl/++/CYz5y5oa+x9gUeDWpGcrJl1sH3eswaz5i1g8DL9F1t313OTuGn0hLfuz1sQi5WxzrVM/35MnD6HsW/MY+78YMVlB/D2ty3HoAH9ePKVaQBssdZQlh/Unydfmca8+cEGbxvC1uuuxF1jJjHf58OSc65mBXGyZtahNl51OTYfsQLXPv4a+75njcXWT545l2ffmNGGyKwI4ybPWuT+pBlzGdBPrL3Ksjz5yjRWXHYAw5cfyAPPT2bi9LkATJk5l/99xzDWWnkwz78xsx1h9x0eYGAF6tfuAMysfhJ8ces1ufrRV3lz9rx2h2O9xNz5Qb+cQKwweAALIt5K1ADmzA/enDVvsSZya4ykum5mjXLNmlkH+tA7hjGgn7j5qQlst/7KVct88O2r8JGNhzNnfvDYK29yyUPjeaPsi9v6jn6CoYMHsM4qy/LipJl5mYgqLZ0LIlhukD/6m8EJmBXF71izDrP8wP58ZovVOeeuF5jfRbejh8ZN4dkJM5g4Yy5rrDiIT22+OkfvsiFHXT/ancv7mJ03GU7/filpGD95Fk+9Oh2AmXPm07+fWH5Qf6bNng+kpG75QQMY0N9JRlP4MFpB3AzaApJ2lBSSNuuh3M8ljS0orI4jaS9JB7Y7jt7ms+9enWcnzOCR8W92WeZPD47nnucn89Tr0xn1zEROu3UMKy27DDtssEqBkVoR7hs7mfuem8ToV6bxthUG8s7VlwdgwrQ5zJgzn3eNWIEhA/szcEA/3jViBQb0r17jZvVrdjOopAPzd0fl7atlZSTpKEkvSpop6V+S3t3K52nt55q11ngI2A54tt2BdLi9gOHAyDbH0WusueIgdthgFU666VmGLJN+aw3qn/4OWaYfCyKYW6W67aUps3h56mzWXWXZQuO11ntzVuqzOHnmPObMX8Dmaw5l7BszmDl3AY+Mm8oWaw3lAxumJH3SjLm8PHkWqyznPmtLqsX90D4ElI8AGVP2/x8AxwDfA54EvgPcLGmziHilVQFZezlZa4GImArc0+44rO9ZbYVBDOjfj+N2fcdi63716U0Z9cwbnH/vuC4e7eqUvq6UuC07sD8z5y5g6qx53PHMRIYM7E9EMHPuArZceyiTZ7rvYjO0MFm7PyKmVdnfYFKydnJEnJWX3Q2MBQ4Hjm5VQNZeS2UzqKQdJN0maZqkKZJGSdoyr3u3pFskzZA0SdKfJK1W9tjnJJ1WZZt/lnRH/v9izaCSVpJ0cd7ny5J+1EDcn5T0oKTpObZ7JX2wbH0/ST+Q9Iyk2ZKeknRAxTYk6ceSXpM0VdL5kvbJ8a6Xy6yX7+8j6Y+53DhJ++X135c0XtLrkk6R1K9iH5tJul7Sm/n2Z0mrl60vHZ8d87ppksZI+npZmZHAZ4APljUFHF/vMetrnnp9Oj+96ZlFbtc9/hoAP79tDH974vWqj1tzxcGMGDqY5yZ6uoa+bKVllwFSf7VyM+bMZ+bcBQwZ2J9VlhvISxXTflhjmt0MWoPtgaHA5aUFETEduBb4WDN2YL3TUlezJmlH4CbgNuAAYDrwfmBNSeOAUcB/gc8DywM/A26StHVEzCG9SfYmVUGXtrk8sDvw/W52/UdgR+DbwCvA/wFvB2qad0HS24ErgF/lfQ8GtgLKOyGdmZ/TiaSm2F2A8yW9ERHX5TLfAo4CTgLuAPYATu1it6cAfyIlTV8CLshJ7br5/lbAT4CHgUtznBsCdwIPAPuRzrEfA9dK2jZikd4y5wEXAOcC+wJnS3ogIu7Lj1kHWAkoJXFdVRktNabNns+Tr01fZNnwPA3D6NemM3veAv5njRXYfv2V+fdLU5k8cy4jhg7mk5utxhvT53D7sxPbEba1wHvWWZE3ps9h+uz5RAQrDVmGdYcN4eUps94aRLLB8CFMnz2POfODFQYPYIPhQ3hl6uxFpvOwJdC6AQbPShpG6krzy4j4XV6+CTAfeLqi/H9J30vWRy11yRpwMvAf4KNlicPfAST9LN//aG7KRNLTpCbNzwCXkJKS70t6X0SUmjo/AQwE/lxth5I2BT4F7BMRl+VltwEvAFNrjHtL4M2I+F7Zsr+V7WND4GvAQRFxQV58s6QRwHHAdZL6kxLKcyLi2FzmH5LWB9auss9bI+KovP17gc8CnwQ2iYj5wN8l7QHsmY8LeV+vAB/LyS2SHiH1rdgNuL5s+5dExE9ymVGk4/hp4L6IeFbSRKBf2XFejKRDgUMBlhs2oqtiS5WJM+YydPAAvrDVmgwZ2J9ps+fx6Pg3+fN/XmbWPI8E7SumzJzLmisOZnCpiXPOfJ5+dRrjJi2sNVumv9h49eUZ2L8fs+YtYOwbMzwZbhM1UFs2XNIDZffPjYhzy+6/TOqPdh/QH9gHOEfSkIg4HVgZmJY/f8tNAoZIGlj63LW+ZalK1iQtB7wX+GZFDU/JtsA/SokaQETcqzRi8wOk5OJhSU+RfsWUkoi9gX9GxKtd7Hqb/Pfqsu1Ok3RTjqcWjwIrSrqAVNt1Z67+LtkZWABcJan8db0F2DcnamsDqwPXVGz7GqpXod9SFu9USa+Tnmf5B8UzpBqwkg+TassWlMXxHKlPxdYsmqz9o2z7c3NivFaVOLqUP+jOBRi2waZLZaesO8ZM4o4xk966/+LkWZxyy5huHmF9wbOvz+DZ17u/QsXoV6cz+tXp3ZaxBjV2BYMJEbF1Vysj4kbgxrJFNyj1Uzta0q8aiNL6iKWtz9rKpIrrl7tYPwKolnC9yqLNjZcBn8v9v4YCu7KwZqma1Um1YpUdRV6rKWogIkaTmiw3INWoTch94N6Wiwwn/RKbAswtu40kJeUjchwAlR2bqnd0gskV9+d0sWxw2f3hwJEVMczNcVfW3vW0LTOzXkmkK4nUc2vQFaTvn/VINWjL5x/f5VYGZrhWre9aqmrWSCf6AlLiUs3LwKpVlq8GPFh2/zJSVfUHgPVJSe9futnvK8AKkgZXJGzV9tWliLgeuF7SiqQ+cmeQ+qntA0wk9X97P+k5VnqNha/32yrWVd5fEhOBq4DfV1k3ocoyM7MOVNglpKLs75OkH+UbAqPLymyS11kftVQlaxExPfe92l/SWVWaQu8FviZphYh4E0DSNqRfNHeUbedxSY+Rmj/XB26OiDe62fX9+e8epESvNChhF2rvs1b+PKYAF+eRoNvlxbeS3sQrRsRN1R4n6UVS4rgHi1a1f7LeGLpxC7Ap8GAXTc31cE2bmfVaBV1t6rOkH7rPkyoUpgKfIw3uQtIQUn/fc7vagHW+pSpZy34A3EzqC3AuaTTodqTRi78kddK/UdIpLBwN+ihwZcV2LgO+CawIHNLdDnNydw3w29xs+jJpRGf3HU7KSPpKjvPvwHjgHaQ37IV5H6MlnQNcKunU/HwGkxKnjSLiyxExX2nakdNy/7M7SYna5nk3zeh9fjypc+z1ks4nfcisSUpMR0bEqDq29SSwh6RPkUaCjo+I8U2I0cxsiTW7Zk3SlaTPz0dIP773zrcjImIBMCsPhDtG0iQWTorbj9TKYn3U0tZnjYj4FylxGAJcREq6PgiMi4jXgZ2AWaSRn2cDtwO7VOkLcCmpf9YC4K817PpAUof6M4A/kGqguuvnVukRUnPlL/N2jiZNfXFkWZnDSFNe7E/q1zaS1Fz6r7Iyp5NGxH6dlICuDPw0r6u7lq9SRDwFvI+UiJ4L3ACcAMwmDUaox29Iz/V8Uu3koUsan5lZLzaaNC3SlaTZBd4F7B8R5YnYz0hTL/0QuI4079ou3Qxwsz5AS95SZZ1O0u9Jb/Z12x3Lkhi2waax+48vbncY1gvst+Ua7Q7BeonD99qFpx77d9MbLAeP2CjWO6C+yqzRp+z6YHejQc26sjQ2gy7VlK6qsDdwF6lW8GPAQSxaQ2dmZt0Q0K9fMZ3WzJys9RJ5KHZX7/yoMglio6aTRrEeDixH6rR6JPCLJm3fzGypUNAAAzMna73Is6TLOFXzPGlE6hKLiOdI/fLMzGwJFDR1h5mTtV7kE8CgLtbNLjIQMzPrwZJNdGtWFydrvUREPNruGMzMrDbpCgbO1qwYTtbMzMzqVtgVDMycrJmZmTXCuZoVxcmamZlZA1yzZkVxsmZmZlYvDzCwAjlZMzMzq5MHGFiRnKyZmZk1wLmaFcXJmpmZWQNcs2ZFcbJmZmbWAOdqVhQna2ZmZvWSa9asOE7WzMzM6pQGGLQ7CltaOFkzMzOrm69gYMVxsmZmZtYA52pWFCdrZmZmDXDNmhXFyZqZmVm9fAUDK5CTNTMzszr5CgZWJCdrZmZmDXCyZkVxsmZmZtYA52pWFCdrZmZmDXDNmhXFyZqZmVm9PMDACtSSZE3S60DUWj4iVm1FHGZmZq0gT4prBWpVzdrZ1JGsmZmZdRrnalaUliRrEXF8K7ZrZmbWW/RztmYFKazPmqSVgc2AtYEbImKSpMHAnIhYUFQcZmZmzeBczYrS8mRN0gDgp8BhwLKk5tFtgEnAlcADwHGtjsPMzKxZJI8GteL0K2AfJwGHAIcDG5Amfi65GvhEATGYmZk1VT/VdzNrVBHNoPsDP4iIP0rqX7HuWVICZ2Zm1lFcs2ZFKSJZW4mUlFUzEKhM4MzMzHo952pWlCKaQR8D9uhi3ceAhwqIwczMrGlEnmutjn9mjSqiZu0nwJWSlgX+TBpg8G5JewJfAT5ZQAxmZmZN5X5oVpSWJ2sRcbWkzwOnAl/Ki38PvAR8MSJubHUMZmZmTSVfwcCKU8g8axFxOXC5pI2BYcBEYHRE+CoHZmbWkZyrWVEKvZB7RIwucn9mZmatIHwFAytOEQMMkLS5pIslPSNpev57saQtiti/mZlZs6WJcWu/mTWqiCsYfAq4nDR9xxXAa8CqpBGiD0jaKyL+2uo4zMzMmsl91qwoRTSDnkK6UsFe5X3UJP2QNDr0FOCvBcRhZmbWFK4tsyIV0Qy6NvD7ysEE+f55eb2ZmVlH6SfVdTNrVBHJ2gPApl2s2wxPimtmZrYYSWtKmiYpJC1ftnxsXlZ+e6WdsVprtaQZVNKQsrvfAS6VtAypubPUZ21P4MvAPq2IwczMrJUKqCs7DZgGLFdl3cXAmWX357Q+HGuXVvVZm0a6UkGJgJOBn1YsA7gXXx/UzMw6TCsHGEjaAdiV9L15WpUiL0fEPS0LwHqVViVrX2LRZM3MzKzPSPOstWjbUn9SrdmJwOTW7MU6SUuStYgY2YrtmpmZ9QqtvdzUV4FBwNnAF7ooc7CkI4CZwE3AdyPi+VYFZO1V6BUMzMzM+opW5GqShgE/BvaLiLldJIRXA/cA44B3AscBt0vaPCKmND8qa7dCkjVJewOHABsBgyvXR8SqRcRhZmbWLA3UrA2X9EDZ/XMj4tyKMicB90TE37raSER8s+zu7ZLuAv4NHAScUW9Q1vsVcQWDzwPnAyOBD+X/9wM+SWqLv7DVMZiZmTVTg33WJkTE1l1uU9qU1Od7B0kr5cWl2RVWlDQ/ImZWPi4iHpM0GnhP3RFZRyhinrXvkap0D8v3fxMRXwLWByYAMwqIwczMrKmU+63VeqvBO4BlgLuBSfl2dl43jkWn6qgUeGBfn1VEM+g7gDsjYr6k+cBQgIh4U9IpwOnAzwuIw8zMrGla0GXtDmCnimW7AkcCuwFjqsYhbQZsAlQ2qVofUUSyNpU0qgXgJVJnyFH5voBhBcRgZmbWNBJNv4RURExg4fdj3o/Wy/+9PSKmSdod2A+4DhhPStKOBl4gdTeyPqiIZO1+YAvgRuAa4FhJ80izLR9LGtFiZmbWUdp0uc8XSVcBOgNYCXgD+DtwVERMbUtE1nJFJGsnA+vm/x+b//9bUn+5+4GvFBCDmZlZU7XyCgYled7SkWX3HwF2bvmOrVdpebKWL4dxT/7/ZGAPSYOAQf4VYGZmnapNNWu2FGrLpLgRMRuY3Y59m5mZLSmhpvdZM+tKS5I1SafWUTwi4shWxGFmZtYScs2aFadVNWufq6NskIYlmy2R9VZelnP3/p92h2G9wMrbHN7uEKyXmD1mfMu2XUSfNTNo3YXc12/Fds3MzHqLImaVNwNfyN3MzKxuwjVrVhwna2ZmZg1o4NqgZg1xsmZmZtYAJ2tWFCdrZmZmdZLcDGrFcbJmZmbWANesWVEKS9aUfoKsBawN/Cciphe1bzMzs2ZzxZoVpZCRx5K+DrwEPA/cDmycl/9F0reKiMHMzKxZBPST6rqZNarlyZqk7wG/BM4DPkQ6x0tGAXu3OgYzM7Nm61fnzaxRRTSDHgYcGxGnSupfsW40sFEBMZiZmTWVK8usKEUka6sDD3axbgEwuIAYzMzMmkZu2rQCFVEz+wzwwS7W7QA8UUAMZmZmTSXVdzNrVBE1a2cAv5E0B7giL1tV0sHAd4BDCojBzMysqTx1hxWl5claRPxe0srAscAJefHfgBnA8RFxcatjMDMza6bSaFCzIhQyz1pEnCbpHGB7YBgwEbg7IqYUsX8zM7Nmc65mRSlsUtyIeBO4saj9mZmZtYzcDGrFaXmylifE7VZE/KbVcZiZmTWTcLZmxSiiZu2sbtZF/utkzczMOkbqs9buKGxp0fKpOyKiX+UNWAXYF/gP8K5Wx2BmZtZs/VTfzaxRhfVZKxcRk4HLJK0I/A7YsR1xmJmZNUoeYWAFaUuyVuY5YOs2x2BmZlYXN4NakdqWrEkaAXyXlLCZmZl1Dl+VwApUxGjQ11k4kKBkILACMAv4dKtjMDMzazZPimtFaddo0FnAOODvEfFGATGYmZk1jZtBrUgtTdYkLQPcDDwXEeNbuS8zM7MiuWLNitLqqTvmA7cCm7R4P2ZmZmZ9Uktr1iJigaSngdVbuR8zM7NiiX6+goEVpOWT4gI/Ao6VtHkB+zIzM2s5kZpB67mZNaolNWuSdgAeiohpwNHAMODfkl4CXqVidGhEbNuKOMzMzFrCVyWwArWqGfQ2YDvgPuCxfDMzM+szPHWHFaVVydpbZ3BEHNSifZiZmbVFqRnUrAjtvtyUmZlZR3LNmhWllcnabpJqmrIjIi5sYRxmZmZN51zNitLKZO3YGssF4GTNzMw6hihmOgUzaG2ythPwQAu3b2Zm1h4CuWrNCtLKZG1mRExv4fbNzMzaxqmaFcUDDMzMzOqULuTudM2K4WTNzMysAU7VrCgt6R8ZEf0i4r5WbNvMzKw3aPXlpiStKWmapJC0fNlySTpK0ouSZkr6l6R3N/GpWS/jwSxmZmZ1E1J9twacBkyrsvwHwDHAKcAncpmbJa3e8NOxXs3JmpmZWZ1KU3fUc6tr++ka27sCP69YPpiUrJ0cEWdFxM3A50jTYB3e6POx3s3JmpmZWQNaVbMmqT9wJnAiMKFi9fbAUODy0oI888K1wMeW+ElZr+RkzczMrAGq81aHrwKDgLOrrNsEmA88XbH8v3md9UEeDWpmZlavFk2KK2kY8GNgv4iYW2UfKwPTImJ+xfJJwBBJAyNiTtMDs7ZysmZmZlanBi83NVxS+ZV9zo2IcyvKnATcExF/azw662ucrJmZmTWggZq1CRGxdTfb2xT4ErCDpJXy4iH574qS5pNq0JaX1L+idm1lYIZr1fomJ2tmZmYNaMGkuO8AlgHurrJuHPAH4GKgP7AhMLps/SbAk80PyXoDJ2tmZmYNaEGXtTuAnSqW7QocCewGjAGeB6aSpuv4SYpDQ0jzrVU2qVof4WTNzMysTqnPWnOztYiYAIxaZD/Sevm/t0fEtLzsZ8AxkiaRatO+Q+pCd2ZTA7Jew8mamZlZA9p4HfefkZKzHwLDgAeAXSLi1bZFZC3ledbMzMzqprr/NSIiRkaESrVqeVlExEkRsVZELBsR/xsRDzftqVmv45o1MzOzBrSxZs2WMk7WzMzM6tSKPmtmXXGyZmZmVi+5Zs2K42TNrIP0Ewzot3B+pwDmL4D5sbDMgH6pXKnMgoC5CwoO1Fpuv0+8l/NO/OJiy79x0qX8/oo73rq/6YZrcOI3Psn7t3w7/fqJ0c+9whE/vYyH//tikeH2SU7WrChO1sw6iEjJ14JYeH9AP1DAvAUpSeunlMCV8rcB/WBQf5hdeSVB6xM+esivmDV77lv3nxs34a3/b7HRmtx8/re5btQjfPEH5wOw1abrsuygZQqPsy9qdNCAWb2crJl1kPnBwiwsU0B/wTxSEjenIimbOx8GDUhJ3IKKx1rne/Dx55k+s/oVhs780T787V+P8aWjL3xr2U13/beo0Po0kd5TZkXw1B1mHS56SMAil/H3ytJlkw1WZ9st1ue3l/6z3aH0WUVM3WEGrlkz62ilZtD53SRsIvWtcaVa3/T4tcczbMXlGDNuAr++6Fb+cOWdAGyz2XoArDR0We697Ae8a4MRvPDyRE49/x9c8Ndql560ernPmhXFyZpZBxrUf+EXxfwFqb9aVwb0W7Sfm/UNr0yYyvFnX8sDjz1P//79+NxHt+Kso/dlyOCBnPmn21ht+FAAfn/i/px+wc088Pjz7PnhLTnnuC/wyoQp3HjHE21+Bp3PtWVWlI5K1iSNBDaLiK0L2NfxwOERMTzf3wj4PHBGREwuK3cg8EdghfIZpm3JSFoV+DowMiLGtjmcXqfUL600OnRAv+oJW2lkaGU/Nut8N9/9X26+e2H/s3/c+QSDBw7gyC/vylkXj3orjRj517v45QU3A/CvB55mk/VX43sHfcTJ2hJynzUrkvus1W4j4DhgpTbHsbRYlXS812tzHL1SaZzB/DwtR/l0HiX9lW5zF7gJdGlx1c3/ZthKy7HuGqsw+c0ZAPzz/qcXKTPq/qfYZIMR7QivjynmclNm0GE1a2a2uNIAA2nh/0s1bvMWuPlzaRI5LY+AJ8eka3pX9quSxILwxHtLzJPiWoE6smZN0i6SHpE0XdIdkjYtW9dP0g8kPSNptqSnJB1Q8fjdJd0k6TVJUyXdI+kj3exvR+DafPc5SSFpbEWx9fM2p0t6UtKnyx7/dUnTJC1fud28rf+p4TmvJOn3ksZLmiXpBUnnVZTZTNL1kt7Mtz9LWr2izBaS7srbeFzSbpIeyE3MpTIj87LdJT0haUbe7iqSNpR0W36eD0jaomL7tRz/UZKukPT5XG6qpBskrZXXrwc8movflo+RU44ulJpiyhO1ZfKgg+4GHljfs+eHt+T1SW/ywssTuec/Y5g4ZTo7brPRImV22nZjHn3qpTZF2LeozptZozqxZm0d4DTgJGAm8HPgMkmbR0QAZwIHACcCDwG7AOdLeiMirsvbWJ+UfP0cWAB8DLhB0g4RcWeVfT4E/F8u/2ngZWB2RZmLgXNzbN8ALpW0QUSMy+t+AXwWGFn2mIOAhyLiPzU8718C2wPfBl4B1gZ2KK2UtCFwJ/AAsB/ptf0xcK2kbSMiJA0BbsyP3xcYDJwOrAw8VrG/dUjH8GhgCOm4nktqljwPOBU4OT/PTfOxh9qOP8B7gTWA7wLLAr/K29+NdHy/APwJOCxvx0hJ2IJY2KzZLzd1libBVS5TurJB5ReEc7e+45Kff5kHHhvLo0+Pp3+/fnz2I+/hcx/diu+c8mcigrnz5nPyuTdw0rc+xeQ3Z/Lg4y/wqQ+/mw+85+185Mu/anf4HS/1WXMKZsXoxGRtFeD9EfE0pJoc4CpgY0nzgK8BB0XEBbn8zZJGkPo/XQcQEWeVNpYffxuwKXAwKeFZRERMlTQ63324iw7vp0fE+XmbDwKvAh8HzomIyZKuJCVnI3OZ5YHPAD+o8XlvC5wdEZeVLbuo7P/HkZKwj0XEnLyPR4AnSQnQ9Xn/w4CtI+KlXOZZ4N4q+1sF2C4ins3ltgC+BxwQERfmZcrb3QT4b04Yezz+2VBg94iYlLe1OnC6pGUjYmaOHeCJiLinq4Mi6VDgUIC111mnq2J9RgD9Ky43Na/sclP9ctOMSBPhlpu/wJed6kueGvsq+++xHWuttjIS/HfMK3zp6Au45Pr73ypz1sWj6NevH1/bZweO/upuPDX2NT7/vT9w58PPtjHyvsOpmhWlE5O1saVELSsNaVoLeDuppuwqSeXP7RZgX0n9I2J+bm47CfgwMIKF77lqtWq1+kfpPxHxhqTXckwlfwBuybVtY4C9SMf/4hq3/2/ge5LmAzdHxFMV6z8MXAAsKHvuzwFjga1JSdU2wIOlRC3Hep+kV6vsb2wpUcueyX9vrbJsTeC/wM7UcPzzsvtLiVpWeh3XLNtujyLiXFKNHFtttXWfrzjqbooOyE2f84qJxdrruLOu5bizru2x3K8vupVfX3Rrj+WsAc7WrCCd2GdtcsX90nVWBgPDgf7AFGBu2W0kKTEakWvSriE1KR4L7ERKYm7I22hmXOXbGwWMAQ7M9w8Cro6IiTVu/3Dgr6SYR0t6WtI+ZeuHA0ey6POeC2xAajIFWB14vcq2qy2bXHF/TpXl5ce+FEO3x7+G7S/Ja2BmZtbndGLNWncmki6R+H5SDU+l14ANgS1JzYV/L62QtGwrA8t9xs4HDpV0EfABUl+5Wh8/GTgCOCI3SX4f+JOkRyLiCdJzvwr4fZWHl67s/AqwcZX1b6v5iXSvluNvZtYneDoOK0pfS9ZuJdXsrBgRN1UrUJaUzS5bti4pwXik2mOyZtT8jCR1vP8D8BJQNcaeRMQjkr5H6oS/CakJ8RZSv7sHyzr7V7of+LykNcv6rG0LrNZIHFX0ePzr4Jo2M+vVPL7AitKnkrWIGC3pHNIIxVNJIyMHk5KYjSLiy6QO9+OAX0g6BlgBOIGUPHWnNMDgK5IuBWZExKPdPaBKfOMl/R3YHTi5rP9WjyTdQao5e4zUr/wQYDpwXy5yfP7/9bkGbwKp/9cupKsAjCJdaeFo4DpJJ5BGYZ5AagZd4q7nNR7/Wr1AGu17gKQpwNyIeGBJYzQzaxbnalaUTuyz1pPDSFNW7A/8jVSbtTvwL4CImE2afmMecEUuezLwz+42GhHPk6bv+DRpIELPPXur+2v++8c6H3c3qb/bFcDlpP5hH8tTg5AHHLwPmEHqcH8DKRGbTe6wHxEzgF1JSdBlpATv+6T+Y1MbejaL6/b41yoiZpES0q1Ir8393T/CzKxgnmjNCqKuW8ysFSRdDoyIiP9tdywAktYHngIOjYh6E8heZautto4773Xlm8HK2xze7hCsl5g9+nIWzHit6anSuzbfMi68ptvf+IvZZoMVHyzi2tbW9/SpZtDeTNLmpCk0Pg3s00PxVsbxQ2A88Dxp4tsfkppBr2xXTGZmHceXm7ICOVkrzrWkpsvfRMQV5Svy5LL9u3ns/G4GDdQrSBPUrkFqIr0d+L+IaFYzqJnZUsG5mhXFyVpBImK9blYfQPd92N668kET4vgZ8LNmbMvMbKnmbM0K4mStd7iWNDFvV54rKhAzM6uFPM+aFcbJWi8QEW8Ab7Q7DjMzq537rFlRnKyZmZnVybNxWJGcrJmZmTXC2ZoVxMmamZlZA9xnzYriZM3MzKwB7rNmRXGyZmZm1gDnalYUJ2tmZmb18ggDK5CTNTMzswa4z5oVxcmamZlZnYT7rFlxnKyZmZk1wLmaFcXJmpmZWSOcrVlBnKyZmZk1wH3WrChO1szMzBrgPmtWFCdrZmZmDXCuZkVxsmZmZtYIZ2tWECdrZmZmdUpz4jpbs2L0a3cAZmZmHUepz1o9tx43KX1W0l2S3pA0S9JoSUdLGlhWZqykqLi90sqnau3nmjUzM7MGtKBebRhwK3AaMBnYFjgeWB04vKzcxcCZZffnND8U602crJmZmTWiydlaRPyuYtFtkoYCh0n6RkREXv5yRNzT3L1bb+ZkzczMrG4qqs/aG8DAHktZn+Y+a2ZmZg1odp+1hdtVf0lDJH0AOAL4bVmtGsDBkuZImiLpCknrNvmpWS/jmjUzM7M6iYZaQYdLeqDs/rkRcW6VctOBQfn/FwLfK1t3NXAPMA54J3AccLukzSNiSv0hWSdwsmZmZtaI+rO1CRGxdQ3ltgeGkAYYHAucBXwdICK+WVbudkl3Af8GDgLOqDsi6whO1szMzBrQqj5rEfFQ/u8dkiYAF0j6RUQ8W6XsY5JGA+9pSTDWK7jPmpmZWQNa1WetQilxW7+bMpFv1kc5WTMzM2uA6rw16P3573NVY5A2AzYBHmx8F9bbuRnUzMysXktWW1Z9k9LfgZuBx4H5pETtu8BlEfGspN2B/YDrgPGkJO1o4AVgZHOjsd7EyZqZmVlDmt5n7X7gQGA9YB4wBvghcE5e/yKwKmkgwUqkOdj+DhwVEVObHYz1Hk7WzMzM6iSaX7MWEccAx3Sz/hFg5+bu1TqBkzUzM7MGFHL9AjOcrJmZmTWk2TVrZl1xsmZmZtaAgq4NauapO8zMzMx6M9esmZmZNcIVa1YQJ2tmZmYNcK5mRXGyZmZmVqclvISUWV2crJmZmTXAAwysKE7WzMzMGuFczQriZM3MzKwBztWsKE7WzMzMGuA+a1YUJ2tmZmZ1k/usWWGcrJmZmdWpFRdyN+uKr2BgZmZm1ou5Zs3MzKwBrlmzojhZMzMza4D7rFlRnKyZmZnVy1cwsAI5WTMzM6uT8DxrVhwna2ZmZo1wtmYFcbJmZmbWAPdZs6I4WTMzM2uA+6xZUZysmZmZNcC5mhXFyZqZmVkjnK1ZQZysmZmZNcB91qwoTtbMzMzq5GuDWpEUEe2OwawpJL0OPN/uONpsODCh3UFYr+HzAdaNiLc1e6OS/k46vvWYEBG7NjsW6/ucrJn1IZIeiIit2x2H9Q4+H8z6hn7tDsDMzMzMuuZkzczMzKwXc7Jm1rec2+4ArFfx+WDWB7jPmpmZmVkv5po1MzMzs17MyZqZmZlZL+ZkzczMzKwXc7Jm1qEkHStpjS7WjZB0bNExmZlZ83mAgVmHkjQf2C4i7quybivgvojoX3xkZmbWTK5ZM+tcArr6tbUWMKnAWKzNJM2XtG0X67bKyb2ZdSBfyN2sg0g6ADgg3w3gt5KmVhQbDGwO/KPI2Kzturus+DLAvKICMbPmcrJm1llmAG/k/wuYAkysKDMHuAH4TYFxWRtIWgdYr2zRlpIGVxQbTErwnysqLjNrLvdZM+tQkv4I/DgixrQ7FmsPSccBx7GwObyr2rWZwJcj4pJCAjOzpnKyZmbWoSS9DViVlKQ9Anwh/y03B3ghImYXHJ6ZNYmTNbMOJmlr4NOkAQWVzV9ExF6FB2VtIWld4OWImNPuWMysudxnzaxDSfoacDYwAXiaVINiS6mIeB5A0iBgTaon708UHZeZLTnXrJl1KEnPArcBX40Ij/RbyuUJks8FPlZtNRCed8+sM7lmzaxzrQpc4kTNst8D7wG+AzyBa1rN+gwna2ad6wbgvcAt7Q7EeoX3A4dExOXtDsTMmsvJmlnnOhs4V9IywE3A5MoC7qO0VHmNNEWHmfUx7rNm1qEkLSi7W/lGdh+lpYykfYHDgN0iovKqFmbWwVyzZta5dmp3ANarfBpYB3he0v0sXtMaEbF34VGZ2RJzzZqZWR8g6baeykSEE3yzDuRkzazDSfoYsDWwNvCTiHhB0g7AMxExvr3RmZnZknKyZtahJK0GXANsBYwF1ge2iYiH8nVDZ0XE19oYorWJJAEjgNc8tYtZ5+vX7gDMrGFnAssDm+Rb+UW8bwZ2bkdQ1j6SdpN0LzALeBHYIi8/T9J+bQ3OzBrmZM2sc+0KHB0Rz7D4aNBxpEsO2VJC0v6kmtYngUNZNHl/Cji4HXGZ2ZJzsmbW2bpq4hqO59xa2vwIOC0iDgAuqlj3OPCu4kMys2ZwsmbWuW4HjpBUPpdaqYbtS8CtxYdkbbQuaXLkamYBQwuMxcyayPOsmXWuI4E7gMeAq0iJ2iGSNgU2B97XxtiseC8CW1I9Sd8aeKbYcMysWVyzZtahIuIx0kjQB4ADgfmkiVHHAe+NiKfaF521wR+A4/JAgmXzMknaGfg+cF7bIjOzJeKpO8zM+oA8XcdZwFdJifsAYC7QH/hdRBzWxvDMbAk4WTMz60MkvR34MDAMmAjc6lpWs87mZM2sg0naC9iTNE3H4Mr1EbFt4UGZmVlTeYCBWYeS9DNSX6T7SZ3H57Q3IusNJG1M18n734qPyMyWlGvWzDqUpNeA0yPi5HbHYu0naXPgEuCdLDohbklERP8qy82sl3PNmlnnmgs82O4grNc4n3ROfBzXtJr1Ka5ZM+tQkr5Pmj9r7/AbeaknaRrwmYi4sd2xmFlzuWbNrENFxKmSfg48KemfwOTFi8SRxUdmbXIfsE67gzCz5nPNmlmHkvQF4AJgAfA6izd7RURsUHhg1haSNiT1WTsDuI3Fk3ciYkaxUZlZMzhZM+tQkl4E/gV8NSLebHc81l6SViJdpeDTXZXxAAOzzuRmULPONRQ434maZRcB2wE/xwMMzPoU16yZdShJ5wPjI+Lodsdi7SdpOnBIRFzc7ljMrLlcs2bWuW4EfiZpdeBWqvdR8iSoS4+xgPukmfVBrlkz61CSFvRQxJOgLkUk7QacAHwuIsa2ORwzayIna2YdStK6PZWJiOeLiMXaT9L9pKk7VibVsk2uLONrxZp1JjeDmnUoJ2JW4bF8M7M+xjVrZh1KUncToC4ApkbE1KLiMTOz1nCyZtahcp+1nt7ALwC/jojTCwjJzMxawM2gZp3r88AppKava0hXMXgbsAewGfBT0rVDT5WEE7a+LU/l0pUFwFTg38BfImJaIUGZWVO4Zs2sQ0n6PTAzIr5RZd2ZwIoRsb+kM4CPRcTGRcdoxckDDNYGVgVeZWHyvhrwGjAFWD+v2zkinmpTqGZWp37tDsDMGvY54Oou1l1DqmEDuAHoceSodbxjSSNA3xsRIyJii4gYAbyPlKh9D9gYeBM4rW1RmlndnKyZda5ZwPu7WPf+vB5AwPRCIrJ2OhU4LiLuL18YEfcBxwOnRMRzwM+AHYoPz8wa5T5rZp3rXOAYScOAa1m0z9pXSX3WALYH/tOWCK1IGwIzu1g3A1gv//95YFARAZlZc7jPmlkHk/RtUvPW6qSRoQJeAU4rDSiQtCkw3bPa922S7iIlYbtHxCtly0cA1wMzIuIDkvYHjo2IDdsUqpnVycmaWYeT1I80c/1qpETtxYjo6VJU1sdI2oJ0vdiVgQdZWNO6FTAR+GhEPCrpB6RLkZ3StmDNrC5O1sz6AEkCRgCvRcS8dsdj7SFpWeBLpClbVicl7/cDf4yIrppIzayXc7Jm1sHyxbuPA94N9Ae2jYiHJJ0L/CsiLmpnfGZmtuQ8GtSsQ+W+R9cATwKHsuj7+Wng4HbEZe0l6WOSjpF0bumSZJJ2kLRGu2Mzs8a4Zs2sQ0kaTZqN/oeS+gNzga1zzdpupKav1dobpRVF0mqk5H0rYCxpAtxt8vnwR2BWRHytjSGaWYNcs2bWudYFbupi3SxgaIGxWPudCSwPbJJvKlt3M7BzO4IysyXnZM2sc70IbNnFuq2BZwqMxdpvV+DoiHiGNI1LuXHAmsWHZGbN4GTNrHP9AThO0n7AsnmZJO0MfB84r22RWbt0NRJ4OF1PmGtmvZz7rJl1qDxdx1mkqxXMJ12RZC5pVOjvIuKwNoZnBZN0PTCQVMMG6VzYKiIezuumR8RebQvQzBrmZM2sw0l6O6k/0nDS5Ke3RsRT7Y3KiiZpM+AO4GXgKuBI4HfApsDmwPt8Xph1JidrZmZ9RE7cj2fR5P0W4PiIeLqNoZnZEnCyZtahJP0vsEpEXJ3vDyONCHwX6Qv6BxExt40hmplZE3iAgVnnOhXYrOz+r0k1KvcABwIntCEm60UkbSLpU54Q16yzOVkz61wbky7YjaQhwJ7ANyPiq6TRoHu3MTYrmKTfSTqn7P7ewGPAX4AnJW3ftuDMbIk4WTPrXANJk98CvJ80GvT6fP8p0oXdbemxK/Cvsvs/Bi4G1gBuzPfNrAM5WTPrXE+ycJqGLwB3R8Sb+f4apM7ltvRYlTRRMpLeAWwInBoRrwDn0vUEymbWyw1odwBm1rATgT9LOhhYEdijbN2uwMNticraZSJQuhbsh4FXIuKxfF+k+ffMrAM5WTPrUBFxjaR3kmpMHq2YQ+tu4JH2RGZtcgNwYr6g+/eBy8vWbUa6uLuZdSBP3WG2FJDUj3St0E9ExOPtjseaT9KKwOnANsC/gcMiYmpedztwV0Qc2b4IzaxRTtbMlgKS+pMuP7R1RDzU7nis/STtD1wbEZPaHYuZdc8DDMzMljI5ef8jsH67YzGznjlZMzNbOqndAZhZbZysmZmZmfViTtbMzMzMejEna2ZmZma9mJM1s6VDAM8Ds9sdiJmZ1ceT4potBSJiAR75Z2bWkZysmXUQSc+RaslqEhEbtDAc60UkbR4Rj9ZSNiLmSzoIeK7FYZlZEzhZM+ssV7JosrYPMAS4CXiNdDHvXYDpwKWFR2ft9B9JDwLnA5dExOTuCkfEBYVEZWZLzFcwMOtQko4CPgLsHhHTy5YvD1wH3BwRP2lXfFYsSTsCBwGfJl20/WpS4nZz+IPerKM5WTPrUJJeAg6NiOurrPs4cF5EjCg+MmsnScsBewMHAh8AxgEXACMj4tk2hmZmDfJoULPONRRYrYt1qwPLFxiL9RIRMT0izo+IHYCNgbHAUcBTkv4pac+2BmhmdXOyZta5rgVOk/RZSQMBJA2U9DnglLzelkKS1pN0PHAjsB3wN+BQ4FXgMkmntzE8M6uTm0HNOpSkFYGRwB6kQQdvAiuQrvl4DXBARExpW4BWKElDgM+S+q39L2mk5/mk5s+Xy8odBPwqIoa2JVAzq5tHg5p1qJyI7SnpXcA2pKbPV4D7I+KJtgZn7fAqqbXkL8CHI2JUF+XuB94oKigzW3KuWTMz6wMkfQ242LWpZn2PkzWzDpJr0Z6NiNn5/91yDZuZWedzsmbWQSQtAN4XEffl/3f1BhYQEdG/uOis3SStAXwcWAsYXLE6IuLI4qMysyXlPmtmnWUnoFRb9iHquPSU9W15So5LSBPivgbMqSgSgJM1sw7kmjUzsz5A0n+Bp4EDI2Jiu+Mxs+bxPGtmHUrSvyR9TdLb2h2L9QprA792ombW9zhZM+tcrwI/B16SdJOkL0laud1BWdvcRbpigZn1MW4GNetg+TqQnwT2AnYlDSy4GbgM+GtEvNnG8KzF8kS4JRsAfwJ+CdwETK4sHxEzionMzJrJyZpZHyFpBWBPUuL2YWB+RCzX3qislaqMCFb+W/WD3aODzTqTR4Oa9RER8aakZ0mXGZoKDG9zSNZ6X8Ijgs36PNesmXU4SdsCewOfA9YEHic1g14aEc+2MzYzM1tyHmBg1qEknSJpDHA3sDvwR2DziNgiIk5yorZ0kTRG0v90sW6zfK6YWQdyM6hZ5/occDmpBu3fbY7F2m89YFAX64aQrmpgZh3IyZpZh4qIDdodg7WXpKHASmWLVpe0TkWxwcA+wEtFxWVmzeVkzayDSRoAfAb4ALAKMBG4HfhLRMxrZ2xWiG8Dx5EGGQRwVRflBHy3qKDMrLk8wMCsQ0laFfgHsAUwljRJ7mqk5rD/AB+JiNfbFZ+1nqR3ABuRkrFrgP8DRlcUmwOMjogXCg7PzJrEyZpZh5J0EfBB4DMRcV/Z8m2AK4F/RsQX2xWfFUvSB4GHPBGyWd/jZM2sQ0maCBweERdXWfcF4MyIWKX4yMzMrJncZ82scw0CuqpFeRMYWGAs1gaSXqeOSXEjYtUWhmNmLeJkzaxz3QMcKenWiJheWpivF3pkXm9929n4CgZmfZ6bQc06lKR3A6OABaSBBq8CqwIfJXU43zEi/tOu+MzMrDmcrJl1MEnDSSMAtwFGAC8D9wK/jIgJ7YzNzMyaw8maWYfKlxZaMyL+VmXdbsC4iHik+MisXSRtBxxMms5jcOX6iNi28KDMbIn52qBmnet04L1drNsmr7elhKRdgH+RLiv1AeB1YBrwP8Aw4LH2RWdmS8LJmlnneg9wZxfr7ga2LDAWa78TgV8Bu+f7x0TEh0i1bHNJ/RvNrAM5WTPrXP2B5bpYtxyeumNp8y7gBtKAkyCfGxHxPHA88KO2RWZmS8TJmlnnuh84tIt1hwIPFBiLtd8soF+kjsgvA28vWzeV1DxqZh3I86yZda7jgZsl3QtcALxCGhG6P6mf0i7tC83a4D/AxsBNwC3ADyW9RLo26InAo22MzcyWgEeDmnUwSTsCJwPbkuZWW0CauuMHEXF7+yKzouURwOtHxNmS1gSuBd6dV48D9oyIB9sVn5k1zsmaWR8gaQiwMjApIma0Ox5rP0kCNgSWBZ6MiDltDsnMGuRkzcysj8mJ2gjgtYiY1+54zGzJeICBmVkfIWm33IdxFvAisEVefp6k/doanJk1zMmamVkfIGl/4BrgSdJoYJWtfop0ZQMz60BO1szM+oYfAadFxAHARRXrHifNw2ZmHcjJmplZ37AuadqOamYBQwuMxcyayMmamVnf8CJdX2Jsa+CZAmMxsyZysmZm1jf8ATguDyRYNi+TpJ2B7wPntS0yM1sinrrDzKwPyNN1nAV8FZhPukLNXNI1ZH8XEYe1MTwzWwJO1szM+hBJbwd2BoYDE4FbI+Kp9kZlZkvCyZqZWR8iaSPSRdsHV66LiL8VH5GZLSlfyN3MrA+Q9C7gUmBTFp1jrSRITaJm1mGcrJmZ9Q2/AwYBnwaeAHwtULM+ws2gZmZ9gKRpwD4RcV27YzGz5vLUHWZmfcOzVOmnZmadz8mamVnf8F3gKEkbtDsQM2suN4OamXUoSfeTBg6UrAusDIwFJleWj4htCwnMzJrKAwzMzDrX4yyarD3erkDMrHVcs2ZmZmbWi7nPmpmZmVkv5mTNzMzMrBdzsma2lJJ0vKQou42XdGW+tmSr9vnxvK/18v318v2P17GNvSQd2MSYls8xdLnNRuLMjxsp6YElDjJta5SkK5qxLTPrLB5gYLZ0mwLsmv+/AfBj4BZJm0bE9AL2/zKwHfBkHY/Zi3SR8pGtCMjMrLdxsma2dJsXEffk/98j6QXgdmA34M+VhSUtGxEzm7XziJgN3NNjQTOzpZibQc2s3IP573oAksZK+oWkYySNA6bm5f0k/UDSM5JmS3pK0gHlG1JyvKTXJL0p6UJgaEWZqs2Lkg6R9KikWZJelXSFpBUljQQ+A3ywrPn2+LLH7SHpgfy4VySdKmmZim1/Jsc7U9K/gE0aOVCS9pd0h6SJkiZJuk3S1l2U/ZSkJ3Ncd+SLrpev7/F4mtnSyzVrZlZuvfz3lbJlnyfN3/V1Fn5mnAkcAJwIPATsApwv6Y2ya1MeARwL/JRUW/dp4NSeApB0dN7ub4DvAUOA3YHlSc206wAr5XgAxuXH7QVcQrqg+VHA24GTST9K/y+XeQ9wGXAV8E1gM+DynmLqwnrAhaTLPA0E9gVuz03IY8rKrQv8EjgGmAmcANwo6R0RMSuXqeV4mtnSKiJ88823pfAGHA9MICVgA4CNgNtItWcjcpmxpH5lg8setyGwADigYnsXAvfn//cHxgO/rShzE2kS1/Xy/fXy/Y/n+ysBM4BfdhP3FcCoimUCngf+WLH8S6QEaVi+fznwBHmOybzsRzmGA7vZ5yJxVlnfLx/DJ4Fjy5aPzI/bvmzZusA84Ku1Hs98fxRwRbvPG9988634m5tBzZZuw4C5+TaaNMhg74h4uazMLbGwBghgZ1JycZWkAaUbcAvwbkn9gbWBEcDVFfv7Sw/xbAcsC/yxzuexEanG7fKKmG4lXdx8s1xuW+CaiCifDbynmKqS9E5JV0l6FZhPOoYb51jKvRYRd5XuRMTzpObm0qWfajmeZrYUczOo2dJtCvBhUu3PK8D4ikQG4NWK+8NJNWdTutjmCGD1/P/XKtZV3q80LP99udtSixue//6ti/Vr57+rNxDTYiStAPyDdGy+Q6rVmwX8npQc9rT910jHCWo7nuPqjdHM+g4na2ZLt3kR0dM8YJXJ20RSM977STVClV5j4WfLqhXrKu9XeiP/HUFqoq3VxPz3UODhKuufy39faSCmarYD1gJ2iYi3ph2RtGKVstW2vyoLr+NZy/E0s6WYkzUzq9etpJqgFSPipmoFJL1ISoz2AP5eturTPWz7blIfswPIgwKqmMPitVejgZdIfeHO62b79wOflPTDshrEnmKqZtn8d3ZpgaTtSX3bHqwou6qk7UtNoZLWAd7DwqbeHo+nmS3dnKyZWV0iYrSkc4BLJZ0KPEBKnjYFNoqIL0fE/Lzu55ImkEaDfgZ4Zw/bnizpx8BJkgaSmjUHkUaDnhARL5E68e8h6VOk5sHxETFe0neB/ydpKHADKanbAPgU8NmImAGcAtxL6tv2B1JftoMbOAz3ANOA8/LzXIs0YOOlKmUnABflUa6l0aCvkSf1reV4NhCfmfUhHmBgZo04jDSNxv6khGokKaH6V1mZM0jTdnwVuJI09cb3e9pwRJwMfI3Ul+5q0lQcKwFv5iK/IfUXO59UU3ZoftxlpJq8d5Mm9P0LaXqPh0iJG7nJdx9gS+CvpERu7zqedynGV4HPkfrAXQ18Kz/PZ6oUf55US3g8cGl+Hh+tGLRRy/E0s6WUFu9LbGZmZma9hWvWzMzMzHoxJ2tmZmZmvZiTNTMzM7NezMmamZmZWS/mZM1sKabkKEkvSpop6V+S3l3D40ZKiiq3TSrKbS3pH5Im5tvNkt5bUabadkJS+Rxm20j6o6RnJM2QNFrScZIq51trKUkH5tiWb+I2Q9LhzdpeqzR6rlRsY4/8fB+oWD5Q0mmSbs/bXmzkm6T+ko7MZd7It39I2qZK2XdIulLSq5KmSrpL0q51P2mzXsLJmtnS7QfAMaT5xz5BmjvsZkmrd/uo5EnSTP7lt7GllZLWBm4mzef4xXwbANwkad2y7VRuYzvS3GQ3lJXZG3h7jnM34GzSZZ7+VM+TbYLrc3wzCt5vb7Ak5wo5sT6dxS9fBjAE+DLpuN5VZT2kiYh/QJqu5YvAfqTrsd4haauy/awA3ESaY+9rwGeB8cC1krat3KhZJ/CkuGYtImlwxVxavUr+8vwBcHJEnJWX3U1KuA4Hju5hE9Mj4p5u1u8OrADsGRFT8vbvIiViuwG/BajcRq4pGQ5cUrb4ZxFRfvmpUZJmAb+TtG6+OHrLRcTrwOtF7Ks3acK5AvA90qTBz5ImI35Lngx5lYgo1TJ+qMrjZwIbRMSksrhuAZ7KMRyUF78fWBf4REQ8msvdmvf9GeC+Wp6zWW/imjXrWJK2k3SNpJclTZf0b0lfqFJuXUmXSJqQm9AekfT5svXLSjpV0vOSZkt6TtLJZesXa6aSdHyemb90v9Q8tq2kUZJmkr6ckPQzSY9KmiZpnKQ/VauNkHRILjcrN99cIWlFSbtJWiBp/Yry6+flezR4CLcHhgKXlxZExHTgWuBjDW6z3DKka15OL1s2LS9TN4/bNz/m2rK4ql0ntHQN0DXqDSy/Vt+W9IvcnDZB0v/ldQdIGiNpsqTzy5taqzWDSvphbp4tvW5/L399JQ2T9Lt8ns5SasL9Vjex7S7pJkmv5Sa8eyR9pKLMWpIuz2VmSnpW6coPpfWb5jgm5vfGfyUdVu9xKrNE54rSJba+D3yzqzLRw6SfETG/PFHLy+aQrrFafg4sk/9OKStXOg+7O+/Mei3XrFknWxe4EzgHmEX6Rf1HSQsi4hIASauSrjc5gzSL/IukX/Vr5/UizUC/HWkG+QeBNYH/bTCmS0gz7J8ATM7LViXN5D8eeBvwXeBWSZtFxIIcx9HAifmx3yM1C+1OmvX/xvzYA0iz4JccSLps0fV5G/3o+QdYRMT8/P9NgPnA0xVl/ktts/q/S9JU0uWg7gd+FBH/LFt/ZX5Ov5B0Ul52LDCJdIWBxeTXYy/g6nx5qO5sR7rw+bNljz+QdM3N9SNibA+P/y7p2O0LfBw4LZ8v2wBHAOuQmu2eAn7WRbz7A0cBR5KShmGkWqHl8vplgVGkc+AEUtPxhvnWlfVJSdDP8/P7GHCDpB0i4s5c5kJSs+ChpPNsA9LrWXIt6XXcj3T90o1JyVYp7qLPlV8Al0fEQ+klbg5Jg0jXWb2ibPEtpBq/nytdgmw66eoSq5Iv8WXWcSLCN986/kb6xTyAdGmiW8uWn0z6sB7RxeM+CgTwyW62HcDhFcuOByaU3T8wl/tmD3H2JyWDAeyQl61ESiZ/2c3jfgI8x8Krjoj8hVQRU/RwG1tW/kfA5Cr7+nIuO7CbeL5J6g/0QVKfoLtJl3TatqLcu0nX7yztfzzwP91sd4dc7hM9HMfVydfXrFi+P6nmbt0eHh/AbWX3+wEvkxLJoWXLLwfurfI6L5/vnwVc2c1+vkJKuN5dz/lVEdcAUsJ+ftnyaV0dI1ITcgCbd7PPIs+VD5FquVbL90cCD3RT/nByRVtPN9KPgdnAxhXL1yUlz6XnMgXYuZZt+uZbb7y5Zs06lqSVSbUVe5ASoP55VfnFtD8E/D0iXu5iMx8CJkbENU0K6/oqcX6M1DF7U8pqN4CNSNd+3I5US/LHbrZ7PqkGZ0fgNmAn0hdS+WPOBa7rIb7ZPayvSUT8qvy+pL+RvhyPIl1vE0kjSDVoD5K+1CFdA/N6SdtHxAtVNr0vKWG6sat9K13g/XJSwvLtirguJNU61eKWssctkPQcMCMippaVeYbUBNiVfwMHSzqB9No/GAtroyCdXw9HxL9rjAlJawEnka6NOoKFTXd3lhX7N3CypGGkHyflx3IiqQb5HEm/JiWlr1XsppBzRdIA4NfASZGup9o0knYnJZHfjYjRZcuXI513k0ifDTOALwBXStopIh6utj2z3szJmnWykcD7SM2XTwBTSbU95X24hpGa6LoyjFSj0iyLfCEpdZa/BriK1JT2GumX/j1AqS/UsPy3yzgiYoykUaRO1Lflv/dFxONlxV7J2+9Oeb+gScDykvpXJBgrk5KWOT1sqzy+GTlh+0TZ4u+R+g99NiLmwlsdvZ8mNUkfUb6N/MX+GVJNVdV952bSC0mJ7/ujog9TnSZX3J/TxbLupgc5nzSI4lBSE+8bks4BjsvHtK7zKzdPXpO3eSwpWZxOqkFatazo3qSE7nRgJUn/ISUtt+TE8yN5/fnAspLuBI4oS1SKOlcOAVYERkpaKS8bCPTP96eXzo165PfVZcA5EXFGxeqDgXcBa0XE5LzsZqVpZU4APlnv/szazQMMrCPlTt8fJ30pnhURt0bEAyx+Tr9Bqp3oSk/rIdUwDKxYtnIXZSs7Se9JGj24d0RcE2nk4ytVYqCGOH4PfEbSmsCnWbwm7ljSVAbd3Z4tK/8kqTaysv/UJnldvUpNTuXbebz8yzgWdgh/e5XH70zq03dJlXUlZ5CS8T0iopEYmyoiFkTE6RHxTlIft58DPyQlKVDb+VVuQ2BL4BsR8YeI+Gc+r5et2O9LEXEgKRncjnROXZNr2oiIJyPiM6Qm9g+TEs7rczIIxZ0rGwNrkX7ETMq3fUnN45Oorb/bIiRtRKrFvIWKhL8spufLErWSh6l+3pn1ek7WrFMNIp2/5ROnrsDiv5pvAT4qabUutnMLsIqkj3ezr3HAO8v204+UWNRiWWBuRJQnMZUjVu8mTUtwQA/b+guppudS0nO/tGL9uaTO8d3dymu+7iLVRn6utEDSkFymfI6zHuWO9LuTmjxLngc2y82WpXKDSAM8xlbZzL6kWqhRXezjh6T+TPtFxB31xFeEiHgxIn5Gqg17V158C7ClpC1q3EwpKSs/r9clDZ6pts8F+QfACaRBKetWrJ8bEbcCvyQljSvlVUWdK2eRmuzLbzeSBm3sRJoPrWa5af1GUiK5b0UtX8nzwHq5m0S5rah+3pn1em4GtY4UEVMk3Q8cm0ckLiDNAzWFRfuFnU7qdH57HpH4IinxWi4iTiV9WdwIXCzpROAh0pfaDhHxlbyNq4DDJD0MjCH1vyrfR3duAr4l6QzSCL3tSSP0yp/L5Dztwkk5sfkbKRndHTghIl7K5WZJ+hOp39cllTUHETGe1IG/Jnl7PwOOkTSJVEPyHVIieGapXB7xeD7w9oh4XtKKpP5OF5ESk+GkvmNrUPZlTqoJ/DJwlaTfkPpeHUY6vueWx5KTuE+RBgwsqIxVaaqVn5Kavl+S9L6y1c9Gmv+s3tGgS0zS70h9xO4hnXs7Ae8gjQ6F1GR7GPAPSccDo0mjPTeKiB9U2eSTpB8Hv5B0DKk59ATK+mHm439j3vZTpHPlu6Tatf/mxPDnpGbCMaRa4COB/0TERCjuXImIZ0jnSPkxOxAYHhGjKpZ/jDSK9t35/mfzqvvzebcsKTFcmZS0b1E2snR2WRPvxaS+k3+TdCqpz9p+wLak95RZ52n3CAfffGv0RmqSuYXUp+cF0jxOx1M2SjOXW5f0xTWJ9MH9H2CfsvXLkr7cxpFqNJ4jdYgurV8euID0pfwKaQLQE6g+GnT5KnF+n5QkTifN6P8Oqo8w/Qqp793svJ/LKRuZmMt8OD/2w006hiJ10h5Hqt27Hdiyokzpua2X7w8m1fK9mGOdAvwdeF+V7e9MGkQxMd/+CexYpdyn8j4W20ZeP5KuRy0eWFbu6zmmlXp43tWO/yjgiopli5xPla9zvn9nfm4zgEeAgyu2MQw4j9RHbBYp0Tmiq1hItVr35dfj6byPkeQRlKTk7DxS4jeDNMnwdeTRn6S+bf+PlKjNyufSJcA6RZ8r3byWi40GJdV6dfn6Aut1cw6MrdjWe0iJ3WukGsH7gM804z3jm2/tuJWmATCzDpBrCvYizeS+WA3U0k7SBcCCiDiox8JmZh3CzaBmHUDSxqR+UF8jNY06UatuO9KIUjOzPsM1a2YdIE/b8V7StA5fjDqm1TAzs87mZM3MzMysF/PUHWZmZma9mJM1MzMzs17MyZqZmZlZL+ZkzczMzKwXc7JmZmZm1os5WTMzMzPrxf4/Yefp5CXrfKMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 32ms/step\n",
      "22/22 [==============================] - 1s 33ms/step\n",
      "\n",
      "Quanv Train Accuracy: 0.92\n",
      "\n",
      "\n",
      "Quanv Valid Accuracy: 0.67\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if ql3 == 1:\n",
    "    modelq=modelq3 \n",
    "    y_pred=modelq.predict(q_valid3)\n",
    "    y_pred1 = (y_pred > 0.5) \n",
    "    y_pred=modelq.predict(q_train3)\n",
    "    y_pred2 = (y_pred > 0.5) \n",
    "\n",
    "    y_pred=np.argmax(y_pred1, axis=1)\n",
    "    print('\\nQuanv Train Accuracy: {:.2f}\\n'.format(accuracy_score(y_train, y_pred2)))\n",
    "    print('\\nQuanv Valid Accuracy: {:.2f}\\n'.format(accuracy_score(y_valid, y_pred1)))\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "    plot_confusion_matrix(cm , \n",
    "                          normalize    = False,\n",
    "                          target_names = labels,\n",
    "                          title        = \"Quanv 2 qubits Depolarizing Circuit with p=0.001 Confusion Matrix\")\n",
    "    \n",
    "    modelq=keras.models.load_model('checkpoints/best_quanv_demo23.hdf5') \n",
    "    y_pred=modelq.predict(q_valid3)\n",
    "    y_pred1 = (y_pred > 0.5) \n",
    "    y_pred=modelq.predict(q_train3)\n",
    "    y_pred2= (y_pred > 0.5) \n",
    "\n",
    "    y_pred=np.argmax(y_pred1, axis=1)\n",
    "    print('\\nQuanv Train Accuracy: {:.2f}\\n'.format(accuracy_score(y_train, y_pred2)))\n",
    "    print('\\nQuanv Valid Accuracy: {:.2f}\\n'.format(accuracy_score(y_valid, y_pred1)))\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "    plot_confusion_matrix(cm , \n",
    "                          normalize    = False,\n",
    "                          target_names = labels,\n",
    "                          title        = \"Best Quanv 2 qubits Depolarizing Circuit with p=0.1 Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "YETjpz5LwVue",
   "metadata": {
    "id": "YETjpz5LwVue"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 27ms/step\n",
      "22/22 [==============================] - 1s 31ms/step\n",
      "\n",
      "Quanv Train Accuracy: 1.00\n",
      "\n",
      "\n",
      "Quanv Valid Accuracy: 0.51\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAHWCAYAAAAo8M7SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABnZklEQVR4nO3dd7ybZf3/8de7hVJKKSAVGQplCJUlyFDGD0H2HspQERAFQVQEBZFZQWSoiIKKBaHwRZYoe5dSQWYLyG6ZZa9CoaWljPbz++O6QtM055wkJ+Pk9P3sI4/T3PeV+/7kzp3kk2vdigjMzMzMrGfq0+oAzMzMzKxjTtbMzMzMejAna2ZmZmY9mJM1MzMzsx7MyZqZmZlZD+ZkzczMzKwHc7LWC0gKSSMqLLtPLr9xQ4PqBSSNkNSwuW0kTZA0uobHteVrKGnjHPc+LY5jtKQJLdz/kHwchjWivM1dJPWRNEzSs5I+7omfWXOb/HqEpCH12mbFyZqkQZKOkfSApCmSpkl6XNKpkharV0A9jaT+kvaTdFU+Ud/Pb4qLJX2h1fHVg6Q18sk1pM7bLXzJFG4zJb0rabykSyTtKmmeeu7Tmk/S2jmxfTa/P6ZKelTS6ZKGtjq+SuQE+Kct3P/C+T24catiqCdJ80k6XtJzkj6Q9IykoyXN26htSNpL0oP5HHxd0jmSPl2m3OaSzpI0RtL07vzw6SHn/t7AccBtwPeA7zRpvy1R+BGdb2t3UOaQojL71LifnvWejIgub8CKwHPATOBy4CBgf+Bc4EPgTeDLlWyr3W7AUCCAO4BjSG+GE4G3gQ+ATXpAjAGMqLBsX6A/0Kdo2T55GxvXOa4hebs3A3vm2wHAqcDjed39wNKtPoYdxD8ivUUatv35gH41PG6O17CFx+i4/LnwBnB6/lw4ADgDeBX4GFgwl+2T4+7b4pj7AfOVLBsNTGjS/pWPwzxFywrvlWFlyne4rqfegCtzzH8Hvp//Vvw5Ve02gEPyutH5HDweeA94DFigpOyI/L31APBgrZ991Zz7DT7WFwHvAGrCvmr6zKpzDCPya/Y+8OcOyjyc1wewT437qfl9B8yT3+N1e00q2ekAYHw+ubcts37tfKK8DizWyhexQSfGosAaZZavTErWxvaAGKv6ECzz+H1q/cDqYruFk/3MDtb/NK9/pPiLq6fcaECyBswL9G/1c6vTc9k3v36jgIXKrJ8fOBkYVOV2BQxs8nMZTZOStQ723+EXQ3e+NFr0XLbJ8f6+ZPnv8/L167kNYDAwFbiPoh8CwPa57JEl21iKnKwDP6/ls69R536Nx3tUK8/dFpxfI/Kxv4hUaVL6w2udvP4fNDlZo4HJeSU7/3EO+NROyvwwl/lt0bIOE4ByH4zAFsClwLOkjPgdUo3MVzt6PLAkcDEwCZgG3ASsWFRu6xzDTzqI+25SreC8Nb6Y9wPTqyi/I+mX3HTgReAEYPPSEwoYlpcNKbONCcDokmWRT+DNgHvysXgN+CMlX3qlr0vRvkpvI/L6/rnM+Lzdd0jJ1W8reL6Fk71sspbLXJjL7FmyfD7gSNIv4+l5v9cAa5aU27hw/PK5+mQu/yTw4w72uRFwC/BuPtceAL5XptwISpI1Uk3rX3JcU/IxuR/4fpnHF47tKsBpwEvAjKJjP9tr2clrUbgN6ei9VbTsa6QvoGdIPyaeBPYuE1tfUk3x8/l4PQzsTifnXsnj+5FqD6YAn67w/P/kterg9TuIVOP6AUUfkMDXSe/5d/LxHg/8ifwLv9zx6OKzZrZl+XUod7zn2F7RY24rs91v5sc9VLL8wLz8yyXvi2Elx6D0NqG0PLAdMCa/Zq8Cv6XCHzpU8TnRnRuz3tOfK1n+ubz8L/XcBqnWLYDvlNnOM8Djneyn6mStlnM/P24w8GfSZ/+H+e+fgUVLyhXO507fy52cNyOKzuvRZeIoPK74fVjR53wn29wJuJOUNL+X/79jmXITSO+/ocB1+Ri+S2qxW7zC4zgix1/47ty9ZP1fSLWdhfdj8fPsAxwF3J7P/Q+BF4C/Fr8OnRzbcu/J3UnfAe8XHfthzP6ZvSDwdD5vFiuJ9ze57L6dPe9K+gt9I/8d3kmZEaRq4K8Dh1WwzXL2AT4FXED6UluK9Ca8VdImEXFHSfkFSAf8HtKX+rLAwcBVklaNiBmkZO81YC/Sh/snJH0e+Arwp4j4qNpgJfUBliDVKFZSfmfgX6ST9XhSFfl3gW2r3XcHvkR6rc4mHcNNgJ8Aq0raPCJmdvC4f5Oex/6kk+aJvPyZ/PfPpF+RF5ASjnmAz5M+SOrhHODbpONwIUDuk3IjsD7wf8CZwELAfsCdkjaKiLEl2/kxsDjwN9IHwDeBP0n6VET8qlBI0vbAFaTz4ve57B7AOZKWi4ijuoh3Y1Kydy2pa8ACwK7A2ZI+HREnlXnMP0hv5EKtwKsdbPvfpDd0sf75cfPkWLvyG9Kv+r+RPuAPBEZIejoi7iwqdyapyeY24HfAp0kfcs9VsA+ADUjH+/8i4s0KH9OZn5Jqsc8mvTYvAkg6kfT+fhz4A+nYLU/6rDmW9GFbj32fRPoyPaRo+RNlSyejgOMlLR8RhffKpqRmsdUkDY6IiXn514DJQOk5W7yfQ0jP7wrSeQDpS6/YNqQfxmeRuqDsSPoyn0R63StR0edEfg8uVOE2KXqukGo2Xo6IF0vKvCjplby+K9Vso/D/u8ts5x7gm5IGRkTp8axV1ee+pIWAu4AVSK/dA8CapPfn1yStGxGl7++u3stPkPqnHcXs5+4zVK/mz3lJP8yPH0f6boP0fX6lpB9ERGnusBQpYbuClC98EfgBMIhUaVOpB4H/5bgvzbH0J332nweU+17vl/f5L+AqUnK5Dql704aS1oqID6n8PbkT6f3zV9L7cnK5QCNiiqQ9SEns+ZK2iYiQtCnwC+CSiDi302dbQRb7FjC5gnIPk76IBpb8OpjjFwvlf+0uUKbcZ4CJwPVlHh/A4SXLD8vLtyxa9tu8bOWSsifk5V+qJJsvE1uhNvH4Csr2JWXvE4HBRcsXItVslGb/w6i+Zi2AnUqW/zEv36No2RyvSxev1dulx7+KYzSErmvWPpXL3F+0rND/ZMuSsoPycRxdtGzjXHYK8Nmi5f1IzSIfFZbn1+F50q/GJUvK3kmq9fp80fIRzFmzVu487ZPPyXcpqqUteh1HU6b2o9xrWbJewCWkBGDnCl/DBynqU0L6YPwAuLho2Sq57I3M3ndxtXwMyp57JbEVatwPreJ8KLxW+5RZ9jZz/uJcl1lNTf1L1oncH6SL83c0XdSsdbSsi+eyQd7nfkXLniX9uAhgt6I43wSuKfO+GNbZsjLrpha/LnnbjwKvVhhzNZ8TGxeV7/JWsr0pwL0dxHAf8EoFsVa8DVKNewDzlyl7al63YgfbqqVmrZZz/8T8mB+WLD8oLz+haFnhfO7yvdzZuUt1NWsVfc6XbhNYhJTAPE1Rky/ps/qZ/DouXPL4T94fRcv/nJevVEEMI3LZwfm1mMGsz/hv5XWrkn6UlD5PdXCefK80Lip7T34EfKHM+mGU+RwFDs3Lfw4sRvrx+SwVNJdXMhp0EOlLqCuFjHLBCsrOISKmFv4vaaCkRUkvwr3Al8s8ZCYltWWkD3VIvwgKzs9/9yravkid3R+NiAeqjVXS+qRfHw9R2S/atUjV9+dF0S/QiHiXlI3Xw/iIuLJk2cn5787d2O67wCqSVu3GNjpTOG8GFS3bk/Qr7X5Jgws3UlJ1C+kX0Pwl2/lHRLxUuBPp19EfSL8Qt8+L1wKWBs6NiFdKyp5KSrp27CzYkvO0fz5PP0WqxR1Eqt4vdXpEfNzZdjtwAqmK/YiIuKLCx/wlP59CvC+Tmk+K3xPb5b9/jKIa14h4hNSVoBKF16vsL8kaXBARb5Qs+3b++8uImF68IrI67bsW95G+pL4GIGkZUu3+xaQEatNcbjXSl8qoMtuo1pURMaFwJz//24DFJQ2scBuVfk48RGpmqvRWbAApqShnel7flWq2Ufh/ufLTS8rUQy3n/s6kpL20lulveXm5z+hK3sv1Uuvn/Oak1oU/RcQnxyP//0/AQFKze7FXIuKykmXlvrsr8Q9SwrR3vv9dYExEPFqucP7YeB9AUt884rP4/Vku1+jMdRHRWQ18qT8A15PyhmtJrQl7FB+7jlTSDDqZ2b9IOzKIlEBN7KpgOZKWJ/362BJYuGR1uQ/lV0o/wEm1gJAOQHpgxKOSHgC+LenI/OW0ESkzPryGONcitbW/QhpwURpDOcvlv+PKrHu82hg6MMcJExGvSnqnaP+1+CmptuARSc+SvhyuIdUUdNS0Wo1yH3xfIFX/d9bEMJjcVJaVe8MUjm3h+S+b/z5WpuxjJWXLyl+Kw4DdSAl4qUXKLHuys212sJ+9Sc0bf4+IU6t46LNllr0FLFN0v3AcxpcpO57U17Mr3fpxVka5Y/R5ch+wOu2jbiLiI0n/JTUjQkrOPiZ1zRhFarKEWc1I9UjWOnptIX3mVdLMV9HnRERMAkbWECOkPk/zdbCuf15fz20U/j8fqbtBadniMvVQy7m/LGkw2mw/2iLiY0lPkpqnS1XyXq6Xn1Lb53wtn6ldnccVi4i3JV0N7CPpQtL77UedPUbSbsDPSM3QpdPAlPv87kxVn+0REfmz/SlS8+tREXFfJY+tJFl7FNhI0goRUdqfBgBJA0g1Cs/HrP5fnf3qnW2/+QvwdlKGfjqpY+MUUvL3S8q3m8/oZPsquX9B3u7XSB9Ae+XHX9jJNubcqPQlZnVM3yT/0mmEio9do0XEVUrzr20DfJX0K+l7wB2SNiv+5Vej1fPf4sRBpHPg0E4eV49+UrW4iFQzNZx0zr5FOpe2ITXflqutruqLIs/rczbpC/7AKuPr6H1R+p7orsIv1zXrtL2OjlGhqa0zrXq/jAK2krQK6bNlTES8J2kU8BNJS+flE0ndRLqrms+8bpHUj1RjXJGIeK3o7iukJrtylgIq+dysZhuvFC0v/Y5ainR+vEL91Pvc70h338sdvS/meE804XO+WL3P43OBG0ifmR+SarfLb1zahdS/7T5SH/cXSbWvfcndQqrcdy0/AjZiVoXUGpU+qJLALs9/v99Jmb1IGWpx8vN2/lvuDb9syf1NSSM7D4mIYRHxr4i4OSJGkhK47rqIVFW6V24++wZwS0R01NF7DjlRG0lKIjeJiOer2H/hl0S5JrKVyywre+xy58klOtjHHBP0SlqCdFKU+yVTrNMvw4h4OyIujIj9SL+STgX+H100GVaocF5dV7TsKVKH91ERMbKDW2mNZrkJigvH9tmSv6tUUHYOkhYmJWr/FxEHRMRFEXFTPk/r8mEmaSVSZ9ZngW9EDYNfKjAh/12pzLpyy8q5kzQQYKfcFNwIT5I+o77YRblqPms6UkuTaqG2bFNSUnZrvj+a9IW0BemDeXQFTbbNatKt9HNifVJ/mkpvxcYAS0mareY531+Sjgda1LqNMfnvemW28xVS02+9BhdAbef+s8BKKpkEPN9fka4/o2vxNuXfE2VbD2r8nO/WZ2qd3EwalLg58O+IeKeTst8hJWebRMRfI+La/Pld7vu87u/J/APuHFLCfxqwq6T9KnlsJcna30kfmodK2qrMzr9EGkn1KqmTYEGhenCzkvLfJL3ZihUybZWU3YLq25DnEGnEzg3ALqR+MIOY1ZetS5LWJNWovUd6kZ+rMoT7SSfTd3P7eGG7g0gj8kqVPXZ0XHMD6YNgp5Jlv8h/r+wivsIHWWly2DcnKJ/IXzoPlitfLUkHk16Ph8mjebILSKOtytasSfpMmcXflvTZojL9SMdrBqlvAKQRWC+QXofFi8rOy6zBKVd1EnJH5+kSdP5jpiL5g/86Uo3ytrkpqhGuyX8PzqOaC/tfjdQNoUv5l/ZRpKagSyXN0SSU+/T9Jp/ntbgo//1Nfj1Lt194Har5rOnIe8AiRdusxIOkkZgHkH5EjYJP+qI+QDr/FqKyJtCy78EGqPRzojt91go1Gz8tWV64/4/ihZKG5m4wtW7jKlLz548k9S3a7vakpGO2/XVXjef+laQfoKWfE/vl5ZX2Sa3Gk8BQSZ/UUEqajzSooTjW7nzO30Ia+PLj4uOQ//9j0nl9SzeeQ5dyM+1BwK+AU7ooXhhAVfy5J+DoMmXr+p7M5+ZFpKb53Unvu7uB01XB1ZC6bCKIiGmSdiBVEV4n6V+kX44fk0ZrfYf0gbVDRLxe9LjxkkYCP8gH43+kKr+dSVXVxW3F/yVPpZCrYl/KZb9Dag5bras4K3A+sANpGoR36TqBAT7pOHwLqS37T8D6eYBBsSuKO56XiogZkg4BLgPuk3Q26fjtS2pGW7rkISNJzYLH5y/w54ANSb8SO+oT+AhwYd72U6S+NN8A/sPsiVA5Y0gJwlGSFiG9+Z7LMbya+wQ8SJq7ZllS09wkZn3pd2VFSXvm/w8gTb2wHemX1/2k0WnFfTn+SPoC+K2kr5G+7CaTjtOm5F9GJft4ErhX0lmk2s9vkfoEnBB5+H9+HX5E+mAcI2l4Lrs76dj+JiKe6uhJRBp+fTOwp6T383FbhjTs/Dmq7G9Rxl9Ix+YsYD1JpTUFnZ5nlYqIx/Jz3x8YKekK0hfGQaTXeS0q+FUZEefmmo7jgKclXUTqJ9iHVIOzK2nEU7npTCqJ8z5Jp5A+1B6QdCnpc2JZ0rm9LvBOlZ81HbmHdE6eKeku0of6qDKDHorjmynpP6Th+9NJUzMUjGJWEtRlshYRb0l6GthD0jOkKYGmRkSl77FKVfQ50Z0+axFxnaRrST/wFyJ9Ia1Hala7MCL+W/KQJ0g1G0Nq2UZEvCnpGNIUNCMlXUxq/vwZqZ/w6cU7k7Q66bsA0qhegO9I2jD//4yccHf2HKs990/Ny/6cKzgeJDWjfo/0OVtNv9RKnUmalmhk/lzsR/pOLW26W5AaP+cj4h1Jh5Mqau7VrGtU70OapuQHXR3LeoiIq4GrKyh6OWnan1GSLiB9NuxEmQEoDXhPDiOdb/tHxOMAkr5F+ry6RGn6lo4G1VDRsOOYNRT3GNKL+R6z+pI8StHQ3JLHLA78k/RF+x6pdusLlB86vzopIZxE+gIdTaqCHcGcQ8PneHx0PdS2HykxCuDsKp73xkXPtaPbkAq3tUt+YT6gk0lxc9kV8/EoTFB4GekDaAKdT4p7L+lX5uuky54sWFJ2H8oMVSeNpnmc1JxX2F4/0ofNffnYfZD3fy5FU1x08nwLr0fhNjOfC0+SpqTYlQ4m9CT9kPgJKSGamm9PkX4lb1Hm9dknl38qx/kUcHAH2/4qKQGfTPqSfZDKJ8UdTKrGfiU/9hHSr+M5jitdTDBb+loya0qaTs+zDvZV9nXt6P1C6qNxHKmm8QNS7eZupC+8oIqrkZCuYnI+KWGdTjpnHyFV8xdPhfLJa9XZsjLb/yap6WlKPg8KX8DF0xpU81lTbtkAUivC68z69T3HsSwTW2Eah1tLlhfe1y9V+jlFSj4LE4sGZSbgLLOtTs+xWj8nunsj1R78mnSOf0BqCjuGMhOQFz/XWrdR9B54KJ+Db5A+p+Y4j5n1XunW53k1534uW5jL8CVSt5yXSEnO4A7iq/S9PMeyonV7M+sKRM+RBtV9jaL3HFV8ztPxdCA7k36sFD6r76JkipguHr8xXXwOFJUdkcsO7qLcHFN35OX7kb7rChNLD2fWFFIjuvueLPe+zM9vBnBpmbK75bJndPZ8CvMUVS23tf+TlJUeGhF/qGlDczmlzuS3Ad+NiBEtDaYN+fjVl6RrSB/mgyJNLG29hKQAzo+IfVodi5lVp9qRD5+I1Gy1O2nOkNMkVTtqzcxaRHPOU1doHtqa1PznRM3MrIfo1rD2SB0t63W5JDNrnr0l7UUa0PAmaaTy/qTmkmNbGZiZmc2uqXN2mVmP8QCpn8lPSP01ppA6wv8qIh5sZWBmZja7mvusmZmZmVnj1dxnzczMzMwaz82g1mtonvlD/ep1qUprZ2t+oXTqQptbPf/8BCZOnFjvy63Rd9AyER+XXoq0c/H+mzdFxByTy5t1xcma9RrqtyDzrbRbq8OwHuDOe89sdQjWQ2zw5bUbst34eDrzDd2jqsdMf/CMwV2XMpuTkzUzM7NqCajq6mRmtXOyZmZmVgu527c1h5M1MzOzWrhmzZrEyZqZmVnV5Jo1axona2ZmZrVwzZo1iZM1MzOzagnXrFnTOFkzMzOrmlyzZk3jZM3MzKwWrlmzJnGyZmZmVgvXrFmTOFkzMzOrmkeDWvM4WTMzM6uWr2BgTeRkzczMrBauWbMmcbJmZmZWNTeDWvM4WTMzM6tFHzeDWnM4WTMzM6uWJ8W1JvKZZmZmVgupuluXm9NoSdHBbb1cRpKOlPSipPcl3S5pjUY/VWst16yZmZlVrSF91n4IDCpZdjywJjAm3z8COAY4DBgHHAqMlLRqRLxW74CsZ3CyZmZmVos6T90REY/Pvnn1A9YGLo2IjyX1JyVrJ0XEmbnM3cAE4EfA0XUNyHoMN4OamZnVQn2qu1VvK2AR4OJ8f31SzdtlhQIRMRW4Bti6m8/GejAna2ZmZtWqtr9abbVwewAvAXfk+0OBGcBTJeWeyOusl3IzqJmZWS0aOBpU0gBgB+BvERF58SLAexExo6T4JGCApH4R8WHDgrKWcbJmZmZWi+prywZLGlt0f3hEDO+g7PbAAsxqArW5mJM1MzOzqtU0GnRiRKxdYdk9gKcjoji5mwQMlNS3pHZtEWCaa9V6L/dZMzMzq0WD+qxJWog0YKC0Vm0c0BdYoWT50LzOeikna2ZmZtUqXMGgMaNBdwbmY85k7S5gMrDrJ2Gkvm3bAzd07wlZT+ZmUDMzs6o19ELuewAPRcQTxQsjYrqkk4FjJE1i1qS4fYAzGhWMtZ6TNTMzs1rUeVLctEkNBjYlXaWgnJNJydkvgUWBscDmEfF63YOxHsPJmpmZWQ8REROBeTtZH8CJ+WZzCSdrZmZmtWjgPGtmxZysmZmZ1aIBzaBm5ThZMzMzq5YaOsDAbDZO1szMzGrhmjVrEidrZmZmNZCTNWsSJ2tmZmZVEk7WrHmcrJmZmVVL+WbWBE7WzMzMqibXrFnTOFkzMzOrgZM1axYna2ZmZjVwsmbN4mTNzMysBk7WrFmcrJmZmVXLAwysiZysmZmZVUkeYGBN5GTNzMysBk7WrFmcrJmZmdXAyZo1i5M1MzOzGjhZs2ZxsmZmZlYtDzCwJnKyZmZmVgPXrFmzOFkzMzOrkkeDWjM5WTMzM6uBkzVrFidrZmZmtXCuZk3iZM3MzKxacs2aNY+TNTMzsxo4WbNmcbJmZmZWAydr1ixO1szayE1nH8xGa3++7LqN9/499z78HACrrLAkx/94BzZYc3n69BHjn3uNn/zmUh584sVmhmstcNmll/CH353KU089yaCFFmKTTTblhN+czJJLLtnq0HoVjwa1ZnKyZtZGDj7pUgYt0H+2ZcccuC1fHPpZxj72PACrr7gUI889hGtHP8x3jjgXgLVWWYb555u36fFac117zdXsvec3+cGBB/GbU37La6++yrDjjmaXHbblrvvup0+fPq0OsXdxrmZN4mTNrI2Me/a12e7PO09fvrTy0lx+8wPMmDETgDOO2oPrb3+UfY++4JNyt9z1RFPjtNa49JKLWHPNL3H6n878ZNmCgwax6y478uT48Qz9whdaGF0v06ABBpLmAX4OfA9YGngT+GdEHFJURsAvgQOBwcAY4CcR8b+6B2Q9gn9mmbWxLTZYmU8ttACX3TgWgKHLLc66qy/LXy/5T4sjs1b46KOPGLTQQrMtW3jhhQGIiBZE1LtJqupWoRHAT4DfAVsARwDvl5Q5AjgGOAXYHngPGClp8Xo8L+t5XLNm1sZ23XItXnptEnc+8AwA66w6BICFB83PvZcewcrLLcELr77NqefezPlX3t3CSK0Z9t5nX3b7+k784/8uYPsdd+L1115j2LFHs/EmX+MLK6/c6vB6nXrXrEnaCtgd+GJEPN5Bmf6kZO2kiDgzL7sbmAD8CDi6rkFZj+CaNbM2NX//edn2q6vxr1se+GTZZwYPAuCc4/fi0uvHsu2BZ3LzXU9w1nHfZssN/WXd2229zbYM//sIDjpwfz6z6EKsvspKzJgxg4sv+1erQ+udVOWta/sCozpK1LL1gUHAZYUFETEVuAbYutqnYO3ByVoDSNpYUkhatYtyv5M0oUlhtR1Ju0nap9Vx9FTbbrQaAwfMx2U33v/JssL3wYgr7+K080dy+9inOOTkyxh933gO++4WrQnUmuY/o2/jJwcdwEE/PpibRt7GBf+4hEmT3mb3b+zMjBkzWh1er9OAZtAvA09KOlPSZEnTJP1bUvFQ3qHADOCpksc+kddZL+Rm0MZ4AFgPeKbVgbS53UidZ0e0OI4eadct1+LpF97ggcdf+GTZO1OmAfCfMbN/jo8e8yQ//vbXmhqfNd8Rh/2MbbfbgRNPOuWTZV/84hp8cdWhXHP1Vey08y4tjK53qbIfWqUWB/YBHgL2ABYETgWukPSVSB0PFwHei4jS7HsSMEBSv4j4sN6BWWs5WWuAiJgM3NPqOKz3GjSwP1tssDKnnT9ytuXjnn0dgNLvEEnMjJnNCs9aZPz4cey6xzdnW7biSisx//zz8+yz/u1YbzUka4MljS26PzwihhdvMt92jIi38j5eBf4DfA24tRvhWhubK5tBJW0k6TZJ70l6V9JoSWvmdWtIujVXP0+S9A9Jnyl67HOSfltmm/+U9N/8/zmaQSUtLOmivM9XJR1VQ9w7SLpf0tQc272Svlq0vo+kIyQ9LekDSU9K2rtkG5J0gqQ3cjX7uZL2yPEOyWWG5Pt7SDovl3tJ0p55/eGSXpH0pqRTJPUp2ceqkq6TNCXf/lk8Sqno+Gyc170n6VlJPywqMwL4OvDVXDYkDav2mPVWO2zyRfrPN+8no0AL7nnoWd5+dyobr7PibMs3WXclHnny5WaGaC2w9DLL8L8HH5ht2bgnnuD9999nmWWGtCaoXqyGZtCJEbF20W14ySYnAY8UErXsv8CHwMpFZQZK6lvy2EWAaa5V653mupo1SRsDtwC3AXsDU4ENgKUkvQSMJrX9fwsYCJwM3CJp7fwmuIw0Wuewom0OBLYFDu9k1+cBGwOHAK+R5tFZHvi4wriXBy4H/pj33R9YC/hUUbEz8nM6ntQUuzlwrqS3IuLaXOanwJHAiaQPgR1J1ezlnAL8g5Q07Qucn5PaZfL9tYBfAw8Cl+Q4VwDuBMYCe5LOsROAayStG7PPH3A2cD4wHPgm8GdJYyPivvyYpYGFgUIS91Ilx2pusOuWa/HQ+JcY/9zrsy3/6OMZnDT8Bk786U68M+V97n/sBXbabA02/NLybPH9P7YoWmuW7+93AIf//BCWWGJJttxqa15//XVOOvF4lhkyhK223qbV4fU+9Z9m7QnSZ3u5PRWqxscBfYEVgPFFZYbmddYLzXXJGnASqT/AlkWJw40Akk7O97fMTZlIeorUpPl14GJSUnJ47j9QaOrcHugH/LPcDiWtAuwE7BERl+ZltwEvAJMrjHtNYEpEHFa07PqifaxAmiDxuxFxfl48UtISwHHAtfmX2OHAWRFxbC5zs6Rlgc+V2eeoiDgyb/9e4BvADsDQ3F/iRkk7Ajvn40Le12vA1oVfeJIeJn2IbANcV7T9iyPi17nMaNJx3AW4LyKekfQ20KfoOM9B0v7A/gDMO7CjYr3KogsvwCbrrsTxf7227PozLxpNnz59OHCPjTj6gG14csIbfOuwv3Png24G6+0O+vFP6NevH2f/7a+cM/wsFlp4YdbfYENO+PVJLLDAAq0Or9dpQJ+1a4FfSRocERPzso2AeUnfWwB3kb43diX9WEbSANLnZ2lNnfUSc1WyJmkB0mibg0tqeArWBW4uJGoAEXGv0ojNDUnJxYOSniTVrhWSiN2B/0TE66UbzNbJf68q2u57km7J8VTiEWAhSeeTarvuzMO1CzYl/fK6QmkG7IJbgW/mRO1zpA6sV5ds+2rKD/n+pH9EREyW9CbpeRZ3bH2aVANWsBmptmxmURzPkeYAWpvZk7Wbi7b/UU6MP1smjg7lZoThAH0GLDZXzPr51jtTGbTuwZ2W+dOFo/jThaOaFJH1FJLY/4AD2f+AA1sdSu/XmCsYDCdNiHuNpN+QBhicAoyMiP8CRMT0XLFwjKRJpB/Ch5K6NZ1R74CsZ5jb+qwtQqpOfrWD9UsA5RKu15m9ufFSYNfc/2sQsBWzapbKWZxUKza9ZPkbFUUNRMR4UpPlcqQatYm5D9ync5HBpKrxd4GPim4jSEn5EjkOSJcvKVZ6v+CdkvsfdrCsuNp+MPCLkhg+ynGX1t51tS0zsx5JpIE81dy6kisKvkbql3YJ8GfSj+bdSoqeTOrK8ktSbdwgYPNOKgyszc1VNWukN8BMUuJSzqvAYmWWfwa4v+j+paRLfWwILEtKev/dyX5fAxaU1L8kYSu3rw5FxHXAdZIWIvWRO530S2oP4G1S/7cNmNW3odgbzHq9P12yrvR+d7wNXAGcU2bdxDLLzMzaUEOm7iAiniZ1GemsTJCStRPrHoD1SHNVshYRU3Pfq70knVmmKfRe4EBJC0bEFABJ6wBDSJ3xC9t5TNKjpObPZUlV1G/RsTH5746kRK8wKGFzKu+zVvw83gUuyiNB18uLR5Fq1haKiFvKPU7Si6TEcUfgpqJVO1QbQyduBVYB7u+gqbkarmkzsx6rAbmaWVlzVbKWHQGMBG6QNJw0GnQ90ujF00id9G+SdAqzRoM+ApRer+VS4GBgIWC/znaYk7urgb/mZtNXSSM6p1UatKQf5DhvBF4BPk/qYHpB3sd4SWcBl0g6NT+f/qTEacWI+H5EzFCaduS3uf/ZnaREbbW8m3pMxDUMuI9UA3guqTZtKVJiOiIiRlexrXHAjpJ2Io0EfSUiXqlDjGZm3daImjWzcua2PmtExO2kxGEAcCEp6foq8FJEvAlsAkwnjfz8M3AHqS9A6dw1l5D6Z80Erqxg1/uQOtSfDvydVAPVWT+3Ug+TmitPy9s5mjT1xS+KyhxEmvJiL1K/thGk5tLbi8r8gTQi9oekBHQR4Dd5XdW1fKUi4kngK6REdDhwA/Ar4APSYIRq/IX0XM8l1U7u3934zMzM2o2631Jl7U7SOaSEdJlWx9IdfQYsFvOtVNoP1+ZGk8ac2eoQrIfY4Mtrc//9Y+teBdZ/iRVjyN7VDb4cf8pW90fE2vWOxXq/ubEZdK6mdFWF3Ulz9cwkTdnxXWavoTMzs04I6NPHzaDWHE7Weog8D1pH7/woc9HeWk0ljWL9EbAA8DwpUft9nbZvZjZXcJc1axYnaz3HM6TLOJXzPGlEardFxHOkfnlmZtYNHmBgzeJkrefYHpivg3UfNDMQMzPrQoUT3ZrVg5O1HiIiHml1DGZmVpl0BQNna9YcTtbMzMyq1pgrGJiV42TNzMysBs7VrFmcrJmZmdXANWvWLE7WzMzMquUBBtZETtbMzMyq5AEG1kxO1szMzGrgXM2axcmamZlZDVyzZs3iZM3MzKwGztWsWZysmZmZVUuuWbPmcbJmZmZWpTTAoNVR2NzCyZqZmVnVfAUDax4na2ZmZjVwrmbN4mTNzMysBq5Zs2ZxsmZmZlYtX8HAmsjJmpmZWZV8BQNrJidrZmZmNXCyZs3Sp9UBmJmZtSOpulvX29M+kqLM7YCiMpJ0pKQXJb0v6XZJazTwaVoP4Jo1MzOzGjSwZu1rwPtF958t+v8RwDHAYcA44FBgpKRVI+K1RgVkreVkzczMrFqNHWAwJiLem2OXUn9SsnZSRJyZl90NTAB+BBzdsIispRqSrEl6E4hKy0fEYo2Iw8zMrBHUmklx1wcGAZcVFkTEVEnXAFvjZK3XalTN2p+pIlkzMzNrNw3M1Z6RtCjwDHBaRPwtLx8KzACeKin/BLB7w6KxlmtIshYRwxqxXTMzs56iT/2ztVdJ/dHuA/oCewBnSRoQEX8AFgHei4gZJY+bBAyQ1C8iPqx3UNZ6TeuzJmkRYFXgc8ANETEpt79/GBEzmxWHmZlZPdSQqw2WNLbo/vCIGF64ExE3ATcVrb8hf08eLemPNQdqba/hyZqkeYDfAAcB85OaR9ch/RL4FzAWOK7RcZiZmdVLmo6j6mxtYkSsXeVjLgd2A4aQvjcHSupbUru2CDDNtWq9VzPmWTsR2I80UmU50sTPBVcB2zchBjMzs7rqo+puNYqiv+NIzaMrlJQZmtdZL9WMZG0v4IiIOA94sWTdM6QEzszMrK1IqupWo28AE4HngbuAycCuRTEMIFV63NDNp2M9WDP6rC1MSsrK6Uf6lWBmZtZW6j2+QNK/SIMLHiZ9N+6ebz/JfbunSzoZOEbSJGZNitsHOKO+0VhP0oxk7VFgR2BkmXVbAw80IQYzM7O6EWmutTobD+xLGogn4HFgr4j4v6IyJ5OSs18Ci5L6fW8eEa/XOxjrOZqRrP0a+Jek+YF/ktrd15C0M/ADYIcmxGBmZlZX3eiHVlZEHAkc2UWZIPUFP7G+e7eerOHJWkRcJelbwKmkXwwA5wAvA9/JQ5XNzMzaR/f6oZlVpSnzrEXEZcBlklYiVdu+DYzPvxDMzMzajnM1a5amXsg9IsY3c39mZmaNIBpyBQOzspoxdQeSVpN0kaSnJU3Nfy+StHoz9m9mZlZvaWLcym9mtWrGFQx2Ai4jTd9xOfAGsBhphOhYSbtFxJWNjsPMzKye3GfNmqUZzaCnkK5UsFtxHzVJvySNDj0FuLIJcZiZmdWFa8usmZrRDPo54JzSwQT5/tl5vZmZWVvpI1V1M6tVM5K1scAqHaxbFU+Ka2ZmZtahhjSD5muVFRwKXCJpXlJzZ6HP2s7A94E9GhGDmZlZI7muzJqlUX3W3iNdqaBAwEnAb0qWAdyLrw9qZmZtxgMMrFkalazty+zJmpmZWa+R5llrdRQ2t2hIshYRIxqxXTMzsx7Bl5uyJmrqFQzMzMx6C+dq1ixNSdYk7Q7sB6wI9C9dHxGLNSMOMzOzenHNmjVLw6fukPQt4HzgaeCzwNXAtXnfk4EzGx2DmZlZPRX6rFVzM6tVM+ZZOww4ATgo3/9LROwLLAtMBKY1IQYzM7O6Uu63VunNrFbNSNY+D9wZETOAGcAggIiYQrrU1I+aEIOZmVldqcqbWa2akaxNBubL/38Z+ELROgGLNiEGMzOzupF8uSlrnmYMMBgDrA7cROqvdqykj4EPgWOBe5oQg5mZWV05/7JmaUaydhKwTP7/sfn/fyXV6o0BftCEGMzMzOrK/dCsWRqerEXEPeTas4h4B9hR0nzAfBExudH7NzMzawTnatYsLZkUNyI+AD5oxb7NzMy6S7gfmjVPQ5I1SadWUTwi4heNiMPMzKwh5Jo1a55G1aztWkXZAJysmVndvDf941aHYD3EjIiGbdt91qxZGnUh92UbsV0zM7OeohlzX5mBL+RuZmZWNeGaNWse/zAwMzOrQaOvDSppKUnvSQpJA4uWS9KRkl6U9L6k2yWtUcenZj2MkzUzM7MaNOFC7r8F3iuz/AjgGNIlG7fPZUZKWrzW52I9m5M1MzOzKkmNvZC7pI2ArYDflSzvT0rWToqIMyNiJGlQX+BrbfdaTtbMzMxq0KiaNUl9gTOA44GJJavXBwYBlxUWRMRU4Bpg6+4+J+uZmpas5Tb2z0laX9ICzdqvmZlZI0jV3apwADAf8Ocy64YCM4CnSpY/kddZL9SUZE3SD4GXgeeBO4CV8vJ/S/ppM2IwMzOrFwF9pKpuFW1XWhQ4ATg0Ij4qU2QR4L2ImFGyfBIwQFK/7jwv65kanqxJOgw4DTgb+BrpHC8YDeze6BjMzMzqrU+VN2CwpLFFt/3LbPZE4J6IuL7hT8DaRjPmWTsIODYiTs3t8MXGAys2IQYzM7O6qmGatYkRsXbH29MqwL7ARpIWzosH5L8LSZpBqkEbKKlvSe3aIsC0iPiw6qisx2tGsrY4cH8H62YC/ZsQg5mZWd2oiqbNKnwemBe4u8y6l4C/AxcBfYEVSBUeBUOBcfUOyHqGZiRrTwNfBW4ts24j4PEmxGBmZlZXDbiAwX+BTUqWbUW6fvY2wLOkvt+TSdN1/DrFoQGk+daG1z0i6xGakaydDvxF0ofA5XnZYpK+BxwK7NeEGMzMzOqqxoluOxQRE0l9uT8haUj+7x0R8V5edjJwjKRJpNq0Q0nd4s6ob0TWUzQ8WYuIcyQtAhwL/Covvh6YBgyLiIsaHYOZmVk9FUaDtsjJpOTsl8CiwFhg84h4vVUBWWM15ULuEfFbSWeRJvNbFHgbuDsi3m3G/s3MzOqtGblaRIwARpQsC9Ko0RMbH4H1BE1J1gAiYgpwU7P2Z2Zm1jC1X+/TrGoNT9byhLidioi/NDoOMzOzehLO1qw5mlGzdmYn6yL/dbJmZmZtI/VZa3UUNrdo+BUMIqJP6Q34FPBN4CFg5UbHYGZmVm+NupC7Wamm9VkrFhHvAJdKWgj4G7BxK+IwMzOrlVo3GtTmMi1J1oo8B3R46Q0zM7OeyM2g1kwtS9YkLQH8jJSwmZmZtQ81Z+oOM2jOaNA3mTWQoKAfsCAwHdil0TGYmZnVWwsnxbW5TKtGg04nXZT2xoh4qwkxmJmZ1Y2bQa2ZGpqsSZoXGAk8FxGvNHJfZmZmzeSKNWuWRk/dMQMYBQxt8H7MzMzMeqWG1qxFxExJTwGLN3I/ZmZmzSX6+AoG1iQNnxQXOAo4VtJqTdiXmZlZw4nUDFrNzaxWDalZk7QR8EBEvAccDSwK/E/Sy8DrlIwOjYh1GxGHmZlZQ/iqBNZEjWoGvQ1YD7gPeDTfzMzMeg1P3WHN0qhk7ZMzOCK+26B9mJmZtUShGdSsGVp9uSkzM7O25Jo1a5ZGJmvbSKpoyo6IuKCBcZiZmdWdczVrlkYma8dWWC4AJ2tmZtY2RHOmUzCDxiZrmwBjG7h9MzOz1hDIVWvWJI1M1t6PiKkN3L6ZmVnLOFWzZvEAAzMzsyqlC7k7XbPmcLJmZmZWA6dq1iwNSdYiwv0uzcysV3PFmjWLa9bMzMyqJg8wsKZxsmZmZlYlT91hzeRzzczMrAaSqrpVsL1vSLpL0luSpksaL+loSf2KykjSkZJelPS+pNslrdHI52mt52TNzMysBqryVoFFgVHA94GtgXOBo4DTisocARwDnAJsD7wHjJS0eDefjvVgbgY1MzOrVgMmxY2Iv5Usuk3SIOAgST8G5iMlaydFxJkAku4GJgA/Ao6ua0DWY7hmzczMrEqFPmvV3Gr0FlBoBl0fGARcVliZJ5+/hlQTZ72Ua9bMzMxq0KjRoJL6kmrRvgT8BPhrRISkocAM4KmShzwB7N6QYKxHcLJmZmZWgxpStcGSiq+ZPTwihpcpN5WUrAFcAByW/78I8F5EzCgpPwkYIKlfRHxYfVjW0zlZMzMzq0ENFWsTI2LtCsqtDwwA1gWOBc4Eflj13qzXcLJmZmZWpdRnrTHNoBHxQP7vfyVNBM6X9HtSDdpASX1LatcWAaa5Vq338gADMzOzGkjV3WpUSNyWBcYBfYEVSsoMzeusl3KyZmZmVjVV/a9GG+S/zwF3AZOBXT+JQhpAmm/thu48G+vZ3AxqZmZWg3oPBpV0IzASeIw06nMD4GfApRHxTC5zMnCMpEmk2rRDSRUvZ9Q3GutJnKyZmZlVqUF91sYA+wBDgI+BZ4FfAmcVlTmZlJz9knTFg7HA5hHxer2DsZ7DyZqZmVm1utcPrayIOIZ0KanOygRwYr7ZXMLJmlkbuensg9lo7c+XXbfx3r/n3oefA2CVFZbk+B/vwAZrLk+fPmL8c6/xk99cyoNPvNjMcK3Bnn3maf78x98z9r57GPfE43xl/Q256oZbP1n/2muvctYZpzN61C0899yzLLzwImy40cYc86sTWXyJJVsYee/QoDlxzebgZM2sjRx80qUMWqD/bMuOOXBbvjj0s4x97HkAVl9xKUaeewjXjn6Y7xxxLgBrrbIM8883b9PjtcYa/8TjjLz5RtZa58t89NHHc6x/+MEHuO7aq9hzr31Za511efON1zn1NyewzWYbcfu9/2PgwIEtiLr36MagAbOqOFkzayPjnn1ttvvzztOXL628NJff/AAzZswE4Iyj9uD62x9l36Mv+KTcLXc90dQ4rTm23GY7tt5uBwC+u+fuvP3WxNnWf3m9Dbj7/keZZ55ZH/Wrf3FNvvKlVbj2qn+zx7f3amq8vYmAPs7VrEk8dYdZG9tig5X51EILcNmN6Qo2Q5dbnHVXX5a/XvKfFkdmzdCnT+cf4QstvPBsiRrA8p9fkQEDBvDaq682MrS5QpOm7jBzsmbWznbdci1eem0Sdz7wDADrrDoEgIUHzc+9lx7BlDF/5LGrj2PvndZrYZTWkzz26MNMmzaN5T9fvu+jVa5Jk+KaOVkza1fz95+Xbb+6Gv+65YFPln1m8CAAzjl+Ly69fizbHngmN9/1BGcd92223HDlVoVqPcTMmTM56vBDWW75z7PVNtu3Opy255o1a5a2StYkjZA0tkn7GpavyVa4v2JetnBJuX0khST31K0jSYvl4z2k1bH0VNtutBoDB8zHZTfe/8mywtfBiCvv4rTzR3L72Kc45OTLGH3feA777hatCdR6jF8fdxRj77uHv5x9HvPO6wEn3VHos1bNzaxWbZWstdiKwHHAwi2OY26xGOl4D2lxHD3WrluuxdMvvMEDj7/wybJ3pkwD4D9jnpqt7OgxTzJ0uSWaGp/1LOee/VfO/OPvOeNv57LWOl9udTi9QNMuN2XmZM2sHQ0a2J8tNlh5tlo1gHHPpknMS/vHSGJmzGxWeNbDXHPVv/nlz3/KcSeczM5f363V4fQOVfZXc5816462TNYkbS7pYUlTJf1X0ipF6/pIOkLS05I+kPSkpL1LHr+tpFskvSFpsqR7JHXYRiRpY+CafPe53Ow5oaTYsnmbUyWNk7RL0eN/KOm90qZSSRvnbX2xgue8sKRzJL0iabqkFySdXVJmVUnXSZqSb/+UtHhJmdUl3ZW38ZikbSSNlTSiqMyIvGxbSY9Lmpa3+ylJK0i6LT/PsZJWL9l+Jcd/tKTLJX0rl5ss6QZJn83rhwCP5OK35WMUXR2juckOm3yR/vPN+8ko0IJ7HnqWt9+dysbrrDjb8k3WXYlHnny5mSFaD3HnHf/hwO/txfcPOIiDDj601eH0KqryZlardpxnbWngt6RLbbwP/A64VNJq+TIcZwB7A8cDDwCbA+dKeisirs3bWJaUfP0OmAlsDdwgaaOIuLPMPh8Afp7L7wK8CnxQUuYiYHiO7cfAJZKWi4iX8rrfA98ARhQ95rvAAxHxUAXP+zRgfeAQ4DXgc8BGhZWSVgDuJF0nbk/Sa3sCcI2kdSMiJA0AbsqP/ybQH/gDsAjwaMn+liYdw6OBAaTjOpzULHk2cCpwUn6eq+RjD5Udf4AvA0uSLlI8P/DHvP1tSMf328A/gIPydqzIrluuxUPjX2L8c7NfDvCjj2dw0vAbOPGnO/HOlPe5/7EX2GmzNdjwS8uzxff/2KJorVGmTZvGyJtvAOC1V15mypQpXH3lvwDYbIuteemF59nrm19nhRVXYqdddmXsffd88thFB3+aZZdbviVx9wapz5pTMGuOdkzWPgVsEBFPQarJAa4AVpL0MXAg8N2IOD+XHylpCVL/p2sBIuLMwsby428DVgG+R0p4ZhMRkyWNz3cfjIgJZeL6Q0Scm7d5P/A6sB1wVkS8I+lfpORsRC4zEPg6cESFz3td4M8RcWnRsguL/n8cKQnbOiI+zPt4GBhHSoCuy/tfFFg7Il7OZZ4B7i2zv08B60XEM7nc6sBhwN4RcUFeprzdocATOWHs8vhng4BtI2JS3tbiwB8kzR8R7+fYAR6PiHvogKT9gf0BmHfuGOOx6MILsMm6K3H8X68tu/7Mi0bTp08fDtxjI44+YBuenPAG3zrs79z54DNNjtQabeKbb/C97+wx27LC/fsffYr7x97H5Hff5bFHHmabzTaardzu3/oOZ/7t3KbF2hs5VbNmacdkbUIhUcsez38/CyxPqim7QlLxc7sV+KakvhExIze3nQhsBizBrPdcuVq1St1c+E9EvCXpjRxTwd+BW3Nt27PAbqTjf1GF2/8fcJikGcDIiHiyZP1mwPnAzKLn/hwwAViblFStA9xfSNRyrPdJep05TSgkatnT+e+oMsuWAp4ANqWC45+XjSkkalnhdVyqaLtdiojhpBo5+gxYbK5oKn3rnakMWvfgTsv86cJR/OnCUZ2Wsfa39DJDeHPKR52u/+aee3e43rrJ2Zo1STv2WXun5P6H+W9/YDDQF3gX+KjoNoKUGC2Ra9KuJjUpHgtsQkpibsjbqGdcxdsbDTwL7JPvfxe4KiLernD7PwKuJMU8XtJTkop/Ug8GfsHsz/sjYDlSkynA4sCbZbZdbtk7Jfc/LLO8+NgXYuj0+Few/e68BmZmZr1OO9asdeZt4GNgA1INT6k3gBWANUnNhTcWVkiav5GB5T5j5wL7S7oQ2JDUV67Sx78D/AT4SW6SPBz4h6SHI+Jx0nO/AjinzMML88W9BqxUZv2nK34inavk+JuZ9QqejsOapbcla6NINTsLRcQt5QoUJWUfFC1bhpRgPFzuMVk9an5GkDre/x14GSgbY1ci4mFJh5E64Q8lNSHeSup3d39RZ/9SY4BvSVqqqM/ausBnaomjjC6PfxVc02ZmPZrHF1iz9KpkLSLGSzqLNELxVNLIyP6kJGbFiPg+qcP9S8DvJR0DLAj8ipQ8daYwwOAHki4BpkXEI509oEx8r0i6EdgWOKmo/1aXJP2XVHP2KBDAfsBU4L5cZFj+/3W5Bm8iqf/X5sCIiBgNnEca3XmtpF+RRmH+itQM2u1JuCo8/pV6gTTad29J7wIfRURTrl5hZlYJ52rWLO3YZ60rB5GmrNgLuJ5Um7UtcDtARHxAmn7jY+DyXPYk4D+dbTQinidN37ELaSDCNZ2V78SV+e95VT7ublJ/t8uBy0j9w7bOU4OQBxx8BZhG6nB/AykR+4DcYT8ipgFbkZKgS0kJ3uGk/mOTa3o2c+r0+FcqIqaTEtK1SK/NmDrFZ2ZWH55ozZpEHbeYWSNIugxYIiL+X6tjAZC0LPAksH9EVJtA9ih9BiwW863k2dkNXrzj9FaHYD3EZht9mf89cH/dU6WVV1szLri609/4c1hnuYXuj4i16x2L9X69qhm0J5O0GmkKjV2APboo3sg4fgm8AjxPmvj2l6Rm0H+1KiYzs7bjS0hZEzlZa55rSE2Xf4mIy4tX5Mll+3by2BmdDBqoVpAmqF2S1ER6B/DziKhXM6iZ2VzBuZo1i5O1JomIIZ2s3pvO+7B9cuWDOsRxMnByPbZlZjZXc7ZmTeJkrWe4hjQxb0eea1YgZmZWCXmeNWsaJ2s9QES8BbzV6jjMzKxy7rNmzeJkzczMrEqejcOaqTfOs2ZmZtZ4dZ5nTdKukq6W9LKk9yTdL+mbZcrtl68PPT2X2bRuz8l6JCdrZmZmNVCV/ypwKPAecAiwA3AbcJGkH3+yz5S8nQVcQLq+9GOkq9KsWu/nZz2Hm0HNzMxq0IA+a9tHxMSi+6MkLUlK4s7Iy4YB50fECSkG/QdYEzgC2LPuEVmP4Jo1MzOzGtT7alMliVrBg6R5MZG0HLAi6ZKDhcfMBP5JqmWzXsrJmpmZWbWqzdRqr4Vbj3RJQICh+e+4kjJPAJ+S9Oma92I9mptBzczMatDoedbywIGdgH3zokXy33dKik4qWv9mQ4OylnCyZmZmViVRU5+1wZLGFt0fHhHDy25fGgJcBFwVESNqCNF6ESdrZmZmNaihXm1iRKzd5XalTwE3AM8D3y5aVahBW4jZa9cWKVlvvYz7rJmZmdWiAX3WJA0ArgX6AdtFxLSi1YW+akNLHjYUeDsi3ATaSzlZMzMzq0G951mTNA9pZOfnga0i4o3i9RHxLGmwwa5Fj+mT799Qz+dmPYubQc3MzGrQgHnW/gJsAxwMLCpp0aJ1D0bEB6R51i6UNAG4E9iblNx9q+7RWI/hZM3MzKwGDRgLukX++8cy65YFJkTExZIGAr8AjiFdwWC7iHi0/uFYT+FkzczMrBZ1ztYiYkiF5c4Gzq7v3q0nc7JmZmZWpTRmoLHzrJkVOFkzMzOrlhrSZ82sLCdrZmZmNXCuZs3iZM3MzKwWztasSZysmZmZVa2yudPM6sHJmpmZWQ3cZ82axcmamZlZlaq4gpRZtzlZMzMzq4WzNWsSJ2tmZmY1cJ81axYna2ZmZjVwnzVrFidrZmZmNXCuZs3iZM3MzKxavoKBNZGTNTMzs5o4W7PmcLJmZmZWJeGaNWseJ2tmZmY1cK5mzeJkzczMrAauWbNmcbJmZmZWA8+zZs3Sp9UBmJmZmVnHXLNmZmZWC1esWZM4WTMzM6uBczVrFidrZmZmVZInxbUmcrJmZmZWAw8wsGZxsmZmZlYL52rWJE7WzMzMauBczZrFyZqZmVkN3GfNmsXJmpmZWdXkPmvWNJ4U18zMrEqFC7lXc6tou9IKkv4m6WFJMySNLlNGko6U9KKk9yXdLmmNuj5B61GcrJmZmfUcqwDbAOOBJzsocwRwDHAKsD3wHjBS0uJNidCazsmamZlZDRpRswZcExGfi4hdgcfm3Kf6k5K1kyLizIgYCewKBPCjOj0162GcrJmZmdVAVf6rRETM7KLI+sAg4LKix0wFrgG2rvW5WM/mZM3MzKxaVdaq1XHk6FBgBvBUyfIn8jrrhTwa1MzMrEqipnnWBksaW3R/eEQMr3IbiwDvRcSMkuWTgAGS+kXEh9WHZj2ZkzUzM7NaVJ+tTYyItRsQifVyTtbMzMxq0KJ51iYBAyX1LaldWwSY5lq13sl91szMzGrQoj5r44C+wAoly4fmddYLOVkzMzOrgaq81cldwGTSdB0pDmkAab61G+q3G+tJ3AxqZmZWiwa0gubEa5t8dylgkKRv5PvXR8Q0SScDx0iaRKpNO5RU+XJG/SOynsDJmpmZWQ0a1GdtMeCfJcsK95cFJgAnk5KzXwKLAmOBzSPi9UYEZK3nZM3MzKxKhWuD1ltETKCLOruICODEfLO5gNJrbtb+JL0JPN/qOFpsMDCx1UFYj+HzAZaJiE/Xe6OSbiQd32pMjIit6h2L9X5O1sx6EUljPY+TFfh8MOsdPBrUzMzMrAdzsmZmZmbWgzlZM+tdqr3OoPVuPh/MegH3WTMzMzPrwVyzZmZmZtaDOVkzMzMz68GcrJmZmZn1YE7WzNqUpGMlLdnBuiUkHdvsmMzMrP48wMCsTUmaAawXEfeVWbcWcF9E9G1+ZGZmVk+uWTNrXwI6+rX1WWBSE2OxFpM0Q9K6HaxbKyf3ZtaGfCF3szYiaW9g73w3gL9KmlxSrD+wGnBzM2Ozluvs4t/zAh83KxAzqy8na2btZRrwVv6/gHeBt0vKfAjcAPyliXFZC0haGhhStGhNSf1LivUnJfjPNSsuM6sv91kza1OSzgNOiIhnWx2LtYak44DjmNUc3lHt2vvA9yPi4qYEZmZ15WTNzKxNSfo0sBgpSXsY+Hb+W+xD4IWI+KDJ4ZlZnThZM2tjktYGdiENKCht/iIidmt6UNYSkpYBXo2ID1sdi5nVl/usmbUpSQcCfwYmAk+RalBsLhURzwNImg9YivLJ++PNjsvMus81a2ZtStIzwG3AARHhkX5zuTxB8nBg63KrgfC8e2btyTVrZu1rMeBiJ2qWnQN8CTgUeBzXtJr1Gk7WzNrXDcCXgVtbHYj1CBsA+0XEZa0OxMzqy8maWfv6MzBc0rzALcA7pQXcR2mu8gZpig4z62XcZ82sTUmaWXS39I3sPkpzGUnfBA4CtomI0qtamFkbc82aWfvapNUBWI+yC7A08LykMcxZ0xoRsXvTozKzbnPNmplZLyDptq7KRIQTfLM25GTNrM1J2hpYG/gc8OuIeEHSRsDTEfFKa6MzM7PucrJm1qYkfQa4GlgLmAAsC6wTEQ/k64ZOj4gDWxiitYgkAUsAb3hqF7P216fVAZhZzc4ABgJD8634It4jgU1bEZS1jqRtJN0LTAdeBFbPy8+WtGdLgzOzmjlZM2tfWwFHR8TTzDka9CXSJYdsLiFpL1JN6zhgf2ZP3p8EvteKuMys+5ysmbW3jpq4BuM5t+Y2RwG/jYi9gQtL1j0GrNz8kMysHpysmbWvO4CfSCqeS61Qw7YvMKr5IVkLLUOaHLmc6cCgJsZiZnXkedbM2tcvgP8CjwJXkBK1/SStAqwGfKWFsVnzvQisSfkkfW3g6eaGY2b14po1szYVEY+SRoKOBfYBZpAmRn0J+HJEPNm66KwF/g4clwcSzJ+XSdKmwOHA2S2LzMy6xVN3mJn1Anm6jjOBA0iJ+zzAR0Bf4G8RcVALwzOzbnCyZmbWi0haHtgMWBR4GxjlWlaz9uZkzayNSdoN2Jk0TUf/0vURsW7TgzIzs7ryAAOzNiXpZFJfpDGkzuMftjYi6wkkrUTHyfv1zY/IzLrLNWtmbUrSG8AfIuKkVsdirSdpNeBi4AvMPiFuQURE3zLLzayHc82aWfv6CLi/1UFYj3Eu6ZzYDte0mvUqrlkza1OSDifNn7V7+I0815P0HvD1iLip1bGYWX25Zs2sTUXEqZJ+B4yT9B/gnTmLxC+aH5m1yH3A0q0OwszqzzVrZm1K0reB84GZwJvM2ewVEbFc0wOzlpC0AqnP2unAbcyZvBMR05oblZnVg5M1szYl6UXgduCAiJjS6nistSQtTLpKwS4dlfEAA7P25GZQs/Y1CDjXiZplFwLrAb/DAwzMehXXrJm1KUnnAq9ExNGtjsVaT9JUYL+IuKjVsZhZfblmzax93QScLGlxYBTl+yh5EtS5xwTAfdLMeiHXrJm1KUkzuyjiSVDnIpK2AX4F7BoRE1ocjpnVkZM1szYlaZmuykTE882IxVpP0hjS1B2LkGrZ3ikt42vFmrUnN4OatSknYlbi0Xwzs17GNWtmbUpSZxOgzgQmR8TkZsVjZmaN4WTNrE3lPmtdvYFfAP4UEX9oQkhmZtYAbgY1a1/fAk4hNX1dTbqKwaeBHYFVgd+Qrh16qiScsPVueSqXjswEJgP/A/4dEe81JSgzqwvXrJm1KUnnAO9HxI/LrDsDWCgi9pJ0OrB1RKzU7BitefIAg88BiwGvMyt5/wzwBvAusGxet2lEPNmiUM2sSn1aHYCZ1WxX4KoO1l1NqmEDuAHocuSotb1jSSNAvxwRS0TE6hGxBPAVUqJ2GLASMAX4bcuiNLOqOVkza1/TgQ06WLdBXg8gYGpTIrJWOhU4LiLGFC+MiPuAYcApEfEccDKwUfPDM7Nauc+aWfsaDhwjaVHgGmbvs3YAqc8awPrAQy2J0JppBeD9DtZNA4bk/z8PzNeMgMysPtxnzayNSTqE1Ly1OGlkqIDXgN8WBhRIWgWY6lntezdJd5GSsG0j4rWi5UsA1wHTImJDSXsBx0bECi0K1cyq5GTNrM1J6kOauf4zpETtxYjo6lJU1stIWp10vdhFgPuZVdO6FvA2sGVEPCLpCNKlyE5pWbBmVhUna2a9gCQBSwBvRMTHrY7HWkPS/MC+pClbFicl72OA8yKioyZSM+vhnKyZtbF88e7jgDWAvsC6EfGApOHA7RFxYSvjMzOz7vNoULM2lfseXQ2MA/Zn9vfzU8D3WhGXtZakrSUdI2l44ZJkkjaStGSrYzOz2rhmzaxNSRpPmo3+l5L6Ah8Ba+eatW1ITV+faW2U1iySPkNK3tcCJpAmwF0nnw/nAdMj4sAWhmhmNXLNmln7Wga4pYN104FBTYzFWu8MYCAwNN9UtG4ksGkrgjKz7nOyZta+XgTW7GDd2sDTTYzFWm8r4OiIeJo0jUuxl4Clmh+SmdWDkzWz9vV34DhJewLz52WStClwOHB2yyKzVuloJPBgOp4w18x6OPdZM2tTebqOM0lXK5hBuiLJR6RRoX+LiINaGJ41maTrgH6kGjZI58JaEfFgXjc1InZrWYBmVjMna2ZtTtLypP5Ig0mTn46KiCdbG5U1m6RVgf8CrwJXAL8A/gasAqwGfMXnhVl7crJmZtZL5MR9GLMn77cCwyLiqRaGZmbd4GTNrE1J+n/ApyLiqnx/UdKIwJVJX9BHRMRHLQzRzMzqwAMMzNrXqcCqRff/RKpRuQfYB/hVC2KyHkTSUEk7eUJcs/bmZM2sfa1EumA3kgYAOwMHR8QBpNGgu7cwNmsySX+TdFbR/d2BR4F/A+Mkrd+y4MysW5ysmbWvfqTJbwE2II0GvS7ff5J0YXebe2wF3F50/wTgImBJ4KZ838zakJM1s/Y1jlnTNHwbuDsipuT7S5I6l9vcYzHSRMlI+jywAnBqRLwGDKfjCZTNrIebp9UBmFnNjgf+Kel7wELAjkXrtgIebElU1ipvA4VrwW4GvBYRj+b7Is2/Z2ZtyMmaWZuKiKslfYFUY/JIyRxadwMPtyYya5EbgOPzBd0PBy4rWrcq6eLuZtaGPHWH2VxAUh/StUK3j4jHWh2P1Z+khYA/AOsA/wMOiojJed0dwF0R8YvWRWhmtXKyZjYXkNSXdPmhtSPigVbHY60naS/gmoiY1OpYzKxzHmBgZjaXycn7ecCyrY7FzLrmZM3MbO6kVgdgZpVxsmZmZmbWgzlZMzMzM+vBnKyZmZmZ9WBO1szmDgE8D3zQ6kDMzKw6nhTXbC4QETPxyD8zs7bkZM2sjUh6jlRLVpGIWK6B4VgPImm1iHikkrIRMUPSd4HnGhyWmdWBkzWz9vIvZk/W9gAGALcAb5Au5r05MBW4pOnRWSs9JOl+4Fzg4oh4p7PCEXF+U6Iys27zFQzM2pSkI4EtgG0jYmrR8oHAtcDIiPh1q+Kz5pK0MfBdYBfSRduvIiVuI8Mf9GZtzcmaWZuS9DKwf0RcV2bddsDZEbFE8yOzVpK0ALA7sA+wIfAScD4wIiKeaWFoZlYjjwY1a1+DgM90sG5xYGATY7EeIiKmRsS5EbERsBIwATgSeFLSfyTt3NIAzaxqTtbM2tc1wG8lfUNSPwBJ/STtCpyS19tcSNIQScOAm4D1gOuB/YHXgUsl/aGF4ZlZldwMatamJC0EjAB2JA06mAIsSLrm49XA3hHxbssCtKaSNAD4Bqnf2v8jjfQ8l9T8+WpRue8Cf4yIQS0J1Myq5tGgZm0qJ2I7S1oZWIfU9PkaMCYiHm9pcNYKr5NaS/4NbBYRozsoNwZ4q1lBmVn3uWbNzKwXkHQgcJFrU816HydrZm0k16I9ExEf5P93yjVsZmbtz8maWRuRNBP4SkTcl//f0RtYQERE3+ZFZ60maUlgO+CzQP+S1RERv2h+VGbWXe6zZtZeNgEKtWVfo4pLT1nvlqfkuJg0Ie4bwIclRQJwsmbWhlyzZmbWC0h6AngK2Cci3m51PGZWP55nzaxNSbpd0oGSPt3qWKxH+BzwJydqZr2PkzWz9vU68DvgZUm3SNpX0iKtDspa5i7SFQvMrJdxM6hZG8vXgdwB2A3YijSwYCRwKXBlRExpYXjWYHki3ILlgH8ApwG3AO+Ulo+Iac2JzMzqycmaWS8haUFgZ1LithkwIyIWaG1U1khlRgQr/y37we7RwWbtyaNBzXqJiJgi6RnSZYYmA4NbHJI13r54RLBZr+eaNbM2J2ldYHdgV2Ap4DFSM+glEfFMK2MzM7Pu8wADszYl6RRJzwJ3A9sC5wGrRcTqEXGiE7W5i6RnJX2xg3Wr5nPFzNqQm0HN2teuwGWkGrT/tTgWa70hwHwdrBtAuqqBmbUhJ2tmbSoilmt1DNZakgYBCxctWlzS0iXF+gN7AC83Ky4zqy8na2ZtTNI8wNeBDYFPAW8DdwD/joiPWxmbNcUhwHGkQQYBXNFBOQE/a1ZQZlZfHmBg1qYkLQbcDKwOTCBNkvsZUnPYQ8AWEfFmq+KzxpP0eWBFUjJ2NfBzYHxJsQ+B8RHxQpPDM7M6cbJm1qYkXQh8Ffh6RNxXtHwd4F/AfyLiO62Kz5pL0leBBzwRslnv42TNrE1Jehv4UURcVGbdt4EzIuJTzY/MzMzqyX3WzNrXfEBHtShTgH5NjMVaQNKbVDEpbkQs1sBwzKxBnKyZta97gF9IGhURUwsL8/VCf5HXW+/2Z3wFA7Nez82gZm1K0hrAaGAmaaDB68BiwJakDucbR8RDrYrPzMzqw8maWRuTNJg0AnAdYAngVeBe4LSImNjK2MzMrD6crJm1qXxpoaUi4voy67YBXoqIh5sfmbWKpPWA75Gm8+hfuj4i1m16UGbWbb42qFn7+gPw5Q7WrZPX21xC0ubA7aTLSm0IvAm8B3wRWBR4tHXRmVl3OFkza19fAu7sYN3dwJpNjMVa73jgj8C2+f4xEfE1Ui3bR6T+jWbWhpysmbWvvsACHaxbAE/dMbdZGbiBNOAkyOdGRDwPDAOOallkZtYtTtbM2tcYYP8O1u0PjG1iLNZ604E+kToivwosX7RuMql51MzakOdZM2tfw4CRku4FzgdeI40I3YvUT2nz1oVmLfAQsBJwC3Ar8EtJL5OuDXo88EgLYzOzbvBoULM2Jmlj4CRgXdLcajNJU3ccERF3tC4ya7Y8AnjZiPizpKWAa4A18uqXgJ0j4v5WxWdmtXOyZtYLSBoALAJMiohprY7HWk+SgBWA+YFxEfFhi0Mysxo5WTMz62VyorYE8EZEfNzqeMysezzAwMysl5C0Te7DOB14EVg9Lz9b0p4tDc7MauZkzcysF5C0F3A1MI40GlhFq58kXdnAzNqQkzUzs97hKOC3EbE3cGHJusdI87CZWRtysmZm1jssQ5q2o5zpwKAmxmJmdeRkzcysd3iRji8xtjbwdBNjMbM6crJmZtY7/B04Lg8kmD8vk6RNgcOBs1sWmZl1i6fuMDPrBfJ0HWcCBwAzSFeo+Yh0Ddm/RcRBLQzPzLrByZqZWS8iaXlgU2Aw8DYwKiKebG1UZtYdTtbMzHoRSSuSLtrev3RdRFzf/IjMrLt8IXczs15A0srAJcAqzD7HWkGQmkTNrM04WTMz6x3+BswH7AI8DvhaoGa9hJtBzcx6AUnvAXtExLWtjsXM6stTd5iZ9Q7PUKafmpm1PydrZma9w8+AIyUt1+pAzKy+3AxqZtamJI0hDRwoWAZYBJgAvFNaPiLWbUpgZlZXHmBgZta+HmP2ZO2xVgViZo3jmjUzMzOzHsx91szMzMx6MCdrZmZmZj2YkzWzuZSkYZKi6PaKpH/la0s2ap/b5X0NyfeH5PvbVbGN3STtU8eYBuYYOtxmLXHmx42QNLbbQaZtjZZ0eT22ZWbtxQMMzOZu7wJb5f8vB5wA3CpplYiY2oT9vwqsB4yr4jG7kS5SPqIRAZmZ9TRO1szmbh9HxD35//dIegG4A9gG+GdpYUnzR8T79dp5RHwA3NNlQTOzuZibQc2s2P357xAASRMk/V7SMZJeAibn5X0kHSHpaUkfSHpS0t7FG1IyTNIbkqZIugAYVFKmbPOipP0kPSJpuqTXJV0uaSFJI4CvA18tar4dVvS4HSWNzY97TdKpkuYt2fbXc7zvS7odGFrLgZK0l6T/Snpb0iRJt0lau4OyO0kal+P6b77oevH6Lo+nmc29XLNmZsWG5L+vFS37Fmn+rh8y6zPjDGBv4HjgAWBz4FxJbxVdm/InwLHAb0i1dbsAp3YVgKSj83b/AhwGDAC2BQaSmmmXBhbO8QC8lB+3G3Ax6YLmRwLLAyeRfpT+PJf5EnApcAVwMLAqcFlXMXVgCHAB6TJP/YBvAnfkJuRni8otA5wGHAO8D/wKuEnS5yNiei5TyfE0s7lVRPjmm29z4Q0YBkwkJWDzACsCt5Fqz5bIZSaQ+pX1L3rcCsBMYO+S7V0AjMn/7wu8Avy1pMwtpElch+T7Q/L97fL9hYFpwGmdxH05MLpkmYDngfNKlu9LSpAWzfcvAx4nzzGZlx2VY9ink33OFmeZ9X3yMRwHHFu0fER+3PpFy5YBPgYOqPR45vujgctbfd745ptvzb+5GdRs7rYo8FG+jScNMtg9Il4tKnNrzKoBAtiUlFxcIWmewg24FVhDUl/gc8ASwFUl+/t3F/GsB8wPnFfl81iRVON2WUlMo0gXN181l1sXuDoiimcD7yqmsiR9QdIVkl4HZpCO4Uo5lmJvRMRdhTsR8Typublw6adKjqeZzcXcDGo2d3sX2IxU+/Ma8EpJIgPwesn9waSas3c72OYSwOL5/2+UrCu9X2rR/PfVTkvNaXD+e30H6z+X/y5eQ0xzkLQgcDPp2BxKqtWbDpxDSg672v4bpOMElR3Pl6qN0cx6DydrZnO3jyOiq3nASpO3t0nNeBuQaoRKvcGsz5bFStaV3i/1Vv67BKmJtlJv57/7Aw+WWf9c/vtaDTGVsx7wWWDziPhk2hFJC5UpW277izHrOp6VHE8zm4s5WTOzao0i1QQtFBG3lCsg6UVSYrQjcGPRql262PbdpD5me5MHBZTxIXPWXo0HXib1hTu7k+2PAXaQ9MuiGsSuYipn/vz3g8ICSeuT+rbdX1J2MUnrF5pCJS0NfIlZTb1dHk8zm7s5WTOzqkTEeElnAZdIOhUYS0qeVgFWjIjvR8SMvO53kiaSRoN+HfhCF9t+R9IJwImS+pGaNecjjQb9VUS8TOrEv6OknUjNg69ExCuSfgb8n6RBwA2kpG45YCfgGxExDTgFuJfUt+3vpL5s36vhMNwDvAecnZ/nZ0kDNl4uU3YicGEe5VoYDfoGeVLfSo5nDfGZWS/iAQZmVouDSNNo7EVKqEaQEqrbi8qcTpq24wDgX6SpNw7vasMRcRJwIKkv3VWkqTgWBqbkIn8h9Rc7l1RTtn9+3KWkmrw1SBP6/ps0vccDpMSN3OS7B7AmcCUpkdu9iuddiPF1YFdSH7irgJ/m5/l0meLPk2oJhwGX5OexZcmgjUqOp5nNpTRnX2IzMzMz6ylcs2ZmZmbWgzlZMzMzM+vBnKyZmZmZ9WBO1szMzMx6MCdrZnMxJUdKelHS+5Jul7RGBY8bISnK3IYWlekn6beS7sjbLjuaSdLmki6WNCFvY1gn+91F0pi8vbck3ShpgVqeey0kDctTkdRre0Pyc96uXttsFEnzSfq9pDckTZV0naQhVW7j4Px8Ly+zbnNJd0p6V9Lr+VJeK5WUGSTp9HyuTJP0hKSfSlIH+1sgn9shadVyZczagZM1s7nbEcAxpPnHtifNHTZS0uKdPioZR5rJv/g2oWj9AOD7pAuz31X64CJbAauTroU5raNCkr4PXESaQ23rvO2naO58kecAWzZxfz3Jn4B9SNOQfIN0maxbJJVOUFyWpMVI05e8WWbdWsB1pHnqdiVNubIc6VwcVFR0BLAnaUqY7YDLgdNIU6eUcxQwbyXxmfVknrrDrEEk9S+ZS6tHyV+yrwO/j4jj87IFSAnX3yLi6E4eOwJYNSLW7mIfioiQ9CPgjIiYowZEUp+ImJn/PxE4MyKGlZQZTLpk1KFdXKGgreSaqeeA7SPi2haH0yFJnyWdF/tGxAV52VKk2H8YEedUsI2/A/1I12mdGBHfKFp3MikR/GxEfJyXrQ48BGwTETdIGkCao+6nEXFG0WP/DSwVEV8u2d8KwP9IyeVfgdUi4tGaDoBZi7lmzdqWpPUkXS3p1dws8z9J3y5TbpnczDYxN508LOlbRevnl3SqpOclfSDpOUknFa0vJBvF25ytOUzSPrncupJGS3ofOCyvO1nSI5Lek/SSpH+Uq7mStF8uNz03A10uaSFJ20iaKWnZkvLL5uU71ngI1wcGAZcVFkTEVOAaUs1Vt5W5KHy5MuWuh1lqt/z3/O5FNFvT4x6SzpM0Ob8ue+b1h0t6RdKbkk6R1KfosaWv+7ySfifphXzuvJKb7/oVlen0/CsT316S/ivpbUmTJN0mae2SMqsoNQG/nc/9JyQdVLR+Q6Xm58n59j9Ju3bjsG2R//67sCBfTeK/VHCuSFqX9Boe0UGReYFphUQte6fw8Py3L+k7q/SC9+8UlSl2OqkmdFyZdWZtxcmatbNlgDtJlwvanjRL/nmSvlkokJte7gbWIf3C3h74O+nXPbmvy1WkGfP/DGwDHEdq4qnFxaRkZxugUFOyGKnZZltSc81ywKiSJOBo0kz9/yHNqn8g6UtpIHAT8ArpepnF9iFdtui6vI0+kubp4ta36PFDgRmkpsRiT+R1XVk5JwIf5OTiqxU8plZfJl3/83s5sfpI0r1K1+P8RE6mKm0uOAV4lXQZrDuA8yX9HlgX2Jf0ZX84sxLFcn4JfJvUlLw56fV9l5RYdHn+dWAIcAGpOfBbwIvAHZKWKypzDem12xPYATgDWDDvcxDp3Hs2P7dvAP9HugoEuUwt58pLEfFeSaxdniv5PXYGcGpO8Mq5EFhS0i8kLSLpc6TmzXGk5nEiYgrph8XhktaQtKBSX7/dSO/d4n1uC3yFdGkvs/YXEb751vY30i/reUgJz6ii5ScBU4ElOnjclkAAO3Sy7QB+VLJsGKkpp3B/n1zu4C7i7AsslctulJctTOqrdVonj/s1qcmp0HVBpGap35XEFF3cJhSVPwp4p8y+vp/L9usknoNJCeVXScnA3aRLOq3bQfkfkSvaujg+E4FhZZbfRGoCe5mUHG1FugD6ZOAzReWOBT7uYh9D8vM7r2jZIOAjUuLat2j5fcClnbzu15KakTvaV1fnXyGW7TpY3yef1+OAY/Oywfkxq3XwmLXz+gU7iWtEBefK6KLyZwP/6+C8fKWL471vPlfnz/dHA5eXKbcZMKlo/08AS5eUmY/UT61QZibwi5Iy/fLr+MN8f+NcdtWuzj/ffOupN1/I3dqWpEVIv5x3JCVAhZqA4l/vXwNujIhXO9jM14C3I+LqOoV1XZk4tybVvKxCSgoKViRd+3E9YH7gvE62ey5wJOmL5zZgE1LNYvFjhjOrNq8jH3SxviIR8cfi+5KuBx7LMe5Uj32UEKmWcdeIuDHv8y7SdTd/RDq+ROp7d3yF27y18J+ImCzpTeA/ETGjqMzTwNKdbON/wIGSXgduBB6JiOKava7OvzlI+gKpJnZ9Uq1swYr579uk2razJP0JuC0i3igq9wxpoMhFks7Jz+mdkt0MA87sIpQpXazvkqSFSAnrjyPi/U7KrUIaPPLv/HcBUpPp9ZLWj4jJuegfSLWs3yXVHG4IDJM0MSL+nsscCkwn/XAz6xWcrFk7G0Fq6jgBeJxUy3IgKXkrWJR0se+OLEpqCquX14vvSFoHuBq4AjiZ1GwZwD1AYRTdovlvh3FExLOSRpO+pG7Lf++LiMeKir2Wt9+Z4kRiEjBQUt+SBGURUv+hD7vYVnF803LCtn2lj6lSocZldNE+J0u6H1i5xm2+U3L/ww6WdTba8dek2p0fkppVX5b026JktqvzbzaSFiRdpP51UtLxPCnxOKcQR0TMlLQFcCIpiZ9f0p3ATyLiwYiYJGlzUkJ2GdBH0s2khOnZvKsXgJe6CKf0XFmoTJlF8rqOHJn3dbOkhfOyeYB58/0p+dw7AXgqIr5XdCzuyDF+HzhNacDBgcAWEXFLLnZ7Pma/k3Qe6XgfRarpXjC1wDIwl11Q0gKR+mWatRX3WbO2pDSScTvguIg4MyJGRcRY5jyn3wKW6GRTXa2HVBvVr2TZIh2ULe0vtTNpqoLdI+LqiLiHlFSVxkAFcZwDfF1pFN4uzFkTdyypKa+z2zNF5ceRaiNXKNnOUGrrlF1ommqEJ0i1a6UdyUVKlloiIqZHxLERMYRU83UpcLqkrXKRSs6vYusBnwX2jIh/RMR/83k9W6IUEeMi4uukJvTNSIncdYV+kBFxT0RsldfvkmO7qGgT59L1uXJrUflxwOc055x2XZ0rK5GaZScV3TYg9bOblJ9vYTv/K3mOk0jJ6vJFZSgtBzyYn+eipBr2gaSm0sL+rsnl7iL1TzVrO07WrF3NRzp/P2nWy7+wdygpdyuwpaTPdLCdW4FPqfNJSV8CvlC0nz7AphXGOT/wUUnTWOmI1buB95lzAEGpf5Nqei4hPfdLStYPJ3Vk7+xWXPN1F6k28pNRgkrTI2xPmsusYpLmJw2guL+ax1Wh0Ly7SdE+FwLWIk3v0HIR8RRpEMEHzKrt6+r8KzV//lt8Xq9P6ttWbp8fRcQoUmf8JSgaRJDXvx8R15CSs+IayGF0fa78oKj8zfnvzkVxLQn8Pzo/V44mvWbFt4dIzf+bAI/kcs8DaxY/UNKi+XlPKCoD8KWSfaxF6hc4kdRsXbq/Q3K5fYGfdRKrWY/lZlBrSxHxrqQxwLGSJpNqV44gjcQr7hf2B2Av0mi6E0l9fb4ALBARpwK3kDqvXyTpeOAB0pfeRhFR+LK6AjhI0oOkfjLfL9lHZ24BfirpdNIv/PVJI/iKn8s7kk4ATlSa8uF6UjK6LfCryCPoImK6pH8ABwEXl/ZDiohXSKNGK5K3dzJwjKRJpBqSQ0mJYPE8VnuRvuyXj4jnc5J0LWkE39OkDu+HAEtSlPjlx25N6n+0Rr5fmFtrTEQ8n5ctQ0oOINVgrpzLTY2IG3KsYyVdBfxd0hGkL+bDSTVAn4wEVLr6wXFRZj63RpB0BSlBfZCUcH+D9Ll6ey7S1flX6h5Sf7OzJZ1KqmUbRlE/zNwc+DtSLd6zpFreXwAPRcTbeSTkvsCVpCbIpUiJ16jCNiJiArNPYNypiHhJaZ600/PozjdzXM+TzoNCbMeSBkLMkx83x7xmkt4hDdIYXbT4LOBKpfn7LiadM78g/Tj5Ry4zNt/Ozft5jtRn7afAH/MPovcoairP+yv8d0y5eMzaQqtHOPjmW603UvPdraRf1S+QvryHUTRaL5dbhvTFNok06vIhYI+i9fOTvvxeItVoPAecWLR+IGl+r7dJTZhHkwY2lBsNOrBMnIeTvqSnAiOBz1N+hOkPSH3vPsj7uQwYVFJms/zYzep0DEXq4/MSKdm4A1izpEzhuQ3J9/uTavlezLG+S+pc/5Uy259A+ZGG+5TZfocjV4teh7+Smhbfz8dytZIypwJvdPGch1BmBCYlo2vzshHA2KL7s51fpLn0xuZjMAW4F9ix0vOvXCykka6P5uf4MGkamNHkEZSkQQf/R0rUpudz5WLyyElS0+PlRa/PS6Rk6FPdPFfmI9XgvUk6l68Hli0pM4wuRv3S8WjQ3Uj9+yaT+l5eD6xRUmZxUneA5/OxfII0fUpnI5c3xqNBfWvzm69gYNZGcm3LbsByUdlksnMVSf8hTd3i+bXMrNdwM6hZG1C6oPXKpNFwv3KiNidJ8wCrkpoizcx6DdesmbWBPG3Hl0nTgHwnqphWw8zM2puTNTMzM7MezFN3mJmZmfVgTtbMzMzMejAna2ZmZmY9mJM1MzMzsx7MyZqZmZlZD+ZkzczMzKwH+//Smv6CM/ZU0QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 24ms/step\n",
      "22/22 [==============================] - 1s 31ms/step\n",
      "\n",
      "Quanv Train Accuracy: 0.57\n",
      "\n",
      "\n",
      "Quanv Valid Accuracy: 0.59\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if ql4 == 1:\n",
    "    modelq=modelq4 \n",
    "    y_pred=modelq.predict(q_valid4)\n",
    "    y_pred1 = (y_pred > 0.5) \n",
    "    y_pred=modelq.predict(q_train4)\n",
    "    y_pred2 = (y_pred > 0.5) \n",
    "\n",
    "    y_pred=np.argmax(y_pred1, axis=1)\n",
    "    print('\\nQuanv Train Accuracy: {:.2f}\\n'.format(accuracy_score(y_train, y_pred2)))\n",
    "    print('\\nQuanv Valid Accuracy: {:.2f}\\n'.format(accuracy_score(y_valid, y_pred1)))\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "    plot_confusion_matrix(cm , \n",
    "                          normalize    = False,\n",
    "                          target_names = labels,\n",
    "                          title        = \"Quanv 2 qubits Depolarizing Circuit with p=0.001 Confusion Matrix\")\n",
    "    \n",
    "    modelq=keras.models.load_model('checkpoints/best_quanv_demo24.hdf5') \n",
    "    y_pred=modelq.predict(q_valid4)\n",
    "    y_pred1 = (y_pred > 0.5) \n",
    "    y_pred=modelq.predict(q_train4)\n",
    "    y_pred2 = (y_pred > 0.5) \n",
    "\n",
    "    y_pred=np.argmax(y_pred1, axis=1)\n",
    "    print('\\nQuanv Train Accuracy: {:.2f}\\n'.format(accuracy_score(y_train, y_pred2)))\n",
    "    print('\\nQuanv Valid Accuracy: {:.2f}\\n'.format(accuracy_score(y_valid, y_pred1)))\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "    plot_confusion_matrix(cm , \n",
    "                          normalize    = False,\n",
    "                          target_names = labels,\n",
    "                          title        = \"Best Quanv 2 qubits Depolarizing Circuit with p=0.2 Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6896c855",
   "metadata": {
    "id": "6896c855"
   },
   "outputs": [],
   "source": [
    "plot_acc_loss(q_history1, q_history2, q_history3, q_history4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b39664",
   "metadata": {
    "id": "21b39664"
   },
   "outputs": [],
   "source": [
    "def to_rgb2(heatmap, h_x, w_x):\n",
    "    heatmap = np.uint8(255 * vis_map(np.rot90(heatmap[0])))\n",
    "    # We use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # We use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[np.rot90(np.transpose(heatmap))]\n",
    "\n",
    "    # We create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "\n",
    "    jet_heatmap = jet_heatmap.resize((  h_x, w_x))\n",
    "\n",
    "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    save_path = \"images/color_cam.jpg\"\n",
    "    superimposed_img = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    superimposed_img.save(save_path)\n",
    "\n",
    "    cam_img= mpimg.imread(save_path)\n",
    "\n",
    "    return cam_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf465bfb",
   "metadata": {
    "id": "bf465bfb"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.image as mpimg\n",
    "def layer_output(in_feats, model, ly_name = \"batch_normalization_6 \", k= idx):\n",
    "    conv_layer = model.get_layer(ly_name)\n",
    "    heatmap_model = models.Model([model.inputs], [conv_layer.output, model.output])\n",
    "\n",
    "    with tf.GradientTape() as gtape:\n",
    "        conv_output, predictions = heatmap_model(in_feats[k:k+1])\n",
    "        loss = predictions[:, np.argmax(predictions[0])]\n",
    "        grads = gtape.gradient(loss, conv_output)\n",
    "        pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)\n",
    "    return heatmap, conv_output, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79439853",
   "metadata": {
    "id": "79439853"
   },
   "outputs": [],
   "source": [
    "def vis_map(heatmap):\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    max_heat = np.max(heatmap)\n",
    "    if max_heat == 0:\n",
    "        max_heat = 1e-10\n",
    "    heatmap /= max_heat\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf2abc",
   "metadata": {
    "id": "5abf2abc"
   },
   "outputs": [],
   "source": [
    "idx = 40\n",
    "w_x, h_x = x_train[idx,:,:,0].shape\n",
    "\n",
    "#q_heatmap, q_covout, q_predict = layer_output(q_train1, modelq, \"ConvDown2\",k=idx)\n",
    "#q_cam = to_rgb2(q_heatmap, h_x, w_x)\n",
    "\n",
    "x_heatmap, x_covout, x_predict= layer_output(x_train, modelx, \"ConvDown2\",k=idx)\n",
    "x_cam = to_rgb2(x_heatmap, h_x, w_x)\n",
    "\n",
    "c_heatmap, c_covout, c_predict = layer_output(x_train, modelc, \"ConvDown2\",k=idx)\n",
    "c_cam = to_rgb2(c_heatmap, h_x, w_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39403b05",
   "metadata": {
    "id": "39403b05"
   },
   "outputs": [],
   "source": [
    "a = 12\n",
    "plt.figure()\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(librosa.power_to_db(x_train[idx,:,:,0], ref=np.max))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('(a) Input Mel-Spectrogram', fontsize=a)\n",
    "# plt.matshow(np.transpose(vis_map(x_train[idx,:,:,0])))\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(q_cam)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('(b) Quanv + RNN', fontsize=a)\n",
    "plt.subplot(2 ,2, 3)\n",
    "plt.imshow(x_cam)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('(c) Conv + RNN', fontsize=a)\n",
    "plt.subplot(2 ,2, 4)\n",
    "plt.imshow(c_cam)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('(d) Baseline RNN', fontsize=a)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/cam_sp_\"+str(idx)+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5cd09c",
   "metadata": {
    "id": "8b5cd09c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "4x1quantum_pre.ipynb",
   "provenance": [
    {
     "file_id": "1R46qEL-i8CwabOiXxnN4X0DA64X8rcxT",
     "timestamp": 1651800300688
    },
    {
     "file_id": "1Lycj9cnRmpR4w-ajcFKLP6R-IDlgee2g",
     "timestamp": 1651756394790
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
