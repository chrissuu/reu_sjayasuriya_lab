{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81a704c4-3e6f-4a36-900e-074fee9bf9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "983787cb-6f09-4a86-b514-5b553fef5aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset_path = '~/Desktop/research_data/SARscope/train_data'\n",
    "test_dataset_path = '~/Desktop/research_data/SARscope/test_data'\n",
    "\n",
    "dataset_train = ImageFolder(root = train_dataset_path, transform = transform)\n",
    "dataset_test = ImageFolder(root = test_dataset_path, transform = transform)\n",
    "\n",
    "batch_size = 32\n",
    "dataloader_train = DataLoader(dataset_train, batch_size = batch_size, shuffle = True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size = batch_size, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "569e5977-c977-41ff-849e-2204b8a0a891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([3, 640, 640])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"shape: \", dataset_train[0][0].shape)\n",
    "len(dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df864e2e-cf6e-4b62-9470-cdc5db050f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15ff645d-6181-4cf3-8c69-bc13e65bfb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train[0][0][1].sum() == dataset_train[0][0][0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45df016f-9241-4e76-ad4b-c7c6425bf9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "affb5527-17e8-4b23-86be-2d71757900f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    _relu = nn.ReLU()\n",
    "    \n",
    "    return _relu(x)\n",
    "\n",
    "def curly_N(v):\n",
    "    v_min, v_max = v.min(), v.max()\n",
    "    new_min, new_max = -.25, .25\n",
    "    v_p = (v - v_min)/(v_max - v_min)*(new_max - new_min) + new_min\n",
    "    return v_p\n",
    "\n",
    "def curly_Nprime(v):\n",
    "    v_min, v_max = v.min(), v.max()\n",
    "    new_min, new_max = -.25, .25\n",
    "    v_pw = (v - v_min + 1)/(v_max - v_min + 2)*(new_max - new_min) + new_min\n",
    "    return v_pw\n",
    "    # return (w - np.min(w) + 1) / (np.max(w) - np.min(w) + 2)\n",
    "\n",
    "def f_VHN(x, w):\n",
    "    relu_x = relu(curly_N(x))\n",
    "    relu_w = relu(curly_Nprime(w))\n",
    "    \n",
    "    return torch.mul(relu_x, relu_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f1ede58-c50a-4c83-a501-d89291a64b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyLinearLayer(nn.Module):\n",
    "#     \"\"\" Custom Linear layer but mimics a standard linear layer \"\"\"\n",
    "#     def __init__(self, size_in, size_out):\n",
    "#         super().__init__()\n",
    "#         self.size_in, self.size_out = size_in, size_out\n",
    "#         weights = torch.Tensor(size_out, size_in)\n",
    "#         self.weights = nn.Parameter(weights)  # nn.Parameter is a Tensor that's a module parameter.\n",
    "#         bias = torch.Tensor(size_out)\n",
    "#         self.bias = nn.Parameter(bias)\n",
    "\n",
    "#         # initialize weights and biases\n",
    "#         nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5)) # weight init\n",
    "#         fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weights)\n",
    "#         bound = 1 / math.sqrt(fan_in)\n",
    "#         nn.init.uniform_(self.bias, -bound, bound)  # bias init\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         w_times_x= torch.mm(x, self.weights.t())\n",
    "#         return torch.add(w_times_x, self.bias)  # w times x + b\n",
    "        \n",
    "class VHNLayer(nn.Module):\n",
    "    \"\"\" Custom VHN layer \"\"\"\n",
    "    def __init__(self, channels, img_len, img_width):\n",
    "        super().__init__()\n",
    "        self.channels, self.img_len, self.img_width = channels, img_len, img_width\n",
    "        weights = torch.Tensor(channels, img_len, img_width)\n",
    "        self.weights = nn.Parameter(weights)  # nn.Parameter is a Tensor that's a module parameter.\n",
    "\n",
    "        # initialize weights and biases\n",
    "        nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5)) # weight init\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return f_VHN(x, self.weights) # w times x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57f8a629-c06d-48b1-aa1c-83159d66fa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vhn1 = VHNLayer(3, 640, 640)\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 5)\n",
    "        self.pool = nn.MaxPool2d(3, 3)\n",
    "        self.fc1 = nn.Linear(28224, 8000)\n",
    "        self.fc2 = nn.Linear(8000, 84)\n",
    "        self.fc3 = nn.Linear(84, 16)\n",
    "        self.fc4 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vhn1(x)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.sigmoid(self.fc4(x))\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = ConvNet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f5c0db0-03ef-4de8-8177-3a63cd651638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aa815e0-186f-436e-b789-e9b427c2d402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    print(epoch)\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        if i != 147:\n",
    "            inputs, labels = data\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels.reshape(32,1).type(torch.float32))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            print(i)\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c9492b-0df1-48af-b010-00efd1b8a0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in dataloader_test:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        print((predicted == labels).sum())\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        print(\n",
    "print(f'Accuracy of the network on the test images: {100 * correct // total} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7821da-71c9-431c-acf5-36e2369d5957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a3d72-64c7-4132-835d-abbcd871a1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
