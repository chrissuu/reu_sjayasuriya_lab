{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81a704c4-3e6f-4a36-900e-074fee9bf9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "983787cb-6f09-4a86-b514-5b553fef5aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    # rgb to grayscale transform \n",
    "    # transform. normalization\n",
    "    # transform. resize / rescale\n",
    "    transforms.ToTensor()\n",
    "\n",
    "])\n",
    "\n",
    "train_dataset_path = '~/Desktop/research_data/SARscope/train_data'\n",
    "test_dataset_path = '~/Desktop/research_data/SARscope/test_data'\n",
    "\n",
    "dataset_train = ImageFolder(root = train_dataset_path, transform = transform)\n",
    "dataset_test = ImageFolder(root = test_dataset_path, transform = transform)\n",
    "\n",
    "batch_size = 32\n",
    "dataloader_train = DataLoader(dataset_train, batch_size = batch_size, shuffle = False)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "for i, data in enumerate(dataloader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data\n",
    "    print(labels.sum() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "569e5977-c977-41ff-849e-2204b8a0a891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([3, 640, 640])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"shape: \", dataset_train[0][0].shape)\n",
    "len(dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df864e2e-cf6e-4b62-9470-cdc5db050f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15ff645d-6181-4cf3-8c69-bc13e65bfb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train[0][0][1].sum() == dataset_train[0][0][0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45df016f-9241-4e76-ad4b-c7c6425bf9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "affb5527-17e8-4b23-86be-2d71757900f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    _relu = nn.ReLU()\n",
    "    \n",
    "    return _relu(x)\n",
    "# change to global min / max\n",
    "def curly_N(w):\n",
    "    w_min, w_max = torch.min(torch.min(torch.min(w))), torch.max(torch.max(torch.max(w)))\n",
    "    reg_N = (w - w_min) / (w_max - w_min)\n",
    "    return v_p\n",
    "\n",
    "def curly_Nprime(w):\n",
    "    w_min, w_max = torch.min(torch.min(torch.min(w))), torch.max(torch.max(torch.max(w)))\n",
    "    curly_N = (w - w_min + 1) / (w_max - w_min + 2)\n",
    "    return curly_N\n",
    "    # return (w - np.min(w) + 1) / (np.max(w) - np.min(w) + 2)\n",
    "\n",
    "def f_VHN(x, w):\n",
    "    relu_x = relu(curly_N(x))\n",
    "    relu_w = relu(curly_Nprime(w))\n",
    "    \n",
    "    return relu_x * relu_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f1ede58-c50a-4c83-a501-d89291a64b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyLinearLayer(nn.Module):\n",
    "#     \"\"\" Custom Linear layer but mimics a standard linear layer \"\"\"\n",
    "#     def __init__(self, size_in, size_out):\n",
    "#         super().__init__()\n",
    "#         self.size_in, self.size_out = size_in, size_out\n",
    "#         weights = torch.Tensor(size_out, size_in)\n",
    "#         self.weights = nn.Parameter(weights)  # nn.Parameter is a Tensor that's a module parameter.\n",
    "#         bias = torch.Tensor(size_out)\n",
    "#         self.bias = nn.Parameter(bias)\n",
    "\n",
    "#         # initialize weights and biases\n",
    "#         nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5)) # weight init\n",
    "#         fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weights)\n",
    "#         bound = 1 / math.sqrt(fan_in)\n",
    "#         nn.init.uniform_(self.bias, -bound, bound)  # bias init\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         w_times_x= torch.mm(x, self.weights.t())\n",
    "#         return torch.add(w_times_x, self.bias)  # w times x + b\n",
    "        \n",
    "class VHNLayer(nn.Module):\n",
    "    \"\"\" Custom VHN layer \"\"\"\n",
    "    def __init__(self, channels, img_len, img_width):\n",
    "        super().__init__()\n",
    "        self.channels, self.img_len, self.img_width = channels, img_len, img_width\n",
    "        weights = torch.Tensor(channels, img_len, img_width)\n",
    "        self.weights = nn.Parameter(weights)  # nn.Parameter is a Tensor that's a module parameter.\n",
    "\n",
    "        # initialize weights and biases\n",
    "        nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5)) # weight init\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return f_VHN(x, self.weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57f8a629-c06d-48b1-aa1c-83159d66fa6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m---> 31\u001b[0m net \u001b[38;5;241m=\u001b[39m ConvNet()\n",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m, in \u001b[0;36mConvNet.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvhn1 \u001b[38;5;241m=\u001b[39m VHNLayer(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m640\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv2d(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMaxPool2d(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m, in \u001b[0;36mVHNLayer.__init__\u001b[0;34m(self, channels, img_len, img_width)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_width \u001b[38;5;241m=\u001b[39m channels, img_len, img_width\n\u001b[0;32m---> 26\u001b[0m weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(channels, img_len, img_width)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mParameter(weights)  \u001b[38;5;66;03m# nn.Parameter is a Tensor that's a module parameter.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# initialize weights and biases\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vhn1 = VHNLayer(3, 640, 640)\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 5)\n",
    "        self.pool = nn.MaxPool2d(3, 3)\n",
    "        self.fc1 = nn.Linear(28224, 8000)\n",
    "        self.fc2 = nn.Linear(8000, 84)\n",
    "        self.fc3 = nn.Linear(84, 16)\n",
    "        self.fc4 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vhn1(x)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.sigmoid(self.fc4(x))\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = ConvNet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5c0db0-03ef-4de8-8177-3a63cd651638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "criterion2 = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aa815e0-186f-436e-b789-e9b427c2d402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataloader_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(epoch)\n\u001b[1;32m      3\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader_train, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# get the inputs; data is a list of [inputs, labels]\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# zero the parameter gradients\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader_train' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    print(epoch)\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss1 = criterion(outputs, labels.reshape(32,1).type(torch.float32))\n",
    "        loss2 = criterion2(net.vhn1.weights, labels.reshape(32,1).type(torch.float32))\n",
    "\n",
    "        loss = loss1 + loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        print(i)\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39c9492b-0df1-48af-b010-00efd1b8a0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "tensor(32)\n",
      "Accuracy of the network on the test images: 100 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in dataloader_test:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        print((predicted == labels).sum())\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "print(f'Accuracy of the network on the test images: {100 * correct // total} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7821da-71c9-431c-acf5-36e2369d5957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a3d72-64c7-4132-835d-abbcd871a1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
