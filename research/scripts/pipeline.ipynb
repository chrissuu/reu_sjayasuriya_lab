{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bee53e3e-2ce6-4b23-9bc3-34ff2a2a0a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import torcheval\n",
    "from torcheval.metrics.functional import binary_auprc\n",
    "import matplotlib.pyplot as plt\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.templates import RandomLayers\n",
    "\n",
    "def generate_generators(data_root, hdf_data_path,BZ,IR,\n",
    "                        label_scheme='label'):\n",
    "    \"\"\"\n",
    "    Gathers all files and organize into train/validation/test. Each\n",
    "       data subset is further organized by class. Converts file lists\n",
    "       into iterable data generators.\n",
    "    Inputs:\n",
    "        * data_root: full path to the data root containing subdirectories of data\n",
    "        * trn_list, val_list, tst_list: each is a list of strings. The strings\n",
    "            should encode the strata being used to divide data into segments and\n",
    "            must match the corresponding field of the FileName class.\n",
    "        * hdf_data_path: the path used internally in the HDF to get the desired surface\n",
    "        * batch_size: the _approximate_ number of samples to be used __next__ call. Note\n",
    "              that if batch_size // n_classes is non-integer then it may be slightly off.\n",
    "        * label_scheme: a string that matches the name of the property of the FileName\n",
    "              class that you want to use as the label.\n",
    "        * strata_scheme: a string that matches the name of the property of the FileName\n",
    "              class that you want to compare against trn_list (etc.) for data segmentation.\n",
    "    \"\"\"\n",
    "    n_classes = 2\n",
    "    tst_files = [[] for clas in range(n_classes)]\n",
    "    trn_files = [[] for clas in range(n_classes)]\n",
    "\n",
    "    \n",
    "    #print('Allocating HDFs to train/valid/test...')\n",
    "    for filename in os.listdir(data_root):\n",
    "        if not filename.endswith('.hdf'):\n",
    "            continue\n",
    "\n",
    "        # Extract the label using 'label_scheme' identifier\n",
    "        label = int(int(filename.split('_')[3]) > 0)  # 0 = clutter (not manmade); 1 = target (manmade)\n",
    "\n",
    "        # list that stores files in two sub-lists\n",
    "        randr = random.randrange(0,5)\n",
    "        if randr < 1:\n",
    "            \n",
    "            tst_files[label].append(filename)\n",
    "\n",
    "        else:\n",
    "\n",
    "            trn_files[label].append(filename)\n",
    "\n",
    "    # Wrap each file list into an iterable data generator that actually\n",
    "    #     read the HDFs when __next__ is called:\n",
    "    \n",
    "    trn_gen = DataGenerator(data_root, trn_files, hdf_data_path,  BZ, IR)\n",
    "    tst_gen = DataGenerator(data_root, tst_files, hdf_data_path, BZ, IR)\n",
    "    length = len(trn_files[0] + trn_files[1]) #+ len(trn_files[1])\n",
    "\n",
    "    return trn_gen, tst_gen\n",
    "\n",
    "\n",
    "class DataGenerator:\n",
    "    def __init__(self, data_root, file_list, hdf_data_path, BZ, IR, n_classes=2):\n",
    "        # Basic properties:\n",
    "        self.data_root = data_root\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        \"balance by class\"\n",
    "        self.hdf_path = hdf_data_path\n",
    "\n",
    "        self._permanent_file_list = file_list\n",
    "        # print(len(file_list[0]), \"\\n\")\n",
    "        \"for august-november split\"\n",
    "        # self.target_list = file_list[1][0:4\n",
    "        \"for fulll dataset\"\n",
    "        self.target_list = file_list[1]\n",
    "        self.target_len = len(self.target_list)\n",
    "        # print(self.target_len, 'length of target')\n",
    "        \n",
    "        \"test\"\n",
    "\n",
    "        #self.clutter_list = file_list[0]\n",
    "        self.clutter_list = file_list[0][0:int(IR*self.target_len)]\n",
    "\n",
    "        #self.clutter_list = file_list[0][0:16799]\n",
    "        self.clutter_len = len(self.clutter_list)\n",
    "        # print(self.clutter_len, 'length of clutter')\n",
    "\n",
    "        self.dataset_size = self.clutter_len + self.target_len\n",
    "        self.batch_size = BZ\n",
    "        self.bsz_by_class = int(self.batch_size / self.n_classes)\n",
    "\n",
    "        if self.batch_size % 2 != 0 or self.bsz_by_class % 2 != 0:\n",
    "            print('batch size is odd or not balanced... \\nadding one to batch size')\n",
    "            self.batch_size = self.batch_size  + 1\n",
    "            self.bsz_by_class = math.floor(self.batch_size / self.n_classes)\n",
    "\n",
    "        n = 1\n",
    "        while n < 6:\n",
    "            if  self.bsz_by_class % 2 != 0:\n",
    "                print('batch size is not balanced... \\nadding one to batch size')\n",
    "                self.batch_size = self.batch_size  + 1\n",
    "                self.bsz_by_class = math.floor(self.batch_size / self.n_classes)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "        # print(self.batch_size, 'batch_size')\n",
    "        # print(self.bsz_by_class, 'balance size')\n",
    "\n",
    "        #self.current_index = [i for i in range(self.batch_size)]\n",
    "\n",
    "\n",
    "        #self.current_index = [0 for label in range(self.n_classes)]\n",
    "\n",
    "        self.HDF_n_rows = 71\n",
    "        self.HDF_n_cols = 71\n",
    "        self.HDF_n_dpth = 101\n",
    "\n",
    "        self.input_shape = (self.batch_size, self.HDF_n_rows, self.HDF_n_cols, self.HDF_n_dpth)\n",
    "\n",
    "        self.chip_n_rows = 64\n",
    "        self.chip_n_cols = 64\n",
    "        self.chip_n_dpth = 101\n",
    "\n",
    "        \"chip shape is one cube from batch\"\n",
    "        self.chip_shape = (self.chip_n_rows, self.chip_n_cols, self.chip_n_dpth)\n",
    "\n",
    "        self.batch_shape = (self.batch_size, self.chip_n_rows, self.chip_n_cols, self.chip_n_dpth)\n",
    "\n",
    "\n",
    "        # Make a boolean indexing mask for efficient extraction of the chip center:\n",
    "        \"input shape minus chip shape row\"\n",
    "        row_diff = self.input_shape[1] - self.chip_shape[0]\n",
    "        \"this is chopping off one half the difference on each side\"\n",
    "        first_row = row_diff // 2\n",
    "        last_row = first_row + self.chip_shape[0]\n",
    "\n",
    "        \"this is chopping off one half the difference on each side\"\n",
    "        col_diff = self.input_shape[2] - self.chip_shape[1]\n",
    "        first_col = col_diff // 2\n",
    "        last_col = first_col + self.chip_shape[1]\n",
    "\n",
    "        \"this is chopping off one half the difference on each side\"\n",
    "        slice_diff = self.input_shape[3] - self.chip_shape[2]\n",
    "        first_slice = slice_diff // 2\n",
    "        last_slice = first_slice + self.chip_shape[2]\n",
    "\n",
    "        \"slicing out the chips from the input data\"\n",
    "        \"list with shape of input all False values\"\n",
    "        self.center_select = np.full((self.HDF_n_rows, self.HDF_n_cols, self.HDF_n_dpth), False)\n",
    "        \"except the chips size all true\"\n",
    "        self.center_select[first_row:last_row, first_col:last_col, first_slice:last_slice] = True\n",
    "\n",
    "        # self.first_slice = 0\n",
    "        # self.last_slice = self.bsz_by_class\n",
    "\n",
    "\n",
    "    def readHDF(self, file_name):\n",
    "        \"\"\" Reads data from the HDF\"\"\"\n",
    "        with h5py.File(os.path.join(self.data_root, file_name), mode='r') as f:\n",
    "            data = f[self.hdf_path][:]\n",
    "            data = np.transpose(data)  # because python reverses the order of the 3d volume, this will correct back to the original matlab order\n",
    "            #data = data / 40  # Now data is in [0,1], to match the 2d sensors\n",
    "\n",
    "\n",
    "        return data\n",
    "\n",
    "    def chip_center(self, data):\n",
    "        \"\"\" extracts the center of the chip via boolean indexing. \"\"\"\n",
    "        return np.reshape(data[self.center_select], self.chip_shape)\n",
    "\n",
    "\n",
    "    def preprocess(self, data_sample):\n",
    "        \"\"\"\n",
    "        Preprocesses a data sample.\n",
    "        TODO: use configuration file and preprocesser class like ADAM dataloader here.\n",
    "        \"\"\"\n",
    "        # TODO: sometimes want to jiggle the chip instead of centering so will\n",
    "        #          need to remove chip_center from here.\n",
    "\n",
    "        \"centering x cube\"\n",
    "        x_center = self.chip_center(data_sample)\n",
    "        return x_center\n",
    "\n",
    "    def perm_target_list(self, target_list):\n",
    "        if self.last_slice % self.target_len == 0:\n",
    "            print('target list permuted')\n",
    "            return np.random.permutation(target_list)\n",
    "        else:\n",
    "            return target_list\n",
    "        #return np.random.permutation(target_list)\n",
    "\n",
    "    def reset_list(self, target_list):\n",
    "\n",
    "        # Come up with a way to reset_list\n",
    "\n",
    "\n",
    "            return target_list\n",
    "\n",
    "    def data_loop(self, list_data):\n",
    "\n",
    "        \"place holder for batch of data\"\n",
    "        batch_data = np.zeros(self.batch_shape, dtype='float32')\n",
    "        \"batch labels\"\n",
    "        batch_label = np.zeros(self.batch_size)\n",
    "\n",
    "        for label in range(0, self.n_classes):\n",
    "            for nth_sample in range(0, self.bsz_by_class):\n",
    "\n",
    "                ld = list_data[label]\n",
    "                sample = ld[nth_sample]\n",
    "\n",
    "                data = self.readHDF(sample)\n",
    "\n",
    "                # Preprocessing can go here, e.g. random flips/translations/normalizations\n",
    "                \"centers the data here\"\n",
    "                data = self.preprocess(data)\n",
    "\n",
    "                # Insert the data into the batch_data and batch_label arrays:\n",
    "                batch_idx = self.bsz_by_class * label + nth_sample\n",
    "                \"batch data: why just rows and columns\"\n",
    "                batch_data[batch_idx][:, :, :] = np.reshape(data, self.chip_shape)\n",
    "                \"batch label\"\n",
    "                batch_label[batch_idx] = label\n",
    "\n",
    "        return batch_data, batch_label\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.first_slice = 0\n",
    "        self.last_slice = self.bsz_by_class\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum([len(label_set) for label_set in self.target_list])\n",
    "\n",
    "    def __next__(self):\n",
    "\n",
    "\n",
    "        # Put `bsz_by_class' samples from each class into `batch_data':\n",
    "\n",
    "        # for n in range(self.bsz_by_class, self.target_len, self.bsz_by_class):\n",
    "\n",
    "\n",
    "        if self.last_slice <= self.clutter_len:\n",
    "            #print(self.last_slice, 'last slice')\n",
    "\n",
    "            if self.last_slice > self.target_len:\n",
    "                tlp = self.perm_target_list(self.target_list)\n",
    "                tl = self.reset_list(tlp)\n",
    "\n",
    "                cl = self.clutter_list[self.first_slice:self.last_slice]\n",
    "\n",
    "                list_data = [cl, tl]\n",
    "\n",
    "                batch_data, batch_label = self.data_loop(list_data)\n",
    "\n",
    "            elif self.last_slice <= self.target_len :\n",
    "                tl = self.target_list[self.first_slice:self.last_slice]\n",
    "                cl = self.clutter_list[self.first_slice:self.last_slice]\n",
    "\n",
    "\n",
    "                list_data = [cl, tl]\n",
    "\n",
    "\n",
    "                batch_data, batch_label = self.data_loop(list_data)\n",
    "\n",
    "        else:\n",
    "            print('next epoch')\n",
    "            raise StopIteration\n",
    "\n",
    "        self.first_slice += 1\n",
    "        self.last_slice += 1\n",
    "        return batch_data, batch_label\n",
    "        # , self.bsz_by_class, self.clutter_len, self.target_len, self.batch_size\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d6e135c-556d-4d71-831a-b7394dcc7be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    _relu = nn.ReLU()\n",
    "    \n",
    "    return _relu(x)\n",
    "# change to global min / max\n",
    "def curly_N(w):\n",
    "    w_min, w_max = torch.min(torch.min(torch.min(w))), torch.max(torch.max(torch.max(w)))\n",
    "    reg_N = (w - w_min) / (w_max - w_min)\n",
    "    return reg_N\n",
    "\n",
    "def curly_Nprime(w):\n",
    "    w_min, w_max = torch.min(torch.min(torch.min(w))), torch.max(torch.max(torch.max(w)))\n",
    "    curly_N = (w - w_min + 1) / (w_max - w_min + 2)\n",
    "    return curly_N\n",
    "    # return (w - torch.min(w) + 1) / (torch.max(w) - torch.min(w) + 2)\n",
    "\n",
    "def f_VHN(x, w):\n",
    "    relu_x = relu(curly_N(x))\n",
    "    relu_w = relu(curly_Nprime(w))\n",
    "    \n",
    "    return relu_x * relu_w\n",
    "    \n",
    "class VHNLayer(nn.Module):\n",
    "    \"\"\" Custom VHN layer \"\"\"\n",
    "    def __init__(self, channels, img_len, img_width):\n",
    "        super().__init__()\n",
    "        self.channels, self.img_len, self.img_width = channels, img_len, img_width\n",
    "        weights = torch.Tensor(channels, img_len, img_width)\n",
    "        self.weights = nn.Parameter(weights)  # nn.Parameter is a Tensor that's a module parameter.\n",
    "\n",
    "        # initialize weights and biases\n",
    "        nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5)) # weight init\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return f_VHN(x, self.weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2f9c03f-1b56-4a4e-9bc0-a40df78e8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from load_data import device\n",
    "\"fix dimensions\"\n",
    "\"may need \"\n",
    "\n",
    "# from colormap import *\n",
    "\n",
    "\n",
    "class ATR(nn.Module):\n",
    "    def __init__(self, nc, device = None, N_filters=4, N_output = 1, ker = 4, s = 2, pad =1):\n",
    "        super(ATR, self).__init__()\n",
    "        self.ker = ker\n",
    "        self.s = s\n",
    "        self.pad = pad\n",
    "        self.nc = nc\n",
    "        # self.device = device\n",
    "        self.N_filters = N_filters\n",
    "        self.N_output = N_output\n",
    "        self.vhn = VHNLayer(101, 64, 64)\n",
    "        self.conv1 = nn.Conv3d(nc, N_filters, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.conv2 = nn.Conv3d(N_filters, N_filters, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.conv3 = nn.Conv3d(N_filters, N_filters, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.conv4 = nn.Conv3d(N_filters, 1, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.avgpool = nn.AvgPool3d(kernel_size = (6, 2, 2), stride= (1, 1, 1), padding= (0, 0, 0))\n",
    "    \n",
    "\n",
    "        # \"columns input x and output columnes\"\n",
    "\n",
    "        self.f2 = nn.Linear(1248,1)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x0):\n",
    "        \"image vectorization\"\n",
    "        # print(x0.shape)\n",
    "        x0 = self.vhn.forward(x0)\n",
    "        x = self.conv1(x0.unsqueeze(1))\n",
    "        x = self.avgpool(F.relu(x))\n",
    "        x = self.conv2(x)\n",
    "        x = self.avgpool(F.relu(x))\n",
    "        x = self.conv3(x)\n",
    "        x = self.avgpool(F.relu(x))\n",
    "        x = self.conv4(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "\n",
    "        x = self.f2(x)\n",
    "\n",
    "        y = self.sigmoid(x)\n",
    "\n",
    "        return y\n",
    "\n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2205becb-221e-46d0-a01a-dfc301b8506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ATR(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6b5e92e-1c13-48da-be4f-6722fc586f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac5ef9b3-faae-4ec7-99e6-8fdf56c303cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be18efb3-1940-4f57-9122-576a26dde859",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../research_data/sas_nov_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7124b66-b2c2-4d7f-b64d-64fef384d5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dldr_trn, dldr_tst = generate_generators(data_root = path , hdf_data_path = 'DL_info/chip_info/cube_raw',BZ = 20, IR = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20745286-1e42-4fc4-ad2b-d1f4fa8f949a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "[1,     5] loss: 0.737\n",
      "[1,    10] loss: 0.736\n",
      "[1,    15] loss: 0.738\n",
      "[1,    20] loss: 0.733\n",
      "[1,    25] loss: 0.728\n",
      "[1,    30] loss: 0.706\n",
      "[1,    35] loss: 0.706\n",
      "[1,    40] loss: 0.705\n",
      "[1,    45] loss: 0.621\n",
      "[1,    50] loss: 0.620\n",
      "[1,    55] loss: 0.555\n",
      "[1,    60] loss: 0.451\n",
      "[1,    65] loss: 0.489\n",
      "[1,    70] loss: 0.446\n",
      "[1,    75] loss: 0.360\n",
      "[1,    80] loss: 0.434\n",
      "[1,    85] loss: 0.478\n",
      "[1,    90] loss: 0.439\n",
      "[1,    95] loss: 0.543\n",
      "[1,   100] loss: 0.668\n",
      "[1,   105] loss: 0.655\n",
      "[1,   110] loss: 0.706\n",
      "[1,   115] loss: 0.666\n",
      "[1,   120] loss: 0.626\n",
      "[1,   125] loss: 0.631\n",
      "[1,   130] loss: 0.643\n",
      "[1,   135] loss: 0.519\n",
      "[1,   140] loss: 0.389\n",
      "[1,   145] loss: 0.431\n",
      "[1,   150] loss: 0.456\n",
      "[1,   155] loss: 0.474\n",
      "[1,   160] loss: 0.335\n",
      "[1,   165] loss: 0.298\n",
      "[1,   170] loss: 0.335\n",
      "[1,   175] loss: 0.494\n",
      "[1,   180] loss: 0.496\n",
      "[1,   185] loss: 0.443\n",
      "[1,   190] loss: 0.722\n",
      "[1,   195] loss: 0.777\n",
      "[1,   200] loss: 0.534\n",
      "[1,   205] loss: 0.489\n",
      "[1,   210] loss: 0.460\n",
      "[1,   215] loss: 0.468\n",
      "[1,   220] loss: 0.515\n",
      "[1,   225] loss: 0.538\n",
      "[1,   230] loss: 0.591\n",
      "[1,   235] loss: 0.527\n",
      "[1,   240] loss: 0.499\n",
      "[1,   245] loss: 0.437\n",
      "[1,   250] loss: 0.448\n",
      "[1,   255] loss: 0.464\n",
      "[1,   260] loss: 0.440\n",
      "[1,   265] loss: 0.517\n",
      "[1,   270] loss: 0.392\n",
      "[1,   275] loss: 0.214\n",
      "[1,   280] loss: 0.339\n",
      "[1,   285] loss: 0.498\n",
      "[1,   290] loss: 0.649\n",
      "[1,   295] loss: 0.474\n",
      "[1,   300] loss: 0.433\n",
      "[1,   305] loss: 0.462\n",
      "[1,   310] loss: 0.414\n",
      "[1,   315] loss: 0.610\n",
      "[1,   320] loss: 0.656\n",
      "[1,   325] loss: 0.486\n",
      "[1,   330] loss: 0.472\n",
      "[1,   335] loss: 0.507\n",
      "[1,   340] loss: 0.451\n",
      "[1,   345] loss: 0.391\n",
      "[1,   350] loss: 0.401\n",
      "[1,   355] loss: 0.377\n",
      "[1,   360] loss: 0.437\n",
      "[1,   365] loss: 0.613\n",
      "[1,   370] loss: 0.666\n",
      "[1,   375] loss: 0.649\n",
      "[1,   380] loss: 0.583\n",
      "[1,   385] loss: 0.557\n",
      "[1,   390] loss: 0.455\n",
      "[1,   395] loss: 0.362\n",
      "[1,   400] loss: 0.427\n",
      "next epoch\n",
      "epoch 1\n",
      "[2,     5] loss: 0.580\n",
      "[2,    10] loss: 0.468\n",
      "[2,    15] loss: 0.229\n",
      "[2,    20] loss: 0.267\n",
      "[2,    25] loss: 0.306\n",
      "[2,    30] loss: 0.253\n",
      "[2,    35] loss: 0.475\n",
      "[2,    40] loss: 0.480\n",
      "[2,    45] loss: 0.331\n",
      "[2,    50] loss: 0.306\n",
      "[2,    55] loss: 0.261\n",
      "[2,    60] loss: 0.133\n",
      "[2,    65] loss: 0.166\n",
      "[2,    70] loss: 0.230\n",
      "[2,    75] loss: 0.154\n",
      "[2,    80] loss: 0.309\n",
      "[2,    85] loss: 0.403\n",
      "[2,    90] loss: 0.324\n",
      "[2,    95] loss: 0.462\n",
      "[2,   100] loss: 0.699\n",
      "[2,   105] loss: 0.676\n",
      "[2,   110] loss: 0.594\n",
      "[2,   115] loss: 0.527\n",
      "[2,   120] loss: 0.467\n",
      "[2,   125] loss: 0.491\n",
      "[2,   130] loss: 0.570\n",
      "[2,   135] loss: 0.448\n",
      "[2,   140] loss: 0.358\n",
      "[2,   145] loss: 0.371\n",
      "[2,   150] loss: 0.361\n",
      "[2,   155] loss: 0.357\n",
      "[2,   160] loss: 0.263\n",
      "[2,   165] loss: 0.216\n",
      "[2,   170] loss: 0.340\n",
      "[2,   175] loss: 0.459\n",
      "[2,   180] loss: 0.420\n",
      "[2,   185] loss: 0.341\n",
      "[2,   190] loss: 0.574\n",
      "[2,   195] loss: 0.666\n",
      "[2,   200] loss: 0.419\n",
      "[2,   205] loss: 0.370\n",
      "[2,   210] loss: 0.356\n",
      "[2,   215] loss: 0.425\n",
      "[2,   220] loss: 0.494\n",
      "[2,   225] loss: 0.511\n",
      "[2,   230] loss: 0.547\n",
      "[2,   235] loss: 0.456\n",
      "[2,   240] loss: 0.430\n",
      "[2,   245] loss: 0.433\n",
      "[2,   250] loss: 0.467\n",
      "[2,   255] loss: 0.432\n",
      "[2,   260] loss: 0.355\n",
      "[2,   265] loss: 0.390\n",
      "[2,   270] loss: 0.339\n",
      "[2,   275] loss: 0.206\n",
      "[2,   280] loss: 0.345\n",
      "[2,   285] loss: 0.566\n",
      "[2,   290] loss: 0.596\n",
      "[2,   295] loss: 0.414\n",
      "[2,   300] loss: 0.405\n",
      "[2,   305] loss: 0.427\n",
      "[2,   310] loss: 0.402\n",
      "[2,   315] loss: 0.526\n",
      "[2,   320] loss: 0.531\n",
      "[2,   325] loss: 0.424\n",
      "[2,   330] loss: 0.354\n",
      "[2,   335] loss: 0.359\n",
      "[2,   340] loss: 0.336\n",
      "[2,   345] loss: 0.317\n",
      "[2,   350] loss: 0.351\n",
      "[2,   355] loss: 0.317\n",
      "[2,   360] loss: 0.351\n",
      "[2,   365] loss: 0.559\n",
      "[2,   370] loss: 0.574\n",
      "[2,   375] loss: 0.669\n",
      "[2,   380] loss: 0.611\n",
      "[2,   385] loss: 0.497\n",
      "[2,   390] loss: 0.323\n",
      "[2,   395] loss: 0.264\n",
      "[2,   400] loss: 0.407\n",
      "next epoch\n"
     ]
    }
   ],
   "source": [
    "\n",
    "criterion1 = nn.BCELoss()\n",
    "criterion2 = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    print(\"epoch {epoch}\".format(epoch=epoch))\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dldr_trn, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "    \n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs = torch.log10(torch.tensor(inputs).transpose(1,3) + 1)\n",
    "        # print(inputs.shape)\n",
    "        labels = torch.tensor(labels)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # print(inputs)\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss1 = criterion1(outputs, labels.reshape(20,1).type(torch.float32))\n",
    "        \n",
    "        loss2 = criterion2(curly_Nprime(net.vhn.weights), curly_N(torch.sum(inputs, dim = 0) / dldr_trn.batch_size))\n",
    "        # print(\"netvhn\", net.vhn.weights.shape)\n",
    "        # print(curly_N(torch.sum(inputs, dim = 0) / dldr.batch_size).shape)\n",
    "        loss = loss1 + loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 5 == 4:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 5:.3f}')\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff0b6b82-894d-40af-add8-6a0dbf28643c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next epoch\n",
      "81\n",
      "PRAUC tensor(0.8826)\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(dldr_tst,0):\n",
    "        inputs, label = data\n",
    "        \n",
    "        inputs = torch.log10(torch.tensor(inputs).transpose(1,3) + 1)\n",
    "        # print(inputs.shape)\n",
    "        label = torch.tensor(label)\n",
    "        # calculate outputs by running images through the \n",
    "        output = net(inputs)\n",
    "\n",
    "        preds.append(output.tolist())\n",
    "        labels.append(label.tolist())\n",
    "\n",
    "\n",
    "        if i > 100:\n",
    "            break\n",
    "print(len(preds))\n",
    "print(\"PRAUC\", binary_auprc(torch.tensor(preds).squeeze(0).squeeze(2), torch.tensor(labels), num_tasks=len(preds)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f78f412e-c8e4-4315-a7ac-8f4ee24cb505",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATRP(nn.Module):\n",
    "    def __init__(self, nc, device = None, N_filters=4, N_output = 1, ker = 4, s = 2, pad =1):\n",
    "        super(ATRP, self).__init__()\n",
    "        self.ker = ker\n",
    "        self.s = s\n",
    "        self.pad = pad\n",
    "        self.nc = nc\n",
    "        # self.device = device\n",
    "        self.N_filters = N_filters\n",
    "        self.N_output = N_output\n",
    "        self.conv1 = nn.Conv3d(nc, N_filters, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.conv2 = nn.Conv3d(N_filters, N_filters, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.conv3 = nn.Conv3d(N_filters, N_filters, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.conv4 = nn.Conv3d(N_filters, 1, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.avgpool = nn.AvgPool3d(kernel_size = (6, 2, 2), stride= (1, 1, 1), padding= (0, 0, 0))\n",
    "    \n",
    "\n",
    "        # \"columns input x and output columnes\"\n",
    "\n",
    "        self.f2 = nn.Linear(1248,1)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x0):\n",
    "        \"image vectorization\"\n",
    "        # print(x0.shape)\n",
    "        x = self.conv1(x0.unsqueeze(1))\n",
    "        x = self.avgpool(F.relu(x))\n",
    "        x = self.conv2(x)\n",
    "        x = self.avgpool(F.relu(x))\n",
    "        x = self.conv3(x)\n",
    "        x = self.avgpool(F.relu(x))\n",
    "        x = self.conv4(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "\n",
    "        x = self.f2(x)\n",
    "\n",
    "        y = self.sigmoid(x)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61831703-54ee-4b10-8a58-12bf98a101a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "[1,     5] loss: 0.679\n",
      "[1,    10] loss: 0.641\n",
      "[1,    15] loss: 0.603\n",
      "[1,    20] loss: 0.533\n",
      "[1,    25] loss: 0.384\n",
      "[1,    30] loss: 0.554\n",
      "[1,    35] loss: 0.456\n",
      "[1,    40] loss: 0.448\n",
      "[1,    45] loss: 0.472\n",
      "[1,    50] loss: 0.335\n",
      "[1,    55] loss: 0.564\n",
      "[1,    60] loss: 0.619\n",
      "[1,    65] loss: 0.461\n",
      "[1,    70] loss: 0.490\n",
      "[1,    75] loss: 0.587\n",
      "[1,    80] loss: 0.542\n",
      "[1,    85] loss: 0.512\n",
      "[1,    90] loss: 0.537\n",
      "[1,    95] loss: 0.694\n",
      "[1,   100] loss: 0.675\n",
      "[1,   105] loss: 0.613\n",
      "[1,   110] loss: 0.644\n",
      "[1,   115] loss: 0.607\n",
      "[1,   120] loss: 0.574\n",
      "[1,   125] loss: 0.546\n",
      "[1,   130] loss: 0.525\n",
      "[1,   135] loss: 0.429\n",
      "[1,   140] loss: 0.357\n",
      "[1,   145] loss: 0.480\n",
      "[1,   150] loss: 0.438\n",
      "[1,   155] loss: 0.382\n",
      "[1,   160] loss: 0.335\n",
      "[1,   165] loss: 0.390\n",
      "[1,   170] loss: 0.438\n",
      "[1,   175] loss: 0.518\n",
      "[1,   180] loss: 0.614\n",
      "[1,   185] loss: 0.573\n",
      "[1,   190] loss: 0.489\n",
      "[1,   195] loss: 0.375\n",
      "[1,   200] loss: 0.529\n",
      "[1,   205] loss: 0.621\n",
      "[1,   210] loss: 0.492\n",
      "[1,   215] loss: 0.471\n",
      "[1,   220] loss: 0.552\n",
      "[1,   225] loss: 0.596\n",
      "[1,   230] loss: 0.591\n",
      "[1,   235] loss: 0.533\n",
      "[1,   240] loss: 0.341\n",
      "[1,   245] loss: 0.253\n",
      "[1,   250] loss: 0.382\n",
      "[1,   255] loss: 0.510\n",
      "[1,   260] loss: 0.542\n",
      "[1,   265] loss: 0.412\n",
      "[1,   270] loss: 0.282\n",
      "[1,   275] loss: 0.158\n",
      "[1,   280] loss: 0.320\n",
      "[1,   285] loss: 0.636\n",
      "[1,   290] loss: 0.506\n",
      "[1,   295] loss: 0.336\n",
      "[1,   300] loss: 0.450\n",
      "[1,   305] loss: 0.480\n",
      "[1,   310] loss: 0.420\n",
      "[1,   315] loss: 0.399\n",
      "[1,   320] loss: 0.413\n",
      "[1,   325] loss: 0.465\n",
      "[1,   330] loss: 0.479\n",
      "[1,   335] loss: 0.428\n",
      "[1,   340] loss: 0.296\n",
      "[1,   345] loss: 0.252\n",
      "[1,   350] loss: 0.456\n",
      "[1,   355] loss: 0.531\n",
      "[1,   360] loss: 0.467\n",
      "[1,   365] loss: 0.614\n",
      "[1,   370] loss: 0.617\n",
      "[1,   375] loss: 0.595\n",
      "[1,   380] loss: 0.525\n",
      "[1,   385] loss: 0.384\n",
      "[1,   390] loss: 0.328\n",
      "[1,   395] loss: 0.340\n",
      "next epoch\n",
      "epoch 1\n",
      "[2,     5] loss: 0.432\n",
      "[2,    10] loss: 0.341\n",
      "[2,    15] loss: 0.278\n",
      "[2,    20] loss: 0.274\n",
      "[2,    25] loss: 0.159\n",
      "[2,    30] loss: 0.317\n",
      "[2,    35] loss: 0.230\n",
      "[2,    40] loss: 0.125\n",
      "[2,    45] loss: 0.370\n",
      "[2,    50] loss: 0.260\n",
      "[2,    55] loss: 0.217\n",
      "[2,    60] loss: 0.280\n",
      "[2,    65] loss: 0.189\n",
      "[2,    70] loss: 0.355\n",
      "[2,    75] loss: 0.658\n",
      "[2,    80] loss: 0.535\n",
      "[2,    85] loss: 0.435\n",
      "[2,    90] loss: 0.447\n",
      "[2,    95] loss: 0.559\n",
      "[2,   100] loss: 0.523\n",
      "[2,   105] loss: 0.436\n",
      "[2,   110] loss: 0.512\n",
      "[2,   115] loss: 0.474\n",
      "[2,   120] loss: 0.423\n",
      "[2,   125] loss: 0.367\n",
      "[2,   130] loss: 0.364\n",
      "[2,   135] loss: 0.251\n",
      "[2,   140] loss: 0.190\n",
      "[2,   145] loss: 0.313\n",
      "[2,   150] loss: 0.311\n",
      "[2,   155] loss: 0.325\n",
      "[2,   160] loss: 0.267\n",
      "[2,   165] loss: 0.285\n",
      "[2,   170] loss: 0.360\n",
      "[2,   175] loss: 0.555\n",
      "[2,   180] loss: 0.588\n",
      "[2,   185] loss: 0.469\n",
      "[2,   190] loss: 0.423\n",
      "[2,   195] loss: 0.251\n",
      "[2,   200] loss: 0.340\n",
      "[2,   205] loss: 0.540\n",
      "[2,   210] loss: 0.493\n",
      "[2,   215] loss: 0.397\n",
      "[2,   220] loss: 0.417\n",
      "[2,   225] loss: 0.461\n",
      "[2,   230] loss: 0.574\n",
      "[2,   235] loss: 0.539\n",
      "[2,   240] loss: 0.313\n",
      "[2,   245] loss: 0.303\n",
      "[2,   250] loss: 0.457\n",
      "[2,   255] loss: 0.468\n",
      "[2,   260] loss: 0.410\n",
      "[2,   265] loss: 0.298\n",
      "[2,   270] loss: 0.223\n",
      "[2,   275] loss: 0.137\n",
      "[2,   280] loss: 0.370\n",
      "[2,   285] loss: 0.628\n",
      "[2,   290] loss: 0.432\n",
      "[2,   295] loss: 0.302\n",
      "[2,   300] loss: 0.333\n",
      "[2,   305] loss: 0.413\n",
      "[2,   310] loss: 0.401\n",
      "[2,   315] loss: 0.441\n",
      "[2,   320] loss: 0.344\n",
      "[2,   325] loss: 0.340\n",
      "[2,   330] loss: 0.368\n",
      "[2,   335] loss: 0.336\n",
      "[2,   340] loss: 0.238\n",
      "[2,   345] loss: 0.246\n",
      "[2,   350] loss: 0.462\n",
      "[2,   355] loss: 0.551\n",
      "[2,   360] loss: 0.504\n",
      "[2,   365] loss: 0.580\n",
      "[2,   370] loss: 0.607\n",
      "[2,   375] loss: 0.593\n",
      "[2,   380] loss: 0.526\n",
      "[2,   385] loss: 0.365\n",
      "[2,   390] loss: 0.295\n",
      "[2,   395] loss: 0.299\n",
      "next epoch\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dldr_trn, dldr_tst = generate_generators(data_root = path , hdf_data_path = 'DL_info/chip_info/cube_raw',BZ = 20, IR = 1)\n",
    "net2 = ATRP(1)\n",
    "criterion1 = nn.BCELoss()\n",
    "optimizer = optim.Adam(net2.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    print(\"epoch {epoch}\".format(epoch=epoch))\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dldr_trn, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "    \n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs = torch.log10(torch.tensor(inputs).transpose(1,3) + 1)\n",
    "        # print(inputs.shape)\n",
    "        labels = torch.tensor(labels)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # print(inputs)\n",
    "        # forward + backward + optimize\n",
    "        outputs = net2(inputs)\n",
    "        loss1 = criterion1(outputs, labels.reshape(20,1).type(torch.float32))\n",
    "        # print(\"netvhn\", net.vhn.weights.shape)\n",
    "        # print(curly_N(torch.sum(inputs, dim = 0) / dldr.batch_size).shape)\n",
    "        loss = loss1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 5 == 4:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 5:.3f}')\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b4e5ead-9f84-4b8e-87db-a9ba91385651",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "next epoch\n",
      "87\n",
      "PRAUC tensor(0.8929)\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(dldr_tst,0):\n",
    "        inputs, label = data\n",
    "        \n",
    "        inputs = torch.log10(torch.tensor(inputs).transpose(1,3) + 1)\n",
    "        # print(inputs.shape)\n",
    "        label = torch.tensor(label)\n",
    "        # calculate outputs by running images through the network\n",
    "        output = net2(inputs)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        preds.append(output.tolist())\n",
    "        labels.append(label.tolist())\n",
    "        print(i)\n",
    "\n",
    "        if i > 100:\n",
    "            break\n",
    "print(len(preds))\n",
    "print(\"PRAUC\", binary_auprc(torch.tensor(preds).squeeze(0).squeeze(2), torch.tensor(labels), num_tasks=len(preds)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c4a8d7b-d7a3-4cfe-a068-cf809d9d875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../research_data/sas_june_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d4e8d79-8083-4c24-874c-4f6b010ec3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dldr_trn, dldr_tst = generate_generators(data_root = path , hdf_data_path = 'DL_info/chip_info/cube_raw',BZ = 20, IR = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7205e7bf-605c-472a-b564-a55993853cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "PRAUC tensor(0.7067)\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(dldr_trn,0):\n",
    "        inputs, label = data\n",
    "        \n",
    "        inputs = torch.log10(torch.tensor(inputs).transpose(1,3) + 1)\n",
    "        # print(inputs.shape)\n",
    "        label = torch.tensor(label)\n",
    "        # calculate outputs by running images through the \n",
    "        output = net(inputs)\n",
    "\n",
    "        preds.append(output.tolist())\n",
    "        labels.append(label.tolist())\n",
    "\n",
    "\n",
    "        if i > 15:\n",
    "            break\n",
    "print(len(preds))\n",
    "print(\"PRAUC\", binary_auprc(torch.tensor(preds).squeeze(0).squeeze(2), torch.tensor(labels), num_tasks=len(preds)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654d23a-bcc7-4b94-a498-e86e639efd77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83984750-866c-4022-9789-f48b162be44a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94245a2b-1234-4f4f-9309-e232d9ed4714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779e68d-c7d7-468f-8eee-7ffe445600a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
