{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bee53e3e-2ce6-4b23-9bc3-34ff2a2a0a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "def generate_generators(data_root, hdf_data_path,BZ,IR,\n",
    "                        label_scheme='label'):\n",
    "    \"\"\"\n",
    "    Gathers all files and organize into train/validation/test. Each\n",
    "       data subset is further organized by class. Converts file lists\n",
    "       into iterable data generators.\n",
    "    Inputs:\n",
    "        * data_root: full path to the data root containing subdirectories of data\n",
    "        * trn_list, val_list, tst_list: each is a list of strings. The strings\n",
    "            should encode the strata being used to divide data into segments and\n",
    "            must match the corresponding field of the FileName class.\n",
    "        * hdf_data_path: the path used internally in the HDF to get the desired surface\n",
    "        * batch_size: the _approximate_ number of samples to be used __next__ call. Note\n",
    "              that if batch_size // n_classes is non-integer then it may be slightly off.\n",
    "        * label_scheme: a string that matches the name of the property of the FileName\n",
    "              class that you want to use as the label.\n",
    "        * strata_scheme: a string that matches the name of the property of the FileName\n",
    "              class that you want to compare against trn_list (etc.) for data segmentation.\n",
    "    \"\"\"\n",
    "    n_classes = 2\n",
    "    tst_files = [[] for clas in range(n_classes)]\n",
    "    trn_files = [[] for clas in range(n_classes)]\n",
    "\n",
    "    \n",
    "    #print('Allocating HDFs to train/valid/test...')\n",
    "    for filename in os.listdir(data_root):\n",
    "        if not filename.endswith('.hdf'):\n",
    "            continue\n",
    "\n",
    "        # Extract the label using 'label_scheme' identifier\n",
    "        label = int(int(filename.split('_')[3]) > 0)  # 0 = clutter (not manmade); 1 = target (manmade)\n",
    "\n",
    "        # list that stores files in two sub-lists\n",
    "        randr = random.randrange(0,5)\n",
    "        if randr < 1:\n",
    "            \n",
    "            tst_files[label].append(filename)\n",
    "\n",
    "        else:\n",
    "\n",
    "            trn_files[label].append(filename)\n",
    "\n",
    "    # Wrap each file list into an iterable data generator that actually\n",
    "    #     read the HDFs when __next__ is called:\n",
    "    \n",
    "    trn_gen = DataGenerator(data_root, trn_files, hdf_data_path,  BZ, IR)\n",
    "    tst_gen = DataGenerator(data_root, tst_files, hdf_data_path, BZ, IR)\n",
    "    length = len(trn_files[0] + trn_files[1]) #+ len(trn_files[1])\n",
    "\n",
    "    return trn_gen, tst_gen\n",
    "\n",
    "\n",
    "class DataGenerator:\n",
    "    def __init__(self, data_root, file_list, hdf_data_path, BZ, IR, n_classes=2):\n",
    "        # Basic properties:\n",
    "        self.data_root = data_root\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        \"balance by class\"\n",
    "        self.hdf_path = hdf_data_path\n",
    "\n",
    "        self._permanent_file_list = file_list\n",
    "        # print(len(file_list[0]), \"\\n\")\n",
    "        \"for august-november split\"\n",
    "        # self.target_list = file_list[1][0:4\n",
    "        \"for fulll dataset\"\n",
    "        self.target_list = file_list[1]\n",
    "        self.target_len = len(self.target_list)\n",
    "        # print(self.target_len, 'length of target')\n",
    "        \n",
    "        \"test\"\n",
    "\n",
    "        #self.clutter_list = file_list[0]\n",
    "        self.clutter_list = file_list[0][0:int(IR*self.target_len)]\n",
    "\n",
    "        #self.clutter_list = file_list[0][0:16799]\n",
    "        self.clutter_len = len(self.clutter_list)\n",
    "        # print(self.clutter_len, 'length of clutter')\n",
    "\n",
    "        self.dataset_size = self.clutter_len + self.target_len\n",
    "        self.batch_size = BZ\n",
    "        self.bsz_by_class = int(self.batch_size / self.n_classes)\n",
    "\n",
    "        if self.batch_size % 2 != 0 or self.bsz_by_class % 2 != 0:\n",
    "            print('batch size is odd or not balanced... \\nadding one to batch size')\n",
    "            self.batch_size = self.batch_size  + 1\n",
    "            self.bsz_by_class = math.floor(self.batch_size / self.n_classes)\n",
    "\n",
    "        n = 1\n",
    "        while n < 6:\n",
    "            if  self.bsz_by_class % 2 != 0:\n",
    "                print('batch size is not balanced... \\nadding one to batch size')\n",
    "                self.batch_size = self.batch_size  + 1\n",
    "                self.bsz_by_class = math.floor(self.batch_size / self.n_classes)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "        # print(self.batch_size, 'batch_size')\n",
    "        # print(self.bsz_by_class, 'balance size')\n",
    "\n",
    "        #self.current_index = [i for i in range(self.batch_size)]\n",
    "\n",
    "\n",
    "        #self.current_index = [0 for label in range(self.n_classes)]\n",
    "\n",
    "        self.HDF_n_rows = 71\n",
    "        self.HDF_n_cols = 71\n",
    "        self.HDF_n_dpth = 101\n",
    "\n",
    "        self.input_shape = (self.batch_size, self.HDF_n_rows, self.HDF_n_cols, self.HDF_n_dpth)\n",
    "\n",
    "        self.chip_n_rows = 64\n",
    "        self.chip_n_cols = 64\n",
    "        self.chip_n_dpth = 101\n",
    "\n",
    "        \"chip shape is one cube from batch\"\n",
    "        self.chip_shape = (self.chip_n_rows, self.chip_n_cols, self.chip_n_dpth)\n",
    "\n",
    "        self.batch_shape = (self.batch_size, self.chip_n_rows, self.chip_n_cols, self.chip_n_dpth)\n",
    "\n",
    "\n",
    "        # Make a boolean indexing mask for efficient extraction of the chip center:\n",
    "        \"input shape minus chip shape row\"\n",
    "        row_diff = self.input_shape[1] - self.chip_shape[0]\n",
    "        \"this is chopping off one half the difference on each side\"\n",
    "        first_row = row_diff // 2\n",
    "        last_row = first_row + self.chip_shape[0]\n",
    "\n",
    "        \"this is chopping off one half the difference on each side\"\n",
    "        col_diff = self.input_shape[2] - self.chip_shape[1]\n",
    "        first_col = col_diff // 2\n",
    "        last_col = first_col + self.chip_shape[1]\n",
    "\n",
    "        \"this is chopping off one half the difference on each side\"\n",
    "        slice_diff = self.input_shape[3] - self.chip_shape[2]\n",
    "        first_slice = slice_diff // 2\n",
    "        last_slice = first_slice + self.chip_shape[2]\n",
    "\n",
    "        \"slicing out the chips from the input data\"\n",
    "        \"list with shape of input all False values\"\n",
    "        self.center_select = np.full((self.HDF_n_rows, self.HDF_n_cols, self.HDF_n_dpth), False)\n",
    "        \"except the chips size all true\"\n",
    "        self.center_select[first_row:last_row, first_col:last_col, first_slice:last_slice] = True\n",
    "\n",
    "        # self.first_slice = 0\n",
    "        # self.last_slice = self.bsz_by_class\n",
    "\n",
    "\n",
    "    def readHDF(self, file_name):\n",
    "        \"\"\" Reads data from the HDF\"\"\"\n",
    "        with h5py.File(os.path.join(self.data_root, file_name), mode='r') as f:\n",
    "            data = f[self.hdf_path][:]\n",
    "            data = np.transpose(data)  # because python reverses the order of the 3d volume, this will correct back to the original matlab order\n",
    "            #data = data / 40  # Now data is in [0,1], to match the 2d sensors\n",
    "\n",
    "\n",
    "        return data\n",
    "\n",
    "    def chip_center(self, data):\n",
    "        \"\"\" extracts the center of the chip via boolean indexing. \"\"\"\n",
    "        return np.reshape(data[self.center_select], self.chip_shape)\n",
    "\n",
    "\n",
    "    def preprocess(self, data_sample):\n",
    "        \"\"\"\n",
    "        Preprocesses a data sample.\n",
    "        TODO: use configuration file and preprocesser class like ADAM dataloader here.\n",
    "        \"\"\"\n",
    "        # TODO: sometimes want to jiggle the chip instead of centering so will\n",
    "        #          need to remove chip_center from here.\n",
    "\n",
    "        \"centering x cube\"\n",
    "        x_center = self.chip_center(data_sample)\n",
    "        return x_center\n",
    "\n",
    "    def perm_target_list(self, target_list):\n",
    "        if self.last_slice % self.target_len == 0:\n",
    "            print('target list permuted')\n",
    "            return np.random.permutation(target_list)\n",
    "        else:\n",
    "            return target_list\n",
    "        #return np.random.permutation(target_list)\n",
    "\n",
    "    def reset_list(self, target_list):\n",
    "\n",
    "        # Come up with a way to reset_list\n",
    "\n",
    "\n",
    "            return target_list\n",
    "\n",
    "    def data_loop(self, list_data):\n",
    "\n",
    "        \"place holder for batch of data\"\n",
    "        batch_data = np.zeros(self.batch_shape, dtype='float32')\n",
    "        \"batch labels\"\n",
    "        batch_label = np.zeros(self.batch_size)\n",
    "\n",
    "        for label in range(0, self.n_classes):\n",
    "            for nth_sample in range(0, self.bsz_by_class):\n",
    "\n",
    "                ld = list_data[label]\n",
    "                sample = ld[nth_sample]\n",
    "\n",
    "                data = self.readHDF(sample)\n",
    "\n",
    "                # Preprocessing can go here, e.g. random flips/translations/normalizations\n",
    "                \"centers the data here\"\n",
    "                data = self.preprocess(data)\n",
    "\n",
    "                # Insert the data into the batch_data and batch_label arrays:\n",
    "                batch_idx = self.bsz_by_class * label + nth_sample\n",
    "                \"batch data: why just rows and columns\"\n",
    "                batch_data[batch_idx][:, :, :] = np.reshape(data, self.chip_shape)\n",
    "                \"batch label\"\n",
    "                batch_label[batch_idx] = label\n",
    "\n",
    "        return batch_data, batch_label\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.first_slice = 0\n",
    "        self.last_slice = self.bsz_by_class\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum([len(label_set) for label_set in self.target_list])\n",
    "\n",
    "    def __next__(self):\n",
    "\n",
    "\n",
    "        # Put `bsz_by_class' samples from each class into `batch_data':\n",
    "\n",
    "        # for n in range(self.bsz_by_class, self.target_len, self.bsz_by_class):\n",
    "\n",
    "\n",
    "        if self.last_slice <= self.clutter_len:\n",
    "            #print(self.last_slice, 'last slice')\n",
    "\n",
    "            if self.last_slice > self.target_len:\n",
    "                tlp = self.perm_target_list(self.target_list)\n",
    "                tl = self.reset_list(tlp)\n",
    "\n",
    "                cl = self.clutter_list[self.first_slice:self.last_slice]\n",
    "\n",
    "                list_data = [cl, tl]\n",
    "\n",
    "                batch_data, batch_label = self.data_loop(list_data)\n",
    "\n",
    "            elif self.last_slice <= self.target_len :\n",
    "                tl = self.target_list[self.first_slice:self.last_slice]\n",
    "                cl = self.clutter_list[self.first_slice:self.last_slice]\n",
    "\n",
    "\n",
    "                list_data = [cl, tl]\n",
    "\n",
    "\n",
    "                batch_data, batch_label = self.data_loop(list_data)\n",
    "\n",
    "        else:\n",
    "            print('next epoch')\n",
    "            raise StopIteration\n",
    "\n",
    "        self.first_slice += 1\n",
    "        self.last_slice += 1\n",
    "        return batch_data, batch_label\n",
    "        # , self.bsz_by_class, self.clutter_len, self.target_len, self.batch_size\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7d6e135c-556d-4d71-831a-b7394dcc7be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    _relu = nn.ReLU()\n",
    "    \n",
    "    return _relu(x)\n",
    "# change to global min / max\n",
    "def curly_N(w):\n",
    "    w_min, w_max = torch.min(torch.min(torch.min(w))), torch.max(torch.max(torch.max(w)))\n",
    "    reg_N = (w - w_min) / (w_max - w_min)\n",
    "    return reg_N\n",
    "\n",
    "def curly_Nprime(w):\n",
    "    w_min, w_max = torch.min(torch.min(torch.min(w))), torch.max(torch.max(torch.max(w)))\n",
    "    curly_N = (w - w_min + 1) / (w_max - w_min + 2)\n",
    "    return curly_N\n",
    "    # return (w - torch.min(w) + 1) / (torch.max(w) - torch.min(w) + 2)\n",
    "\n",
    "def f_VHN(x, w):\n",
    "    relu_x = relu(curly_N(x))\n",
    "    relu_w = relu(curly_Nprime(w))\n",
    "    \n",
    "    return relu_x * relu_w\n",
    "    \n",
    "class VHNLayer(nn.Module):\n",
    "    \"\"\" Custom VHN layer \"\"\"\n",
    "    def __init__(self, channels, img_len, img_width):\n",
    "        super().__init__()\n",
    "        self.channels, self.img_len, self.img_width = channels, img_len, img_width\n",
    "        weights = torch.Tensor(channels, img_len, img_width)\n",
    "        self.weights = nn.Parameter(weights)  # nn.Parameter is a Tensor that's a module parameter.\n",
    "\n",
    "        # initialize weights and biases\n",
    "        nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5)) # weight init\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return f_VHN(x, self.weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e2f9c03f-1b56-4a4e-9bc0-a40df78e8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from load_data import device\n",
    "\"fix dimensions\"\n",
    "\"may need \"\n",
    "import matplotlib.pyplot as plt\n",
    "# from colormap import *\n",
    "import os\n",
    "\n",
    "class ATR(nn.Module):\n",
    "    def __init__(self, nc, device = None, N_filters=4, N_output = 1, ker = 4, s = 2, pad =1):\n",
    "        super(ATR, self).__init__()\n",
    "        self.ker = ker\n",
    "        self.s = s\n",
    "        self.pad = pad\n",
    "        self.nc = nc\n",
    "        # self.device = device\n",
    "        self.N_filters = N_filters\n",
    "        self.N_output = N_output\n",
    "        self.vhn = VHNLayer(101, 64, 64)\n",
    "        self.conv1 = nn.Conv3d(nc, N_filters, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.conv2 = nn.Conv3d(N_filters, N_filters, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.conv3 = nn.Conv3d(N_filters, N_filters, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.conv4 = nn.Conv3d(N_filters, 1, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.avgpool = nn.AvgPool3d(kernel_size = (6, 2, 2), stride= (1, 1, 1), padding= (0, 0, 0))\n",
    "    \n",
    "\n",
    "        # \"columns input x and output columnes\"\n",
    "\n",
    "        self.f2 = nn.Linear(1248,1)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x0):\n",
    "        \"image vectorization\"\n",
    "        # print(x0.shape)\n",
    "        x0 = self.vhn.forward(x0)\n",
    "        x = self.conv1(x0.unsqueeze(1))\n",
    "        x = self.avgpool(F.relu(x))\n",
    "        x = self.conv2(x)\n",
    "        x = self.avgpool(F.relu(x))\n",
    "        x = self.conv3(x)\n",
    "        x = self.avgpool(F.relu(x))\n",
    "        x = self.conv4(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "\n",
    "        x = self.f2(x)\n",
    "\n",
    "        y = self.sigmoid(x)\n",
    "\n",
    "        return y\n",
    "\n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2205becb-221e-46d0-a01a-dfc301b8506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ATR(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d6b5e92e-1c13-48da-be4f-6722fc586f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ac5ef9b3-faae-4ec7-99e6-8fdf56c303cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "be18efb3-1940-4f57-9122-576a26dde859",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../research_data/sas_full_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d7124b66-b2c2-4d7f-b64d-64fef384d5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401 length of target\n",
      "401 length of clutter\n",
      "20 batch_size\n",
      "10 balance size\n",
      "99 length of target\n",
      "99 length of clutter\n",
      "20 batch_size\n",
      "10 balance size\n"
     ]
    }
   ],
   "source": [
    "dldr_trn, dldr_tst = generate_generators(data_root = path , hdf_data_path = 'DL_info/chip_info/cube_raw',BZ = 20, IR = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "20745286-1e42-4fc4-ad2b-d1f4fa8f949a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [4, 20, 3, 3, 3], expected input[20, 1, 101, 64, 64] to have 20 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# print(inputs)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# forward + backward + optimize\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m outputs \u001b[38;5;241m=\u001b[39m net(inputs)\n\u001b[1;32m     24\u001b[0m loss1 \u001b[38;5;241m=\u001b[39m criterion1(outputs, labels\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[1;32m     26\u001b[0m loss2 \u001b[38;5;241m=\u001b[39m criterion2(curly_Nprime(net\u001b[38;5;241m.\u001b[39mvhn\u001b[38;5;241m.\u001b[39mweights), curly_N(torch\u001b[38;5;241m.\u001b[39msum(inputs, dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m/\u001b[39m dldr\u001b[38;5;241m.\u001b[39mbatch_size))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[122], line 37\u001b[0m, in \u001b[0;36mATR.forward\u001b[0;34m(self, x0)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# print(x0.shape)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m x0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvhn\u001b[38;5;241m.\u001b[39mforward(x0)\n\u001b[0;32m---> 37\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x0\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     38\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(F\u001b[38;5;241m.\u001b[39mrelu(x))\n\u001b[1;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:610\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:605\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    595\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    596\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    604\u001b[0m     )\n\u001b[0;32m--> 605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[1;32m    607\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [4, 20, 3, 3, 3], expected input[20, 1, 101, 64, 64] to have 20 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion1 = nn.BCELoss()\n",
    "criterion2 = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    print(\"epoch {epoch}\".format(epoch=epoch))\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dldr, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "    \n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs = torch.log10(torch.tensor(inputs).transpose(1,3) + 1)\n",
    "        # print(inputs.shape)\n",
    "        labels = torch.tensor(labels)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # print(inputs)\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss1 = criterion1(outputs, labels.reshape(20,1).type(torch.float32))\n",
    "        \n",
    "        loss2 = criterion2(curly_Nprime(net.vhn.weights), curly_N(torch.sum(inputs, dim = 0) / dldr.batch_size))\n",
    "        # print(\"netvhn\", net.vhn.weights.shape)\n",
    "        # print(curly_N(torch.sum(inputs, dim = 0) / dldr.batch_size).shape)\n",
    "        loss = loss1 + loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 5 == 4:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 5:.3f}')\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b6b82-894d-40af-add8-6a0dbf28643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "import torcheval\n",
    "from torcheval.metrics.functional import binary_auprc\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(dldr_tst,0):\n",
    "        inputs, label = data\n",
    "        \n",
    "        inputs = torch.log10(torch.tensor(inputs).transpose(1,3) + 1)\n",
    "        # print(inputs.shape)\n",
    "        label = torch.tensor(label)\n",
    "        # calculate outputs by running images through the network\n",
    "        output = net(inputs)\n",
    "\n",
    "        preds.append(output.tolist())\n",
    "        labels.append(label.tolist())\n",
    "\n",
    "\n",
    "        if i > 100:\n",
    "            break\n",
    "print(len(preds))\n",
    "print(\"PRAUC\", binary_auprc(torch.tensor(preds).squeeze(0).squeeze(2), torch.tensor(labels), num_tasks=len(preds)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f412e-c8e4-4315-a7ac-8f4ee24cb505",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATR(nn.Module):\n",
    "    def __init__(self, nc, device = None, N_filters=4, N_output = 1, ker = 4, s = 2, pad =1):\n",
    "        super(ATR, self).__init__()\n",
    "        self.ker = ker\n",
    "        self.s = s\n",
    "        self.pad = pad\n",
    "        self.nc = nc\n",
    "        # self.device = device\n",
    "        self.N_filters = N_filters\n",
    "        self.N_output = N_output\n",
    "        self.conv1 = nn.Conv3d(nc, N_filters, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.conv2 = nn.Conv3d(N_filters, N_filters, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.conv3 = nn.Conv3d(N_filters, N_filters, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.conv4 = nn.Conv3d(N_filters, 1, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.avgpool = nn.AvgPool3d(kernel_size = (6, 2, 2), stride= (1, 1, 1), padding= (0, 0, 0))\n",
    "    \n",
    "\n",
    "        # \"columns input x and output columnes\"\n",
    "\n",
    "        self.f2 = nn.Linear(1248,1)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x0):\n",
    "        \"image vectorization\"\n",
    "        # print(x0.shape)\n",
    "        x = self.conv1(x0.unsqueeze(1))\n",
    "        x = self.avgpool(F.relu(x))\n",
    "        x = self.conv2(x)\n",
    "        x = self.avgpool(F.relu(x))\n",
    "        x = self.conv3(x)\n",
    "        x = self.avgpool(F.relu(x))\n",
    "        x = self.conv4(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "\n",
    "        x = self.f2(x)\n",
    "\n",
    "        y = self.sigmoid(x)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61831703-54ee-4b10-8a58-12bf98a101a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion1 = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    print(\"epoch {epoch}\".format(epoch=epoch))\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dldr, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "    \n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs = torch.log10(torch.tensor(inputs).transpose(1,3) + 1)\n",
    "        # print(inputs.shape)\n",
    "        labels = torch.tensor(labels)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # print(inputs)\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss1 = criterion1(outputs, labels.reshape(20,1).type(torch.float32))\n",
    "        # print(\"netvhn\", net.vhn.weights.shape)\n",
    "        # print(curly_N(torch.sum(inputs, dim = 0) / dldr.batch_size).shape)\n",
    "        loss = loss1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 5 == 4:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 5:.3f}')\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e5ead-9f84-4b8e-87db-a9ba91385651",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "import torcheval\n",
    "from torcheval.metrics.functional import binary_auprc\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(dldr_tst,0):\n",
    "        inputs, label = data\n",
    "        \n",
    "        inputs = torch.log10(torch.tensor(inputs).transpose(1,3) + 1)\n",
    "        # print(inputs.shape)\n",
    "        label = torch.tensor(label)\n",
    "        # calculate outputs by running images through the network\n",
    "        output = net(inputs)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        preds.append(output.tolist())\n",
    "        labels.append(label.tolist())\n",
    "        print(i)\n",
    "\n",
    "        if i > 100:\n",
    "            break\n",
    "print(len(preds))\n",
    "print(\"PRAUC\", binary_auprc(torch.tensor(preds).squeeze(0).squeeze(2), torch.tensor(labels), num_tasks=len(preds)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4e8d79-8083-4c24-874c-4f6b010ec3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7205e7bf-605c-472a-b564-a55993853cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3be792-24d0-4499-875b-ef363141e44c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
