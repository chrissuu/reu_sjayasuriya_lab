{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee53e3e-2ce6-4b23-9bc3-34ff2a2a0a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "def generate_generators(data_root, hdf_data_path,BZ,IR,\n",
    "                        label_scheme='label'):\n",
    "    \"\"\"\n",
    "    Gathers all files and organize into train/validation/test. Each\n",
    "       data subset is further organized by class. Converts file lists\n",
    "       into iterable data generators.\n",
    "    Inputs:\n",
    "        * data_root: full path to the data root containing subdirectories of data\n",
    "        * trn_list, val_list, tst_list: each is a list of strings. The strings\n",
    "            should encode the strata being used to divide data into segments and\n",
    "            must match the corresponding field of the FileName class.\n",
    "        * hdf_data_path: the path used internally in the HDF to get the desired surface\n",
    "        * batch_size: the _approximate_ number of samples to be used __next__ call. Note\n",
    "              that if batch_size // n_classes is non-integer then it may be slightly off.\n",
    "        * label_scheme: a string that matches the name of the property of the FileName\n",
    "              class that you want to use as the label.\n",
    "        * strata_scheme: a string that matches the name of the property of the FileName\n",
    "              class that you want to compare against trn_list (etc.) for data segmentation.\n",
    "    \"\"\"\n",
    "    n_classes = 2\n",
    "    tst_files = [[] for clas in range(n_classes)]\n",
    "    trn_files = [[] for clas in range(n_classes)]\n",
    "\n",
    "    \n",
    "    #print('Allocating HDFs to train/valid/test...')\n",
    "    for filename in os.listdir(data_root):\n",
    "        if not filename.endswith('.hdf'):\n",
    "            continue\n",
    "\n",
    "        # Extract the label using 'label_scheme' identifier\n",
    "        label = int(int(filename.split('_')[3]) > 0)  # 0 = clutter (not manmade); 1 = target (manmade)\n",
    "\n",
    "        # list that stores files in two sub-lists\n",
    "        randr = random.randrange(0,5)\n",
    "        if randr < 1:\n",
    "            \n",
    "            tst_files[label].append(filename)\n",
    "\n",
    "        else:\n",
    "\n",
    "            trn_files[label].append(filename)\n",
    "\n",
    "    # Wrap each file list into an iterable data generator that actually\n",
    "    #     read the HDFs when __next__ is called:\n",
    "    \n",
    "    trn_gen = DataGenerator(data_root, trn_files, hdf_data_path,  BZ, IR)\n",
    "    tst_gen = DataGenerator(data_root, tst_files, hdf_data_path, BZ, IR)\n",
    "    length = len(trn_files[0] + trn_files[1]) #+ len(trn_files[1])\n",
    "\n",
    "    return trn_gen, tst_gen\n",
    "\n",
    "\n",
    "class DataGenerator:\n",
    "    def __init__(self, data_root, file_list, hdf_data_path, BZ, IR, n_classes=2):\n",
    "        # Basic properties:\n",
    "        self.data_root = data_root\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        \"balance by class\"\n",
    "        self.hdf_path = hdf_data_path\n",
    "\n",
    "        self._permanent_file_list = file_list\n",
    "        # print(len(file_list[0]), \"\\n\")\n",
    "        \"for august-november split\"\n",
    "        # self.target_list = file_list[1][0:4\n",
    "        \"for fulll dataset\"\n",
    "        self.target_list = file_list[1]\n",
    "        self.target_len = len(self.target_list)\n",
    "        # print(self.target_len, 'length of target')\n",
    "        \n",
    "        \"test\"\n",
    "\n",
    "        #self.clutter_list = file_list[0]\n",
    "        self.clutter_list = file_list[0][0:int(IR*self.target_len)]\n",
    "\n",
    "        #self.clutter_list = file_list[0][0:16799]\n",
    "        self.clutter_len = len(self.clutter_list)\n",
    "        # print(self.clutter_len, 'length of clutter')\n",
    "\n",
    "        self.dataset_size = self.clutter_len + self.target_len\n",
    "        self.batch_size = BZ\n",
    "        self.bsz_by_class = int(self.batch_size / self.n_classes)\n",
    "\n",
    "        if self.batch_size % 2 != 0 or self.bsz_by_class % 2 != 0:\n",
    "            print('batch size is odd or not balanced... \\nadding one to batch size')\n",
    "            self.batch_size = self.batch_size  + 1\n",
    "            self.bsz_by_class = math.floor(self.batch_size / self.n_classes)\n",
    "\n",
    "        n = 1\n",
    "        while n < 6:\n",
    "            if  self.bsz_by_class % 2 != 0:\n",
    "                print('batch size is not balanced... \\nadding one to batch size')\n",
    "                self.batch_size = self.batch_size  + 1\n",
    "                self.bsz_by_class = math.floor(self.batch_size / self.n_classes)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "        # print(self.batch_size, 'batch_size')\n",
    "        # print(self.bsz_by_class, 'balance size')\n",
    "\n",
    "        #self.current_index = [i for i in range(self.batch_size)]\n",
    "\n",
    "\n",
    "        #self.current_index = [0 for label in range(self.n_classes)]\n",
    "\n",
    "        self.HDF_n_rows = 71\n",
    "        self.HDF_n_cols = 71\n",
    "        self.HDF_n_dpth = 101\n",
    "\n",
    "        self.input_shape = (self.batch_size, self.HDF_n_rows, self.HDF_n_cols, self.HDF_n_dpth)\n",
    "\n",
    "        self.chip_n_rows = 64\n",
    "        self.chip_n_cols = 64\n",
    "        self.chip_n_dpth = 101\n",
    "\n",
    "        \"chip shape is one cube from batch\"\n",
    "        self.chip_shape = (self.chip_n_rows, self.chip_n_cols, self.chip_n_dpth)\n",
    "\n",
    "        self.batch_shape = (self.batch_size, self.chip_n_rows, self.chip_n_cols, self.chip_n_dpth)\n",
    "\n",
    "\n",
    "        # Make a boolean indexing mask for efficient extraction of the chip center:\n",
    "        \"input shape minus chip shape row\"\n",
    "        row_diff = self.input_shape[1] - self.chip_shape[0]\n",
    "        \"this is chopping off one half the difference on each side\"\n",
    "        first_row = row_diff // 2\n",
    "        last_row = first_row + self.chip_shape[0]\n",
    "\n",
    "        \"this is chopping off one half the difference on each side\"\n",
    "        col_diff = self.input_shape[2] - self.chip_shape[1]\n",
    "        first_col = col_diff // 2\n",
    "        last_col = first_col + self.chip_shape[1]\n",
    "\n",
    "        \"this is chopping off one half the difference on each side\"\n",
    "        slice_diff = self.input_shape[3] - self.chip_shape[2]\n",
    "        first_slice = slice_diff // 2\n",
    "        last_slice = first_slice + self.chip_shape[2]\n",
    "\n",
    "        \"slicing out the chips from the input data\"\n",
    "        \"list with shape of input all False values\"\n",
    "        self.center_select = np.full((self.HDF_n_rows, self.HDF_n_cols, self.HDF_n_dpth), False)\n",
    "        \"except the chips size all true\"\n",
    "        self.center_select[first_row:last_row, first_col:last_col, first_slice:last_slice] = True\n",
    "\n",
    "        # self.first_slice = 0\n",
    "        # self.last_slice = self.bsz_by_class\n",
    "\n",
    "\n",
    "    def readHDF(self, file_name):\n",
    "        \"\"\" Reads data from the HDF\"\"\"\n",
    "        with h5py.File(os.path.join(self.data_root, file_name), mode='r') as f:\n",
    "            data = f[self.hdf_path][:]\n",
    "            data = np.transpose(data)  # because python reverses the order of the 3d volume, this will correct back to the original matlab order\n",
    "            #data = data / 40  # Now data is in [0,1], to match the 2d sensors\n",
    "\n",
    "\n",
    "        return data\n",
    "\n",
    "    def chip_center(self, data):\n",
    "        \"\"\" extracts the center of the chip via boolean indexing. \"\"\"\n",
    "        return np.reshape(data[self.center_select], self.chip_shape)\n",
    "\n",
    "\n",
    "    def preprocess(self, data_sample):\n",
    "        \"\"\"\n",
    "        Preprocesses a data sample.\n",
    "        TODO: use configuration file and preprocesser class like ADAM dataloader here.\n",
    "        \"\"\"\n",
    "        # TODO: sometimes want to jiggle the chip instead of centering so will\n",
    "        #          need to remove chip_center from here.\n",
    "\n",
    "        \"centering x cube\"\n",
    "        x_center = self.chip_center(data_sample)\n",
    "        return x_center\n",
    "\n",
    "    def perm_target_list(self, target_list):\n",
    "        if self.last_slice % self.target_len == 0:\n",
    "            print('target list permuted')\n",
    "            return np.random.permutation(target_list)\n",
    "        else:\n",
    "            return target_list\n",
    "        #return np.random.permutation(target_list)\n",
    "\n",
    "    def reset_list(self, target_list):\n",
    "\n",
    "        # Come up with a way to reset_list\n",
    "\n",
    "\n",
    "            return target_list\n",
    "\n",
    "    def data_loop(self, list_data):\n",
    "\n",
    "        \"place holder for batch of data\"\n",
    "        batch_data = np.zeros(self.batch_shape, dtype='float32')\n",
    "        \"batch labels\"\n",
    "        batch_label = np.zeros(self.batch_size)\n",
    "\n",
    "        for label in range(0, self.n_classes):\n",
    "            for nth_sample in range(0, self.bsz_by_class):\n",
    "\n",
    "                ld = list_data[label]\n",
    "                sample = ld[nth_sample]\n",
    "\n",
    "                data = self.readHDF(sample)\n",
    "\n",
    "                # Preprocessing can go here, e.g. random flips/translations/normalizations\n",
    "                \"centers the data here\"\n",
    "                data = self.preprocess(data)\n",
    "\n",
    "                # Insert the data into the batch_data and batch_label arrays:\n",
    "                batch_idx = self.bsz_by_class * label + nth_sample\n",
    "                \"batch data: why just rows and columns\"\n",
    "                batch_data[batch_idx][:, :, :] = np.reshape(data, self.chip_shape)\n",
    "                \"batch label\"\n",
    "                batch_label[batch_idx] = label\n",
    "\n",
    "        return batch_data, batch_label\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.first_slice = 0\n",
    "        self.last_slice = self.bsz_by_class\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum([len(label_set) for label_set in self.target_list])\n",
    "\n",
    "    def __next__(self):\n",
    "\n",
    "\n",
    "        # Put `bsz_by_class' samples from each class into `batch_data':\n",
    "\n",
    "        # for n in range(self.bsz_by_class, self.target_len, self.bsz_by_class):\n",
    "\n",
    "\n",
    "        if self.last_slice <= self.clutter_len:\n",
    "            #print(self.last_slice, 'last slice')\n",
    "\n",
    "            if self.last_slice > self.target_len:\n",
    "                tlp = self.perm_target_list(self.target_list)\n",
    "                tl = self.reset_list(tlp)\n",
    "\n",
    "                cl = self.clutter_list[self.first_slice:self.last_slice]\n",
    "\n",
    "                list_data = [cl, tl]\n",
    "\n",
    "                batch_data, batch_label = self.data_loop(list_data)\n",
    "\n",
    "            elif self.last_slice <= self.target_len :\n",
    "                tl = self.target_list[self.first_slice:self.last_slice]\n",
    "                cl = self.clutter_list[self.first_slice:self.last_slice]\n",
    "\n",
    "\n",
    "                list_data = [cl, tl]\n",
    "\n",
    "\n",
    "                batch_data, batch_label = self.data_loop(list_data)\n",
    "\n",
    "        else:\n",
    "            print('next epoch')\n",
    "            raise StopIteration\n",
    "\n",
    "        self.first_slice += 1\n",
    "        self.last_slice += 1\n",
    "        return batch_data, batch_label\n",
    "        # , self.bsz_by_class, self.clutter_len, self.target_len, self.batch_size\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d6e135c-556d-4d71-831a-b7394dcc7be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    _relu = nn.ReLU()\n",
    "    \n",
    "    return _relu(x)\n",
    "# change to global min / max\n",
    "def curly_N(w):\n",
    "    w_min, w_max = torch.min(torch.min(torch.min(w))), torch.max(torch.max(torch.max(w)))\n",
    "    reg_N = (w - w_min) / (w_max - w_min)\n",
    "    return reg_N\n",
    "\n",
    "def curly_Nprime(w):\n",
    "    w_min, w_max = torch.min(torch.min(torch.min(w))), torch.max(torch.max(torch.max(w)))\n",
    "    curly_N = (w - w_min + 1) / (w_max - w_min + 2)\n",
    "    return curly_N\n",
    "    # return (w - torch.min(w) + 1) / (torch.max(w) - torch.min(w) + 2)\n",
    "\n",
    "def f_VHN(x, w):\n",
    "    relu_x = relu(curly_N(x))\n",
    "    relu_w = relu(curly_Nprime(w))\n",
    "    \n",
    "    return relu_x * relu_w\n",
    "    \n",
    "class VHNLayer(nn.Module):\n",
    "    \"\"\" Custom VHN layer \"\"\"\n",
    "    def __init__(self, channels, img_len, img_width):\n",
    "        super().__init__()\n",
    "        self.channels, self.img_len, self.img_width = channels, img_len, img_width\n",
    "        weights = torch.Tensor(channels, img_len, img_width)\n",
    "        self.weights = nn.Parameter(weights)  # nn.Parameter is a Tensor that's a module parameter.\n",
    "\n",
    "        # initialize weights and biases\n",
    "        nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5)) # weight init\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return f_VHN(x, self.weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2f9c03f-1b56-4a4e-9bc0-a40df78e8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from load_data import device\n",
    "\"fix dimensions\"\n",
    "\"may need \"\n",
    "import matplotlib.pyplot as plt\n",
    "# from colormap import *\n",
    "import os\n",
    "\n",
    "class ATR(nn.Module):\n",
    "    def __init__(self, nc, device = None, N_filters=4, N_output = 1, ker = 4, s = 2, pad =1):\n",
    "        super(ATR, self).__init__()\n",
    "        self.ker = ker\n",
    "        self.s = s\n",
    "        self.pad = pad\n",
    "        self.nc = nc\n",
    "        # self.device = device\n",
    "        self.N_filters = N_filters\n",
    "        self.N_output = N_output\n",
    "        self.vhn = VHNLayer(101, 64, 64)\n",
    "        self.conv1 = nn.Conv3d(nc, N_filters, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.conv2 = nn.Conv3d(N_filters, N_filters, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.conv3 = nn.Conv3d(N_filters, N_filters, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.conv4 = nn.Conv3d(N_filters, 1, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.avgpool = nn.AvgPool3d(kernel_size = (6, 2, 2), stride= (1, 1, 1), padding= (0, 0, 0))\n",
    "    \n",
    "\n",
    "        # \"columns input x and output columnes\"\n",
    "\n",
    "        self.f2 = nn.Linear(1248,1)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x0):\n",
    "        \"image vectorization\"\n",
    "        # print(x0.shape)\n",
    "        x0 = self.vhn.forward(x0)\n",
    "        x = self.conv1(x0.unsqueeze(1))\n",
    "        x = self.avgpool(F.relu(x))\n",
    "        x = self.conv2(x)\n",
    "        x = self.avgpool(F.relu(x))\n",
    "        x = self.conv3(x)\n",
    "        x = self.avgpool(F.relu(x))\n",
    "        x = self.conv4(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "\n",
    "        x = self.f2(x)\n",
    "\n",
    "        y = self.sigmoid(x)\n",
    "\n",
    "        return y\n",
    "\n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2205becb-221e-46d0-a01a-dfc301b8506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ATR(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6b5e92e-1c13-48da-be4f-6722fc586f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac5ef9b3-faae-4ec7-99e6-8fdf56c303cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be18efb3-1940-4f57-9122-576a26dde859",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../research_data/sas_nov_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7124b66-b2c2-4d7f-b64d-64fef384d5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dldr_trn, dldr_tst = generate_generators(data_root = path , hdf_data_path = 'DL_info/chip_info/cube_raw',BZ = 20, IR = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20745286-1e42-4fc4-ad2b-d1f4fa8f949a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "[1,     5] loss: 0.735\n",
      "[1,    10] loss: 0.735\n",
      "[1,    15] loss: 0.728\n",
      "[1,    20] loss: 0.697\n",
      "[1,    25] loss: 0.621\n",
      "[1,    30] loss: 0.603\n",
      "[1,    35] loss: 0.620\n",
      "[1,    40] loss: 0.411\n",
      "[1,    45] loss: 0.362\n",
      "[1,    50] loss: 0.378\n",
      "[1,    55] loss: 0.174\n",
      "[1,    60] loss: 0.360\n",
      "[1,    65] loss: 0.542\n",
      "[1,    70] loss: 0.496\n",
      "[1,    75] loss: 0.381\n",
      "[1,    80] loss: 0.374\n",
      "[1,    85] loss: 0.398\n",
      "[1,    90] loss: 0.672\n",
      "[1,    95] loss: 0.716\n",
      "[1,   100] loss: 0.704\n",
      "[1,   105] loss: 0.601\n",
      "[1,   110] loss: 0.557\n",
      "[1,   115] loss: 0.561\n",
      "[1,   120] loss: 0.367\n",
      "[1,   125] loss: 0.265\n",
      "[1,   130] loss: 0.204\n",
      "[1,   135] loss: 0.240\n",
      "[1,   140] loss: 0.491\n",
      "[1,   145] loss: 0.596\n",
      "[1,   150] loss: 0.483\n",
      "[1,   155] loss: 0.395\n",
      "[1,   160] loss: 0.404\n",
      "[1,   165] loss: 0.283\n",
      "[1,   170] loss: 0.423\n",
      "[1,   175] loss: 0.565\n",
      "[1,   180] loss: 0.625\n",
      "[1,   185] loss: 0.569\n",
      "[1,   190] loss: 0.471\n",
      "[1,   195] loss: 0.579\n",
      "[1,   200] loss: 0.616\n",
      "[1,   205] loss: 0.540\n",
      "[1,   210] loss: 0.478\n",
      "[1,   215] loss: 0.513\n",
      "[1,   220] loss: 0.459\n",
      "[1,   225] loss: 0.362\n",
      "[1,   230] loss: 0.476\n",
      "[1,   235] loss: 0.665\n",
      "[1,   240] loss: 0.434\n",
      "[1,   245] loss: 0.268\n",
      "[1,   250] loss: 0.326\n",
      "[1,   255] loss: 0.367\n",
      "[1,   260] loss: 0.352\n",
      "[1,   265] loss: 0.249\n",
      "[1,   270] loss: 0.105\n",
      "[1,   275] loss: 0.224\n",
      "[1,   280] loss: 0.372\n",
      "[1,   285] loss: 0.412\n",
      "[1,   290] loss: 0.318\n",
      "[1,   295] loss: 0.432\n",
      "[1,   300] loss: 0.490\n",
      "[1,   305] loss: 0.501\n",
      "[1,   310] loss: 0.498\n",
      "[1,   315] loss: 0.416\n",
      "[1,   320] loss: 0.386\n",
      "[1,   325] loss: 0.429\n",
      "[1,   330] loss: 0.367\n",
      "[1,   335] loss: 0.340\n",
      "[1,   340] loss: 0.399\n",
      "[1,   345] loss: 0.434\n",
      "[1,   350] loss: 0.404\n",
      "[1,   355] loss: 0.436\n",
      "[1,   360] loss: 0.479\n",
      "[1,   365] loss: 0.487\n",
      "[1,   370] loss: 0.521\n",
      "[1,   375] loss: 0.578\n",
      "[1,   380] loss: 0.504\n",
      "[1,   385] loss: 0.295\n",
      "next epoch\n",
      "epoch 1\n",
      "[2,     5] loss: 0.621\n",
      "[2,    10] loss: 0.630\n",
      "[2,    15] loss: 0.421\n",
      "[2,    20] loss: 0.391\n",
      "[2,    25] loss: 0.378\n",
      "[2,    30] loss: 0.374\n",
      "[2,    35] loss: 0.387\n",
      "[2,    40] loss: 0.263\n",
      "[2,    45] loss: 0.199\n",
      "[2,    50] loss: 0.189\n",
      "[2,    55] loss: 0.075\n",
      "[2,    60] loss: 0.208\n",
      "[2,    65] loss: 0.394\n",
      "[2,    70] loss: 0.196\n",
      "[2,    75] loss: 0.146\n",
      "[2,    80] loss: 0.230\n",
      "[2,    85] loss: 0.266\n",
      "[2,    90] loss: 0.371\n",
      "[2,    95] loss: 0.525\n",
      "[2,   100] loss: 0.502\n",
      "[2,   105] loss: 0.535\n",
      "[2,   110] loss: 0.517\n",
      "[2,   115] loss: 0.534\n",
      "[2,   120] loss: 0.335\n",
      "[2,   125] loss: 0.255\n",
      "[2,   130] loss: 0.266\n",
      "[2,   135] loss: 0.270\n",
      "[2,   140] loss: 0.350\n",
      "[2,   145] loss: 0.493\n",
      "[2,   150] loss: 0.464\n",
      "[2,   155] loss: 0.324\n",
      "[2,   160] loss: 0.252\n",
      "[2,   165] loss: 0.210\n",
      "[2,   170] loss: 0.390\n",
      "[2,   175] loss: 0.595\n",
      "[2,   180] loss: 0.583\n",
      "[2,   185] loss: 0.547\n",
      "[2,   190] loss: 0.460\n",
      "[2,   195] loss: 0.532\n",
      "[2,   200] loss: 0.594\n",
      "[2,   205] loss: 0.403\n",
      "[2,   210] loss: 0.296\n",
      "[2,   215] loss: 0.458\n",
      "[2,   220] loss: 0.437\n",
      "[2,   225] loss: 0.370\n",
      "[2,   230] loss: 0.458\n",
      "[2,   235] loss: 0.537\n",
      "[2,   240] loss: 0.412\n",
      "[2,   245] loss: 0.246\n",
      "[2,   250] loss: 0.347\n",
      "[2,   255] loss: 0.324\n",
      "[2,   260] loss: 0.291\n",
      "[2,   265] loss: 0.216\n",
      "[2,   270] loss: 0.123\n",
      "[2,   275] loss: 0.278\n",
      "[2,   280] loss: 0.391\n",
      "[2,   285] loss: 0.328\n",
      "[2,   290] loss: 0.334\n",
      "[2,   295] loss: 0.390\n",
      "[2,   300] loss: 0.451\n",
      "[2,   305] loss: 0.483\n",
      "[2,   310] loss: 0.539\n",
      "[2,   315] loss: 0.395\n",
      "[2,   320] loss: 0.411\n",
      "[2,   325] loss: 0.451\n",
      "[2,   330] loss: 0.316\n",
      "[2,   335] loss: 0.378\n",
      "[2,   340] loss: 0.495\n",
      "[2,   345] loss: 0.455\n",
      "[2,   350] loss: 0.457\n",
      "[2,   355] loss: 0.487\n",
      "[2,   360] loss: 0.447\n",
      "[2,   365] loss: 0.451\n",
      "[2,   370] loss: 0.546\n",
      "[2,   375] loss: 0.608\n",
      "[2,   380] loss: 0.502\n",
      "[2,   385] loss: 0.314\n",
      "next epoch\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion1 = nn.BCELoss()\n",
    "criterion2 = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    print(\"epoch {epoch}\".format(epoch=epoch))\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dldr_trn, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "    \n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs = torch.log10(torch.tensor(inputs).transpose(1,3) + 1)\n",
    "        # print(inputs.shape)\n",
    "        labels = torch.tensor(labels)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # print(inputs)\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss1 = criterion1(outputs, labels.reshape(20,1).type(torch.float32))\n",
    "        \n",
    "        loss2 = criterion2(curly_Nprime(net.vhn.weights), curly_N(torch.sum(inputs, dim = 0) / dldr_trn.batch_size))\n",
    "        # print(\"netvhn\", net.vhn.weights.shape)\n",
    "        # print(curly_N(torch.sum(inputs, dim = 0) / dldr.batch_size).shape)\n",
    "        loss = loss1 + loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 5 == 4:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 5:.3f}')\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff0b6b82-894d-40af-add8-6a0dbf28643c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next epoch\n",
      "95\n",
      "PRAUC tensor(0.9239)\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "import torcheval\n",
    "from torcheval.metrics.functional import binary_auprc\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(dldr_tst,0):\n",
    "        inputs, label = data\n",
    "        \n",
    "        inputs = torch.log10(torch.tensor(inputs).transpose(1,3) + 1)\n",
    "        # print(inputs.shape)\n",
    "        label = torch.tensor(label)\n",
    "        # calculate outputs by running images through the \n",
    "        output = net(inputs)\n",
    "\n",
    "        preds.append(output.tolist())\n",
    "        labels.append(label.tolist())\n",
    "\n",
    "\n",
    "        if i > 100:\n",
    "            break\n",
    "print(len(preds))\n",
    "print(\"PRAUC\", binary_auprc(torch.tensor(preds).squeeze(0).squeeze(2), torch.tensor(labels), num_tasks=len(preds)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f78f412e-c8e4-4315-a7ac-8f4ee24cb505",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATRP(nn.Module):\n",
    "    def __init__(self, nc, device = None, N_filters=4, N_output = 1, ker = 4, s = 2, pad =1):\n",
    "        super(ATRP, self).__init__()\n",
    "        self.ker = ker\n",
    "        self.s = s\n",
    "        self.pad = pad\n",
    "        self.nc = nc\n",
    "        # self.device = device\n",
    "        self.N_filters = N_filters\n",
    "        self.N_output = N_output\n",
    "        self.conv1 = nn.Conv3d(nc, N_filters, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.conv2 = nn.Conv3d(N_filters, N_filters, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.conv3 = nn.Conv3d(N_filters, N_filters, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.conv4 = nn.Conv3d(N_filters, 1, kernel_size = (3, 3, 3), stride=(1, 2, 2), padding= (0, 1, 1))\n",
    "        self.avgpool = nn.AvgPool3d(kernel_size = (6, 2, 2), stride= (1, 1, 1), padding= (0, 0, 0))\n",
    "    \n",
    "\n",
    "        # \"columns input x and output columnes\"\n",
    "\n",
    "        self.f2 = nn.Linear(1248,1)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x0):\n",
    "        \"image vectorization\"\n",
    "        # print(x0.shape)\n",
    "        x = self.conv1(x0.unsqueeze(1))\n",
    "        x = self.avgpool(F.relu(x))\n",
    "        x = self.conv2(x)\n",
    "        x = self.avgpool(F.relu(x))\n",
    "        x = self.conv3(x)\n",
    "        x = self.avgpool(F.relu(x))\n",
    "        x = self.conv4(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "\n",
    "        x = self.f2(x)\n",
    "\n",
    "        y = self.sigmoid(x)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61831703-54ee-4b10-8a58-12bf98a101a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "dldr_trn, dldr_tst = generate_generators(data_root = path , hdf_data_path = 'DL_info/chip_info/cube_raw',BZ = 20, IR = 1)\n",
    "criterion1 = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "net2 = ATRP(1)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    print(\"epoch {epoch}\".format(epoch=epoch))\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dldr_trn, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "    \n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs = torch.log10(torch.tensor(inputs).transpose(1,3) + 1)\n",
    "        # print(inputs.shape)\n",
    "        labels = torch.tensor(labels)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # print(inputs)\n",
    "        # forward + backward + optimize\n",
    "        outputs = net2(inputs)\n",
    "        loss1 = criterion1(outputs, labels.reshape(20,1).type(torch.float32))\n",
    "        # print(\"netvhn\", net.vhn.weights.shape)\n",
    "        # print(curly_N(torch.sum(inputs, dim = 0) / dldr.batch_size).shape)\n",
    "        loss = loss1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 5 == 4:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 5:.3f}')\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b4e5ead-9f84-4b8e-87db-a9ba91385651",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "next epoch\n",
      "14\n",
      "PRAUC tensor(0.6609)\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "import torcheval\n",
    "from torcheval.metrics.functional import binary_auprc\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(dldr_tst,0):\n",
    "        inputs, label = data\n",
    "        \n",
    "        inputs = torch.log10(torch.tensor(inputs).transpose(1,3) + 1)\n",
    "        # print(inputs.shape)\n",
    "        label = torch.tensor(label)\n",
    "        # calculate outputs by running images through the network\n",
    "        output = net2(inputs)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        preds.append(output.tolist())\n",
    "        labels.append(label.tolist())\n",
    "        print(i)\n",
    "\n",
    "        if i > 100:\n",
    "            break\n",
    "print(len(preds))\n",
    "print(\"PRAUC\", binary_auprc(torch.tensor(preds).squeeze(0).squeeze(2), torch.tensor(labels), num_tasks=len(preds)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c4a8d7b-d7a3-4cfe-a068-cf809d9d875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../research_data/sas_june_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d4e8d79-8083-4c24-874c-4f6b010ec3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dldr_trn, dldr_tst = generate_generators(data_root = path , hdf_data_path = 'DL_info/chip_info/cube_raw',BZ = 20, IR = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7205e7bf-605c-472a-b564-a55993853cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next epoch\n",
      "82\n",
      "PRAUC tensor(0.7327)\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "import torcheval\n",
    "from torcheval.metrics.functional import binary_auprc\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(dldr_trn,0):\n",
    "        inputs, label = data\n",
    "        \n",
    "        inputs = torch.log10(torch.tensor(inputs).transpose(1,3) + 1)\n",
    "        # print(inputs.shape)\n",
    "        label = torch.tensor(label)\n",
    "        # calculate outputs by running images through the \n",
    "        output = net2(inputs)\n",
    "\n",
    "        preds.append(output.tolist())\n",
    "        labels.append(label.tolist())\n",
    "\n",
    "\n",
    "        if i > 2000:\n",
    "            break\n",
    "print(len(preds))\n",
    "print(\"PRAUC\", binary_auprc(torch.tensor(preds).squeeze(0).squeeze(2), torch.tensor(labels), num_tasks=len(preds)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654d23a-bcc7-4b94-a498-e86e639efd77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83984750-866c-4022-9789-f48b162be44a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94245a2b-1234-4f4f-9309-e232d9ed4714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779e68d-c7d7-468f-8eee-7ffe445600a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
