{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.templates import RandomLayers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30   # Number of optimization epochs\n",
    "n_layers = 2    # Number of random layers\n",
    "n_train = 100    # Size of the train dataset\n",
    "n_test = 30   # Size of the test dataset\n",
    "num_filters = 5\n",
    "\n",
    "SAVE_PATH = \"../../research_data/qnn_data/\"  # Data saving folder\n",
    "PREPROCESS = True           # If False, skip quantum processing and load data from SAVE_PATH\n",
    "np.random.seed(0)           # Seed for NumPy random number generator\n",
    "tf.random.set_seed(0)       # Seed for TensorFlow random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data()\n",
    "\n",
    "# Reduce dataset size\n",
    "train_images = train_images[:n_train]\n",
    "train_labels = train_labels[:n_train]\n",
    "test_images = test_images[:n_test]\n",
    "test_labels = test_labels[:n_test]\n",
    "\n",
    "# Normalize pixel values within 0 and 1\n",
    "train_images = train_images / 255\n",
    "test_images = test_images / 255\n",
    "\n",
    "# Add extra dimension for convolution channels\n",
    "train_images = np.array(train_images[..., tf.newaxis], requires_grad=False)\n",
    "test_images = np.array(test_images[..., tf.newaxis], requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"lightning.qubit\", wires=4)\n",
    "# Random circuit parameters\n",
    "rand_params = np.random.uniform(high=2 * np.pi, size=(n_layers, 4))\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(phi):\n",
    "    # Encoding of 4 classical input values\n",
    "    for j in range(4):\n",
    "        qml.RY(np.pi * phi[j], wires=j)\n",
    "    # print(\"qml.RY(np.pi * phi[j], wires = j\") \n",
    "    # Random quantum circuit\n",
    "    RandomLayers(rand_params, wires=list(range(4)))\n",
    "    # Measurement producing 4 classical output values\n",
    "    return [qml.expval(qml.PauliZ(j)) for j in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quanv(image, num_filters):\n",
    "    \"\"\"Convolves the input image with many applications of the same quantum circuit.\"\"\"\n",
    "    tot = np.zeros((14, 14, 4, num_filters))\n",
    "    \n",
    "    for i in range(num_filters):\n",
    "        out = np.zeros((14, 14, 4))\n",
    "    \n",
    "        # Loop over the coordinates of the top-left pixel of 2X2 squares\n",
    "        for j in range(0, 28, 2):\n",
    "            for k in range(0, 28, 2):\n",
    "                # Process a squared 2x2 region of the image with a quantum circuit\n",
    "                q_results = circuit(\n",
    "                    [\n",
    "                        image[j, k, 0],\n",
    "                        image[j, k + 1, 0],\n",
    "                        image[j + 1, k, 0],\n",
    "                        image[j + 1, k + 1, 0]\n",
    "                    ]\n",
    "                )\n",
    "                # Assign expectation values to different channels of the output pixel (j/2, k/2)\n",
    "                for c in range(4):\n",
    "                    tot[j // 2, k // 2, c, i] = q_results[c]\n",
    "    return tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum pre-processing of train images:\n",
      "100/100        \n",
      "Quantum pre-processing of test images:\n",
      "30/30        \r"
     ]
    }
   ],
   "source": [
    "if PREPROCESS == True:\n",
    "    q_train_images = []\n",
    "    print(\"Quantum pre-processing of train images:\")\n",
    "    for idx, img in enumerate(train_images):\n",
    "        print(\"{}/{}        \".format(idx + 1, n_train), end=\"\\r\")\n",
    "        # _q_train_images = np.array_split(quanv(img, num_filters), num_filters, axis = 3)\n",
    "        # print(_q_train_images[0].shape)\n",
    "        for img in quanv(img, num_filters):\n",
    "            q_train_images.append(img)\n",
    "    q_train_images = np.asarray(q_train_images)\n",
    "\n",
    "    q_test_images = []\n",
    "    print(\"\\nQuantum pre-processing of test images:\")\n",
    "    for idx, img in enumerate(test_images):\n",
    "        print(\"{}/{}        \".format(idx + 1, n_test), end=\"\\r\")\n",
    "        # _q_test_images = np.array_split(quanv(img, num_filters), num_filters, axis = 3)\n",
    "        for img in quanv(img, num_filters):\n",
    "            q_test_images.append(img)\n",
    "    q_test_images = np.asarray(q_test_images)\n",
    "\n",
    "    # Save pre-processed images\n",
    "    np.save(SAVE_PATH + \"q_train_images.npy\", q_train_images)\n",
    "    np.save(SAVE_PATH + \"q_test_images.npy\", q_test_images)\n",
    "\n",
    "\n",
    "# Load pre-processed images\n",
    "q_train_images = np.load(SAVE_PATH + \"q_train_images.npy\")\n",
    "q_test_images = np.load(SAVE_PATH + \"q_test_images.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array split does not result in an equal division",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[184], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m q_train_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(np\u001b[38;5;241m.\u001b[39msplit(q_train_images, n_train, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m20\u001b[39m, n_train)\u001b[38;5;241m.\u001b[39mreshape(n_train,\u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m q_test_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_test_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m20\u001b[39m, n_test)\u001b[38;5;241m.\u001b[39mreshape(n_test,\u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/.venv/lib/python3.10/site-packages/pennylane/numpy/wrapper.py:117\u001b[0m, in \u001b[0;36mtensor_wrapper.<locals>._wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m         tensor_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _np\u001b[38;5;241m.\u001b[39many([i\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tensor_args])\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# evaluate the original object\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, _np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# only if the output of the object is a ndarray,\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# then convert to a PennyLane tensor\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     res \u001b[38;5;241m=\u001b[39m tensor(res, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtensor_kwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/.venv/lib/python3.10/site-packages/autograd/tracer.py:48\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_box(ans, trace, node)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/.venv/lib/python3.10/site-packages/numpy/lib/shape_base.py:864\u001b[0m, in \u001b[0;36msplit\u001b[0;34m(ary, indices_or_sections, axis)\u001b[0m\n\u001b[1;32m    862\u001b[0m     N \u001b[38;5;241m=\u001b[39m ary\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m N \u001b[38;5;241m%\u001b[39m sections:\n\u001b[0;32m--> 864\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    865\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray split does not result in an equal division\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_split(ary, indices_or_sections, axis)\n",
      "\u001b[0;31mValueError\u001b[0m: array split does not result in an equal division"
     ]
    }
   ],
   "source": [
    "q_train_images = np.array(np.split(q_train_images, n_train, axis = 0)).reshape(14,14,20, n_train).reshape(n_train,14,14,20)\n",
    "q_test_images = np.array(np.split(q_test_images, n_train, axis = 0)).reshape(14,14,20, n_test).reshape(n_test,14,14,20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(q_train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_samples = 4\n",
    "# n_channels = 4 * num_filters\n",
    "# fig, axes = plt.subplots(1 + n_channels, n_samples, figsize=(10, 10))\n",
    "# for k in range(n_samples):\n",
    "#     axes[0, 0].set_ylabel(\"Input\")\n",
    "#     if k != 0:\n",
    "#         axes[0, k].yaxis.set_visible(False)\n",
    "#     axes[0, k].imshow(train_images[k, :, :, 0], cmap=\"gray\")\n",
    "\n",
    "#     # Plot all output channels\n",
    "#     for c in range(n_channels):\n",
    "#         axes[c + 1, 0].set_ylabel(\"Output [ch. {}]\".format(c))\n",
    "#         if k != 0:\n",
    "#             axes[c, k].yaxis.set_visible(False)\n",
    "#         axes[c + 1, k].imshow(q_train_images[k, :, :, c], cmap=\"gray\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyModel():\n",
    "    \"\"\"Initializes and returns a custom Keras model\n",
    "    which is ready to be trained.\"\"\"\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_model = MyModel()\n",
    "\n",
    "q_history = q_model.fit(\n",
    "    q_train_images,\n",
    "    train_labels,\n",
    "    validation_data=(q_test_images, test_labels),\n",
    "    batch_size=10,\n",
    "    epochs=n_epochs,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model = MyModel()\n",
    "\n",
    "c_history = c_model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    validation_data=(test_images, test_labels),\n",
    "    batch_size=4,\n",
    "    epochs=n_epochs,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6, 9))\n",
    "\n",
    "ax1.plot(q_history.history[\"val_accuracy\"], \"-ob\", label=\"With quantum layer\")\n",
    "ax1.plot(c_history.history[\"val_accuracy\"], \"-og\", label=\"Without quantum layer\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(q_history.history[\"val_loss\"], \"-ob\", label=\"With quantum layer\")\n",
    "ax2.plot(c_history.history[\"val_loss\"], \"-og\", label=\"Without quantum layer\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_ylim(top=2.5)\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
